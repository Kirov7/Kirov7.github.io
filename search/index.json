[{"content":"CFC-Golang 开发规范 注：此开发规范整合了部分网络上有价值的参考意见和开发实践中的总结\nGithub地址：https://github.com/Kirov7/cfc-golang-develop-norms\n为什么需要编程规范？ 编程规范又叫代码规范，是团队之间在程序开发时需要遵守的约定。俗话说，无规矩不成方圆，一个开发团队应该就一种编程规范达成一致。编程规范有很多好处，我们简单说几个最主要的。\n促进团队合作 现代项目大多是由团队完成的，但是如果每个人书写出的代码风格迥异，最后集成代码时很容易杂乱无章、可读性极差。相反，风格统一的代码将大大提高可读性，易于理解，促进团队协作。\n规避错误 每一种语言都有容易犯的错误，Go语言也不例外。但是编码规范可以规避掉像Map并发读写等问题。不仅如此，规范的日志处理、错误处理还能够加快我们查找问题的速度。\n提升性能 优秀的开发者，能够在头脑中想象出不同程序运行的过程和结果，写出高性能的程序非常考验开发者的内功。但每个人的水平都有差异，这一点并不可控。但是如果我们将高性能编程的常见手段归纳整理出来，开发者只需要遵守这些简单的规则，就能够规避性能陷阱、极大提升程序性能。\n便于维护 我们习惯于关注编写代码的成本，但实际上维护代码的成本要高得多。大部分的项目是在前人的基础上完成开发的。我们在开发代码的时候，也会花大量时间阅读之前的代码。符合规范的代码更容易上手维护、更少出现牵一发动全身的耦合现象、也更容易看出业务处理逻辑。\n知道了编程规范的好处，那我们应该规范什么内容呢？这其实涉及到我们对好代码的定义。针对这个问题，每个人都能够说个几句。但总体来说，好的代码首先是整洁、一致的，同时它还是高效、健壮和可扩展的。\n有一些规范可以是强制的，因为我们可以通过工具和代码review强制要求用户遵守，还有一些规范是建议的，因为它更具有灵活性，很难被约束。在后面的规范中，[强制 xxx]中的“xxx”代表的就是可强制检查的工具。\n整洁、一致 好代码的第一个要求，是整洁和一致。有一句话是这样说的：\nAny fool can write code that a computer can understand. Good programmers write code that humans can understand.\n它的意思是，任何傻瓜都可以编写计算机可以理解的代码，而优秀的程序员编写的是人类可以理解的代码。\n如果我们的代码看起来乱七八糟，就像喝醉的人写的那样，这样不严谨的代码让我们有理由相信，项目的其他各个方面也隐藏着对细节的疏忽，并埋下了重大的隐患。\n阅读整洁的代码就像看到精心设计的手表或汽车一样赏心悦目，因为它凝聚了团队的智慧。\n阅读整洁的代码也像读到的武侠小说，书中的文字被脑中的图像取代，你看到了角色，听到了声音，体验到了悲怆和幽默。\n但是，明白什么是整洁的代码并不意味着你能写出整洁的代码。就好像我们知道如何欣赏一幅画不意味着我们能成为画家。\n整洁的代码包括对格式化、命名、函数等细节的密切关注，更需要在项目中具体实践。接下来我们就来看看整洁代码关注的这些细节和最佳的实践。\n格式化 代码长度\n代码应该有足够的垂直密度，能够肉眼一次获得到更多的信息。同时，单个函数、单行、单文件也需要限制长度，保证可阅读性和可维护性。\n[强制 lll] 一行内不超过 120 个字符，同时应当避免刻意断行。如果你发现某一行太长了，要么改名，要么调整语义，往往就可以解决问题了。\n[强制 funlen] 单个函数的行数不超过 40 行，过长则表示函数功能不专一、定义不明确、程序结构不合理，不易于理解。当函数过长时，可以提取函数以保持正文小且易读。\n[强制] 单个文件不超过 2000 行，过长说明定义不明确，程序结构划分不合理，不利于维护。\n代码布局\n我们先试想一篇写得很好的报纸文章。在顶部，你希望有一个标题，它会告诉你故事的大致内容，并影响你是否要阅读它。文章的第一段会为你提供整个故事的概要、粗略的概念，但是隐藏了所有细节。继续向下阅读，详细信息会逐步增加。\n[建议] Go 文件推荐按以下顺序进行布局。\n包注释：对整个模块和功能的完整描述，写在文件头部\nPackage：包名称\nImports：引入的包\nConstants：常量定义\nTypedefs：类型定义\nGlobals：全局变量定义\nFunctions：函数实现\n每个部分之间用一个空行分割。每个部分有多个类型定义或者有多个函数时，也用一个空行分割。示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 /* 注释 */ package http import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) const ( VERSION = \u0026#34;1.0.0\u0026#34; ) type Request struct{ } var msg = \u0026#34;HTTP success\u0026#34; func foo() { //... } [强制 goimports] 当 import 多个包时，应该对包进行分组。同一组的包之间不需要有空行，不同组之间的包需要一个空行。标准库的包应该放在第一组。\n空格与缩进\n为了让阅读代码时视线畅通，自上而下思路不被打断，我们需要使用一些空格和缩进。\n空格是为了分离关注点，将不同的组件分开。缩进是为了处理错误和边缘情况，与正常的代码分隔开。\n较常用的有下面这些规范：\n[强制 gofmt] 注释和声明应该对齐。示例如下：\n1 2 3 4 type T struct { name string // name of the object value int // its value } [强制 gofmt] 小括号()、中括号[]、大括号{} 内侧都不加空格。\n[强制 gofmt] 逗号、冒号（slice中冒号除外）前都不加空格，后面加 1 个空格。\n[强制 gofmt] 所有二元运算符前后各加一个空格，作为函数参数时除外。例如b := 1 + 2。[强制 gofmt] 使用 Tab 而不是空格进行缩进。\n[强制 nlreturn] return前方需要加一个空行，让代码逻辑更清晰。\n[强制 gofmt] 判断语句、for语句需要缩进1个 Tab，并且右大括号}与对应的 if 关键字垂直对齐。例如：\n1 2 3 4 5 if xxx { } else { } [强制 goimports] 当 import 多个包时，应该对包进行分组。同一组的包之间不需要有空行，不同组之间的包需要一个空行。标准库的包应该放在第一组。这同样适用于常量、变量和类型声明：\n1 2 3 4 5 6 7 8 9 10 import ( \u0026#34;fmt\u0026#34; \u0026#34;hash/adler32\u0026#34; \u0026#34;os\u0026#34; \u0026#34;appengine/foo\u0026#34; \u0026#34;appengine/user\u0026#34; \u0026#34;github.com/foo/bar\u0026#34; \u0026#34;rsc.io/goversion/version\u0026#34; ) [推荐] 避免 else 语句中处理错误返回，避免正常的逻辑位于缩进中。如下代码实例，else中进行错误处理，代码逻辑阅读起来比较费劲。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 if something.OK() { something.Lock() defer something.Unlock() err := something.Do() if err == nil { stop := StartTimer() defer stop() log.Println(\u0026#34;working...\u0026#34;) doWork(something) \u0026lt;-something.Done() // wait for it log.Println(\u0026#34;finished\u0026#34;) return nil } else { return err } } else { return errors.New(\u0026#34;something not ok\u0026#34;) } 如果把上面的代码修改成下面这样会更加清晰：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 if !something.OK() { return errors.New(\u0026#34;something not ok\u0026#34;) } something.Lock() defer something.Unlock() err := something.Do() if err != nil { return err } stop := StartTimer() defer stop() log.Println(\u0026#34;working...\u0026#34;) doWork(something) \u0026lt;-something.Done() // wait for it log.Println(\u0026#34;finished\u0026#34;) return nil [推荐] 函数内不同的业务逻辑处理建议用单个空行加以分割。\n[推荐] 注释之前的空行通常有助于提高可读性——新注释的引入表明新思想的开始。\n命名 Good naming is like a good joke. If you have to explain it, it’s not funny. ———Dave Cheney\n一个好的名字应该满足几个要素：\n短，容易拼写； 保持一致性； 意思准确，容易理解，没有虚假和无意义的信息。 例如，像下面这样的命名就是让人迷惑的：\n1 int d; // elapsed time in days [强制 revive] Go中的命名统一使用驼峰式、不要加下划线。\n[强制 revive] 缩写的专有名词应该大写，例如： ServeHTTP、IDProcessor。\n[强制] 区分变量名应该用有意义的名字，而不是使用阿拉伯数字：a1, a2, .. aN。\n[强制] 不要在变量名称中包含你的类型名称。\n[建议]变量的作用域越大，名字应该越长。\n现代 IDE 已经让更改名称变得更容易了，巧妙地使用IDE的功能，能够级联地同时修改多处命名。\n包名\n包名应该简短而清晰。\n[强制] 使用简短的小写字母，不需要下划线或混合大写字母。\n[建议] 合理使用缩写，例如：\n1 2 3 strconv（字符串转换） syscall（系统调用） fmt（格式化的 I/O） [强制] 避免无意义的包名，例如util,common,base等。\n接口命名\n[建议]单方法接口由方法名称加上 -er 后缀或类似修饰来命名。例如：Reader, Writer, Formatter, CloseNotifier ，当一个接口包含多个方法时，请选择一个能够准确描述其用途的名称（例如：net.Conn、http.ResponseWriter、io.ReadWriter）。\n本地变量命名\n[建议]尽可能地短。在这里，i 指代 index，r 指代 reader，b 指代 buffer。\n例如，下面这段代码就可以做一个简化：\n1 2 3 for index := 0; index \u0026lt; len(s); index++ { // } 可以替换为：\n1 2 3 for i := 0; i \u0026lt; len(s); i++ { // } 函数参数命名\n[建议]如果函数参数的类型已经能够看出参数的含义，那么函数参数的命名应该尽量简短：\n1 2 func AfterFunc(d Duration, f func()) *Timer func Escape(w io.Writer, s []byte) [建议]如果函数参数的类型不能表达参数的含义，那么函数参数的命名应该尽量准确：\n1 2 func Unix(sec, nsec int64) Time func HasPrefix(s, prefix []byte) bool 函数返回值命名\n[建议] 对于公开的函数，返回值具有文档意义，应该准确表达含义，如下所示：\n1 2 3 func Copy(dst Writer, src Reader) (written int64, err error) func ScanBytes(data []byte, atEOF bool) (advance int, token []byte, err error) 可导出的变量名\n[建议] 由于使用可导出的变量时会带上它所在的包名，因此，不需要对变量重复命名。例如bytes包中的ByteBuffer替换为Buffer，这样在使用时就是bytes.Buffer，显得更简洁。类似的还有把strings.StringReader修改为strings.Reader，把errors.NewError 修改为errors.New。\nError值命名\n[建议] 错误类型应该以Error结尾。\n[建议] Error变量名应该以Err开头。\n1 2 3 4 type ExitError struct { ... } var ErrFormat = errors.New(\u0026#34;image: unknown format\u0026#34;) 函数 [强制 cyclop] 圈复杂度（Cyclomatic complexity）\u0026lt;10。\n[强制 gochecknoinits] 避免使用init函数。\n[强制 revive] Context 应该作为函数的第一个参数。\n[强制] 正常情况下禁用unsafe。\n[强制] 禁止return裸返回，如下例中第一个return：\n1 2 3 4 5 6 7 8 9 func (f *Filter) Open(name string) (file File, err error) { for _, c := range f.chain { file, err = c.Open(name) if err != nil { return } } return f.source.Open(name) } [强制] 不要在循环里面使用defer，除非你真的确定defer的执行流程。\n[强制] 对于通过:=进行变量赋值的场景，禁止出现仅部分变量初始化的情况。例如在下面这个例子中，f函数返回的res是初始化的变量，但是函数返回的err其实复用了之前的err：\n1 2 var err error res,err := f() [建议] 函数返回值大于 3 个时，建议通过 struct 进行包装。\n[建议] 函数参数不建议超过 3 个，大于 3 个时建议通过 struct 进行包装。\n控制结构 [强制] 禁止使用goto。\n[强制 gosimple] 当一个表达式为 bool 类型时，应该使用 expr 或 !expr 判断，禁止使用 == 或 != 与 true / false 比较。\n[强制 nestif] if 嵌套深度不大于5。\n方法 [强制 revive] receiver 的命名要保持一致，如果你在一个方法中将接收器命名为 \u0026ldquo;c\u0026rdquo;，那么在其他方法中不要把它命名为 \u0026ldquo;cl\u0026rdquo;。\n[强制] receiver 的名字要尽量简短并有意义，禁止使用 this、self 等。\n1 2 3 4 5 6 func (c Client) done() error { // ... } func (cl Client) call() error { // ... } 注释 Go提供C风格的注释。有/**/ 的块注释和 // 的单行注释两种注释风格。注释主要有下面几个用处。\n注释不仅仅可以提供具体的逻辑细节，还可以提供代码背后的意图和决策。 帮助澄清一些晦涩的参数或返回值的含义。一般来说，我们会尽量找到一种方法让参数或返回值的名字本身就是清晰的。但是当它是标准库的一部分时，或者在你无法更改的第三方库中，一个清晰的注释会非常有用。 强调某一个重要的功能。例如，提醒开发者修改了这一处代码必须连带修改另一处代码。 总之，好的注释给我们讲解了what、how、why，方便后续的代码维护。\n[强制] 无用注释直接删除，无用的代码不应该注释而应该直接删除。即使日后需要，我们也可以通过Git快速找到。\n[强制] 使用行注释而不是尾注释，注释一律写在所描述内容的上一行。\n[强制] 统一使用中文注释，中英文字符之间严格使用空格分隔。\n1 // 从 Redis 中批量读取属性，对于没有读取到的 id ， 记录到一个数组里面，准备从 DB 中读取 [强制] 注释不需要额外的格式，例如星号横幅。\n[强制] 包、函数、方法和类型的注释说明都是一个完整的句子，以被描述的对象为主语开头。Go源码中都是这样的。\n示例如下：\n1 2 3 4 // queueForIdleConn queues w to receive the next idle connection for w.cm. // As an optimization hint to the caller, queueForIdleConn reports whether // it successfully delivered an already-idle connection. func (t *Transport) queueForIdleConn(w *wantConn) (delivered bool) [强制] Go语言提供了文档注释工具go doc，可以生成注释和导出函数的文档。文档注释的写法可以参考文稿中的链接。\n[强制 godot] 注释最后应该以句号结尾。\n[建议] 当某个部分等待完成时，可用 TODO: 开头的注释来提醒维护人员。\n[建议] 大部分情况下使用行注释。块注释主要用在包的注释上，不过块注释在表达式中或禁用大量代码时很有用。\n[建议] 当某个部分存在已知问题需要修复或改进时，可用 FIXME: 开头的注释来提醒维护人员。\n[建议] 需要特别说明某个问题时，可用 NOTE: 开头的注释。\n结构体 [强制] 不要将 Context 成员添加到 Struct 类型中。\nCommit 规范 commit message格式\n1 \u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; [强制] type(必须)\n用于说明git commit的类别，只允许使用下面的标识。\nfeat：新功能（feature）。\nfix/to：修复bug，可以是QA发现的BUG，也可以是研发自己发现的BUG。\nfix：产生diff并自动修复此问题。适合于一次提交直接修复问题 to：只产生diff不自动修复此问题。适合于多次提交。最终修复问题提交时使用fix docs：文档（documentation）。\nstyle：格式（不影响代码运行的变动）。\nrefactor：重构（即不是新增功能，也不是修改bug的代码变动）。\nperf：优化相关，比如提升性能、体验。\ntest：增加测试。\nchore：构建过程或辅助工具的变动。\nrevert：回滚到上一个版本。\nmerge：代码合并。\nsync：同步主线或分支的Bug。\n[建议] scope(可选)\nscope用于说明 commit 影响的范围，比如数据层、控制层、视图层等等，视项目不同而不同。\n例如在Angular，可以是location，browser，compile，compile，rootScope， ngHref，ngClick，ngView等。如果你的修改影响了不止一个scope，你可以使用*代替。\n[强制] subject(必须)\nsubject是commit目的的简短描述，不超过50个字符。\n建议使用中文（感觉中国人用中文描述问题能更清楚一些）。\n结尾不加句号或其他标点符号。 根据以上规范git commit message将是如下的格式： 1 2 fix(DAO):用户查询缺少username属性 feat(Controller):用户查询接口开发 这样规范 git commit 有以下优点\n便于开发者对提交历史进行追溯，了解发生了什么情况。 一旦约束了commit message，意味着我们将慎重的进行每一次提交，不能再一股脑的把各种各样的改动都放在一个git commit里面，这样一来整个代码改动的历史也将更加清晰。 格式化的commit message才可以用于自动化输出Change log。 高效 [强制] Map在初始化时需要指定长度make(map[T1]T2, hint)。\n[强制] Slice在初始化时需要指定长度和容量make([]T, length, capacity)。\n我们来看下下面这段程序，它的目的是往切片中循环添加元素。\n1 2 3 4 5 6 func createSlice(n int) (slice []string) { for i := 0; i \u0026lt; n; i++ { slice = append(slice, \u0026#34;I\u0026#34;, \u0026#34;love\u0026#34;, \u0026#34;go\u0026#34;) } return slice } 从功能上来看，这段代码没有问题。但是，这种写法忽略了一个事实，如下图所示，往切片中添加数据时，切片会自动扩容，Go运行时会创建新的内存空间并执行拷贝。\n自动扩容显然是有成本的。在循环操作中执行这样的代码会放大性能损失，减慢程序的运行速度。性能损失的对比可参考这篇文章。我们可以改写一下上面这段程序，在初始化时指定合适的切片容量：\n1 2 3 4 5 6 7 func createSlice(n int) []string { slice := make([]string, 0, n*3) for i := 0; i \u0026lt; n; i++ { slice = append(slice, \u0026#34;I\u0026#34;, \u0026#34;love\u0026#34;, \u0026#34;go\u0026#34;) } return slice } 这段代码在一开始就指定了需要的容量，最大程度避免了内存的浪费。同时，运行时不需要再执行自动扩容操作，加速了程序的运行。\n[强制] time.After()在某些情况下会发生泄露，替换为使用Timer。\n[强制] 数字与字符串转换时，使用strconv，而不是fmt。\n[强制] 读写磁盘时，使用读写buffer。\n[建议] 谨慎使用Slice的截断操作和append操作，除非你知道下面的代码输出什么：\n1 2 3 4 5 6 x := []int{1, 2, 3, 4} y := x[:2] fmt.Println(cap(x), cap(y)) y = append(y, 30) fmt.Println(\u0026#34;x:\u0026#34;, x) fmt.Println(\u0026#34;y:\u0026#34;, y) [建议] 任何书写的协程，都需要明确协程什么时候退出。\n[建议] 热点代码中，内存分配复用内存可以使用 sync.Pool 提速。\n[建议] 将频繁的字符串拼接操作（+=），替换为StringBuffer 或 StringBuilder。\n[建议] 使用正则表达式重复匹配时，利用Compile提前编译提速。\n[建议] 当程序严重依赖Map时，Map的Key使用int而不是string将提速。\n[建议] 多读少写的场景，使用读写锁而不是写锁将提速。\n健壮性 [强制] 除非出现不可恢复的程序错误，否则不要使用 panic 来处理常规错误，使用 error 和多返回值。\n[强制] 永远只在 main 函数和 init 函数中调用 log.Fatal() 方法。\n[强制] 永远先关闭 写channel 再关闭 读channel，否则对已关闭 写channel 进行写入时会引发 panic 。\n[强制 revive] 错误信息不应该首字母大写（除专有名词和缩写词外），也不应该以标点符号结束。因为错误信息通常在其他上下文中被打印。\n[强制 errcheck] 不要使用 _ 变量来丢弃 error。如果函数返回 error，应该强制检查。\n[强制] 在 Release模式 使用 context 的时候需要设定超时时间。\n[建议] 在处理错误时，如果我们逐层返回相同的错误，那么在最后日志打印时，我们并不知道代码中间的执行路径。例如找不到文件时打印的No such file or directory，这会减慢我们排查问题的速度。因此，在中间处理err时，需要使用fmt.Errorf 或第三方包给错误添加额外的上下文信息。像下面这个例子，在fmt.Errorf中，除了实际报错的信息，还加上了授权错误信息authenticate failed ：\n1 2 3 4 5 6 7 func AuthenticateRequest(r *Request) error { err := authenticate(r.User) if err != nil { return fmt.Errorf(\u0026#34;authenticate failed: %v\u0026#34;, err) } return nil } 当有多个错误需要处理时，可以考虑将fmt.Errorf放入defer中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func DoSomeThings(val1 int, val2 string) (_ string, err error) { defer func() { if err != nil { err = fmt.Errorf(\u0026#34;in DoSomeThings: %w\u0026#34;, err) } }() val3, err := doThing1(val1) if err != nil { return \u0026#34;\u0026#34;, err } val4, err := doThing2(val2) if err != nil { return \u0026#34;\u0026#34;, err } return doThing3(val3, val4) } [强制] 利用recover捕获panic时，需要由defer函数直接调用。\n例如，下面例子中的panic是可以被捕获的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package main import \u0026#34;fmt\u0026#34; func printRecover() { r := recover() fmt.Println(\u0026#34;Recovered:\u0026#34;, r) } func main() { defer printRecover() panic(\u0026#34;OMG!\u0026#34;) } 但是下面这个例子中的panic却不能被捕获：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func printRecover() { r := recover() fmt.Println(\u0026#34;Recovered:\u0026#34;, r) } func main() { defer func() { printRecover() }() panic(\u0026#34;OMG!\u0026#34;) } [强制] 不用重复使用recover，只需要在每一个协程的最上层函数拦截即可。recover只能够捕获当前协程，而不能跨协程捕获panic，下例中的panic就是无法被捕获的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 package main import \u0026#34;fmt\u0026#34; func printRecover() { r := recover() fmt.Println(\u0026#34;Recovered:\u0026#34;, r) } func main() { defer printRecover() go func() { panic(\u0026#34;OMG!\u0026#34;) }() // ... } [强制] 有些特殊的错误是recover不住的，例如Map的并发读写冲突。这种错误可以通过race工具来检查。\n扩展性 [建议] 利用接口实现扩展性。接口特别适用于访问外部组件的情况，例如访问数据库、访问下游服务。另外，接口可以方便我们进行功能测试。关于接口的最佳实践，需要单独论述。\n[建议] 使用功能选项模式(options 模式)对一些公共API的构造函数进行扩展，大量第三方库例如gomicro、zap等都使用了这种策略。\n1 2 3 4 5 6 7 db.Open(addr, db.DefaultCache, zap.NewNop()) 可以替换为=\u0026gt; db.Open( addr, db.WithCache(false), db.WithLogger(log), ) 内部实践 Gin 项目启动 [强制] 在大型的项目开发中，采用优雅服务启停设计，采用 httpServer.ListenAndServer() 方法进行web服务的启动，而不是 Gin 框架的方法，web服务需额外启动一个 goroutine 来运行，通过信号监听的方式控制结束程序。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 func main() { r := gin.Default() srv := \u0026amp;http.Server{ Addr: \u0026#34;:80\u0026#34;, Handler: r, } // 优雅的启停 go func() { log.Printf(\u0026#34;web server running in %s \\n\u0026#34;, srv.Addr) if err := srv.ListenAndServe(); err != nil \u0026amp;\u0026amp; err != http.ErrServerClosed { log.Fatalln(err) } }() quit := make(chan os.Signal) // SIGINT 用户发送 INTR 字符(Ctrl + C)触发 kill -2 // SIGTERM 结束程序 (可以被捕获、阻塞或忽略) signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM) \u0026lt;-quit log.Println(\u0026#34;Shutting Down project Web server...\u0026#34;) ctx, cancel := context.WithTimeout(context.Background(), 2*time.Second) defer cancel() if err := srv.Shutdown(ctx); err != nil { log.Fatalln(\u0026#34;Web server shutdown, cause by : \u0026#34;, err) } select { case \u0026lt;-ctx.Done(): log.Println(\u0026#34;wait timeout...\u0026#34;) } log.Println(\u0026#34;Web Server stop success...\u0026#34;) } 以上代码可进一步封装，以保证 main 的代码结构清晰\n返回值格式 [强制] json格式的返回值，code部分统一采用 net/http 包中的 http.StatusOK，obj 则为业务对象的统一格式封装。\n1 2 ctx.JSON(http.StatusOK, result.Success(list)) ctx.JSON(http.StatusOK, result.Fail(http.StatusBadRequest, \u0026#34;参数错误\u0026#34;)) [强制] 业务对象中的统一字段为：code、msg、data，其中code为错误代码，由具体的服务实现方定义，需要保证全局唯一，如果没有错误则固定为 200 ，msg为错误信息，由具体的服务实现方定义，需要简洁的描述错误的原因，错误可统一定义为全局变量，当在api层产生参数错误、数据校验失败等请求值错误，则使用 http.StatusBadRequest 作为错误码， data 则为前端所需要的业务对象，推荐使用在api服务中封装返回值结构体实例。\n对应结构体实例：\n1 2 3 4 5 6 type BusinessCode int type Result struct { Code BusinessCode `json:\u0026#34;code\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` Data any `json:\u0026#34;data\u0026#34;` } [强制] 在给前端返回 json 后必须 return 。\ngrpc proto文件与命名规范 [强制] proto文件中的 service、rpc Function、message 以大驼峰的方式命名。\n[推荐] 尽可能的将 proto 文件中 service 命名为 xxxService 、 RPC 方法的入参命名为 XxxRequest，出参命名为 XxxResponse。\n[强制] 将引用的生成 rpc 包重命名为 xxxRpc 以避免module中的本地模块产生冲突。\n1 2 3 import( departmentRpc \u0026#34;github.com/Kirov7/project-grpc/project/department\u0026#34; ) [推荐] 编译 proto 文件时推荐不要直接生成到会被其他模块引用的包下，建议生成到指定目录后手动迁移文件。\n注册grpc服务 [建议] 优雅的启动 grpcServer 示例，其中 RegisterGrpc() 返回的 grpc.Server 可供上层调用 grpcSever.Stop() 等，可对 grpcServer 生命周期进行管控。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 type gRPCConfig struct { Addr string RegisterFunc func(server *grpc.Server) } func RegisterGrpc() *grpc.Server { c := gRPCConfig{ Addr: config.AppConf.GrpcConfig.Addr, RegisterFunc: func(g *grpc.Server) { login.RegisterLoginServiceServer(g, loginServiceV1.NewLoginService()) }, } // 可通过拦截器实现服务接口的缓存 //cacheInterceptor := interceptor.NewCacheInterceptor() //s := grpc.NewServer(cacheInterceptor.CacheInterceptor()) s := grpc.NewServer() c.RegisterFunc(s) listen, err := net.Listen(\u0026#34;tcp\u0026#34;, c.Addr) if err != nil { log.Printf(\u0026#34;listen port %s fail\\n\u0026#34;, c.Addr) } go func() { log.Printf(\u0026#34;grpc server started as %s \\n\u0026#34;, c.Addr) err = s.Serve(listen) if err != nil { log.Printf(\u0026#34;server started error: %s\\n\u0026#34;, err) return } }() return s } 项目结构核心部分示例 此示例结合了部分DDD领域驱动设计的思想，但并非完全按照DDD的模式进行组织，旨在优化项目组织结构的同时，尽量避免过于复杂抽象的概念。\nmain.go 进行各类初始化操作，如初始化http服务、路由注册、初始化grpc客户端、grpc服务注册等。\nconfig 包 内有 config.go 和 config.yaml 文件，config.go 中拥有包含配置的全局变量，推荐使用 viper 进行配置读取。\ninternal 包 internal包 是 golang 中特殊的一个包，它对外部module不可见，可用来存放数据操作等敏感内容。\n可包含domain、repository、dao、rpc、data等包\ndomain：领域服务，负责表达业务概念，业务状态信息以及业务规则，通过调用 repository 、rpc 或其他 domain 进行数据操作与数据整合，实现完整的某一领域模块的业务逻辑。在进行单元测试时可以绕过 service 直接对 domain 进行细粒度的测试，简化测试流程。\nrepository：仓库，负责封装数据的查询、创建、更新、删除等逻辑的接口，屏蔽底层实现，供使用者调用\ndao：数据操作层，实现 repository 的接口，封装对MySQL、Redis等数据库操作的具体实现的。\nrpc：rpc客户端，对其他rpc服务进行远程调用的客户端。\ndata：数据表的直接映射，并包含对于数据传输模型的转换。\npkg 包 pkg包 包含了服务具体实现与其所依赖的预定义的常量与全局变量。\n可包含model、service等包\nmodel：预定义的常量与全局变量，便于在业务中重用，简化操作逻辑。可包含预定于的 rediskey、业务所需的枚举值、预定义的错误等。 service：业务层，接受客户端传输的数据，对请求数据进行校验与转换，通过调用 domain 层进行业务操作，整合调用的结果值，返回给客户端。 工具 要人工来保证团队成员遵守了上述的编程规范并不是一件容易的事情。因此，我们有许多静态的和动态的代码分析工具帮助团队识别代码规范的错误，甚至可以发现一些代码的bug。\ngolangci-lint golangci-lint 是当前大多数公司采用的静态代码分析工具，词语Linter 指的是一种分析源代码以此标记编程错误、代码缺陷、风格错误的工具。\n而golangci-lint是集合多种Linter的工具。要查看支持的 Linter 列表以及启用/禁用了哪些Linter，可以使用下面的命令：\n1 golangci-lint help linters Go语言定义了实现Linter的API，它还提供了golint工具，用于集成了几种常见的Linter。在源码中，我们可以查看怎么在标准库中实现典型的Linter。\nLinter的实现原理是静态扫描代码的AST（抽象语法树），Linter的标准化意味着我们可以灵活实现自己的Linters。不过golangci-lint里面其实已经集成了包括golint在内的总多Linter，并且有灵活的配置能力。所以在自己写Linter之前，建议先了解golangci-lint现有的能力。\n在大型项目中刚开始使用golang-lint会出现大量的错误，这种情况下我们只希望扫描增量的代码。如下所示，可以通过在golangci-lint配置文件中调整new-from-rev参数，配置以当前基准分支为基础实现增量扫描\n1 2 3 4 linters: enable-all: true issues: new-from-rev: master Pre-Commit 在代码通过Git Commit提交到代码仓库之前，git 提供了一种pre-commit的hook能力，用于执行一些前置脚本。在脚本中加入检查的代码，就可以在本地拦截住一些不符合规范的代码，避免频繁触发CI或者浪费时间。pre-commit的配置和使用方法，可以参考TiDB。\n并发检测 race Go 1.1 提供了强大的检查工具race来排查数据争用问题。race 可以用在多个Go指令中，一旦检测器在程序中找到数据争用，就会打印报告。这份报告包含发生race冲突的协程栈，以及此时正在运行的协程栈。可以在编译时和运行时执行race，方法如下：\n1 2 3 4 $ go test -race mypkg $ go run -race mysrc.go $ go build -race mycmd $ go install -race mypkg 在下面这个例子中， 运行中加入race检查后直接报错。从报错后输出的栈帧信息中，我们能看出具体发生并发冲突的位置。\n1 2 3 4 5 6 7 8 9 » go run -race 2_race.go ================== WARNING: DATA RACE Read at 0x00000115c1f8 by goroutine 7: main.add() bookcode/concurrence_control/2_race.go:5 +0x3a Previous write at 0x00000115c1f8 by goroutine 6: main.add() bookcode/concurrence_control/2_race.go:5 +0x56 第四行Read at 表明读取发生在2_race.go 文件的第5行，而第七行Previous write 表明前一个写入也发生在2_race.go 文件的第5行。这样我们就可以非常快速地定位数据争用问题了。\n竞争检测的成本因程序而异。对于典型的程序，内存使用量可能增加 5~10 倍，执行时间会增加2~20倍。同时，竞争检测器会为当前每个defer和recover语句额外分配8字节。在Goroutine退出前，这些额外分配的字节不会被回收。这意味着，如果有一个长期运行的Goroutine，而且定期有defer 和recover调用，那么程序内存的使用量可能无限增长。（这些内存分配不会显示到 runtime.ReadMemStats或runtime / pprof 的输出。）\n覆盖率 一般我们会使用代码覆盖率来判断代码书写的质量，识别无效代码。go tool cover 是go语言提供的识别代码覆盖率的工具。\n","date":"2023-02-16T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/cfclogo03.png","permalink":"https://Kirov7.github.io/p/cfc-studio-golang%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","title":"CFC Studio Golang开发规范"},{"content":"Badger源码导读(二) 源码分析入口基准案例 本次我们研究的是第二部分 - 读写事务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 func main() { // 打开db db, _ := badger.Open(badger.DefaultOptions(\u0026#34;tmp/badger\u0026#34;)) defer db.Close() // 读写事务 err := db.Update(func(txn *badger.Txn) error { txn.Set([]byte(\u0026#34;answer\u0026#34;), []byte(\u0026#34;42\u0026#34;)) txn.Get([]byte(\u0026#34;answer\u0026#34;)) return nil }) // 只读事务 err = db.View(func(txn *badger.Txn) error { txn.Get([]byte(\u0026#34;answer_v1\u0026#34;)) return nil }) // 遍历keys err = db.View(func(txn *badger.Txn) error { opts := badger.DefaultIteratorOptions opts.PrefetchSize = 10 it := txn.NewIterator(opts) defer it.Close() for it.Rewind(); it.Valid(); it.Next() { item := it.Item() k := item.Key() err := item.Value(func(val []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, val) return nil }) if err != nil { return err } } return nil }) err = db.RunValueLogGC(0.7) _ = err } 读写事务 在第一章db初始化的时候，我们发现参数opt里面有一个 orcale 实例\n在事务的实现中oracle实例发挥着重要的作用\n1 Oracle的实例,一个KV引擎并发事务的管理器,负责分配事务的版本号,用来实现MVCC功能 oracle实例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func newOracle(opt Options) *oracle { orc := \u0026amp;oracle{ isManaged: opt.managedTxns, // 当前事务是否支持冲突检测 detectConflicts: opt.DetectConflicts, // We\u0026#39;re not initializing nextTxnTs and readOnlyTs. It would be done after replay in Open. // // WaterMarks must be 64-bit aligned for atomic package, hence we must use pointers here. // See https://golang.org/pkg/sync/atomic/#pkg-note-BUG. // 水位,用来进行并发控制 readMark: \u0026amp;y.WaterMark{Name: \u0026#34;badger.PendingReads\u0026#34;}, txnMark: \u0026amp;y.WaterMark{Name: \u0026#34;badger.TxnTimestamp\u0026#34;}, closer: z.NewCloser(2), } orc.readMark.Init(orc.closer) orc.txnMark.Init(orc.closer) return orc } WaterMark.Init()\n1 2 3 4 5 6 // Init initializes a WaterMark struct. MUST be called before using it. func (w *WaterMark) Init(closer *z.Closer) { // 固定100大小的缓冲mark channel w.markCh = make(chan mark, 100) go w.process(closer) } mark 结构体\n1 2 3 4 5 6 7 8 9 10 type mark struct { // Either this is an (index, waiter) pair or (index, done) or (indices, done). // 索引 index uint64 // 传递空结构体信息的channel waiter chan struct{} indices []uint64 // 是否完成的标志 done bool // Set to true if the index is done. } 核心方法-Update(func(*badger.Txn)) db.Update(func(*badger.Txn))\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 func (db *DB) Update(fn func(txn *Txn) error) error { // 判断状态是否关闭 if db.IsClosed() { return ErrDBClosed } // 事务启动和提交时间戳由最终用户管理。这只对构建在Badger之上的数据库有用(比如Dgraph) if db.opt.managedTxns { panic(\u0026#34;Update can only be used with managedDB=false.\u0026#34;) } txn := db.NewTransaction(true) defer txn.Discard() // 回调的闭包 if err := fn(txn); err != nil { return err } return txn.Commit() } newTransaction(bool) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 func (db *DB) NewTransaction(update bool) *Txn { return db.newTransaction(update, false) } func (db *DB) newTransaction(update, isManaged bool) *Txn { // 设置是否只读事务,badger对读写并发的设计不同 // 只读事务比读写事务性能要更好(少做一些事情,不需要考虑并发控制如读写冲突等) if db.opt.ReadOnly \u0026amp;\u0026amp; update { // DB is read-only, force read-only transaction. update = false } // 创建事务实例 txn := \u0026amp;Txn{ // 只读标记 update: update, // 反引用db db: db, count: 1, // One extra entry for BitFin. size: int64(len(txnKey) + 10), // Some buffer for the extra entry. } // 标记读写事务 if update { // 如果检测冲突 if db.opt.DetectConflicts { // 记录写入事务的set,检测事务冲突 // 如读取一个已经修改了的事务就要进行检测 txn.conflictKeys = make(map[uint64]struct{}) } // 记录当前的读写事务在事务上做了多少次set操作,所有插入都会进行记录 txn.pendingWrites = make(map[string]*Entry) } // 给事务分配一个读时间戳 if !isManaged { // oracle进行事务版本号的分发 txn.readTs = db.orc.readTs() } return txn } orcale.readTs() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 func (o *oracle) readTs() uint64 { if o.isManaged { panic(\u0026#34;ReadTs should not be retrieved for managed DB\u0026#34;) } var readTs uint64 // 加锁 o.Lock() // 获取全局事务号(后面在commit的时候就直到为什么是-1了) readTs = o.nextTxnTs - 1 // 标记当前读事务时间戳,事务已经进入读取阶段 o.readMark.Begin(readTs) o.Unlock() // Wait for all txns which have no conflicts, have been assigned a commit // timestamp and are going through the write to value log and LSM tree // process. Not waiting here could mean that some txns which have been // committed would not be read. // 此时事务版本号已经分配好,而且也已经通知了事务的水位标记线,事务已经开始了 y.Check(o.txnMark.WaitForMark(context.Background(), readTs)) return readTs } WaterMark.Begin() 方法 1 2 3 4 5 6 7 // Begin sets the last index to the given value. func (w *WaterMark) Begin(index uint64) { // 更改index atomic.StoreUint64(\u0026amp;w.lastIndex, index) // 写入之前创建的缓冲区为100的缓冲mark channel(消费方后面详解) w.markCh \u0026lt;- mark{index: index, done: false} } WaterMark.WaitForMark(ctx, index) 方法 传入读时间戳\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // WaitForMark waits until the given index is marked as done. // 等待比当前小的时间戳提交 func (w *WaterMark) WaitForMark(ctx context.Context, index uint64) error { // w.DoneUntil() =\u0026gt; 已提交事务的最大版本号 // 用读事务时间戳和已提交事务最大版本号进行比较 if w.DoneUntil() \u0026gt;= index { return nil } waitCh := make(chan struct{}) // 如果发现有比当前事务号更小的,会等待小的读取事务全部提交完成之后,会回调waiter进行close // 具体mark的处理过程见下文 w.markCh \u0026lt;- mark{index: index, waiter: waitCh} select { case \u0026lt;-ctx.Done(): return ctx.Err() case \u0026lt;-waitCh: return nil } } txn.set(k,v []byte) 方法 set操作不会真正的写磁盘,只会对事务对象进行一定的操作,一切都基于内存,直到提交的时候才会持久化到磁盘,如果事务终止的话,直接将内存中的数据释放即可,也是保证事务一致性的因素之一\n1 2 3 4 5 6 7 8 func (txn *Txn) Set(key, val []byte) error { // 包装成entry return txn.SetEntry(NewEntry(key, val)) } func (txn *Txn) SetEntry(e *Entry) error { return txn.modify(e) } txn.modify(*Entry)方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 func (txn *Txn) modify(e *Entry) error { // key的最大尺寸,因为key的最大长度的为uint32 65535 // 在写入key的时候,会拼接提交时间戳(事务版本号) const maxKeySize = 65000 switch { // 是否为只读事务 case !txn.update: return ErrReadOnlyTxn case txn.discarded: // 事务是否已提交 return ErrDiscardedTxn // 如果key为空 case len(e.Key) == 0: return ErrEmptyKey // 通过前缀判断是否为内部key (!badger!) case bytes.HasPrefix(e.Key, badgerPrefix): return ErrInvalidKey // 检查key大小是否超出约定值 case len(e.Key) \u0026gt; maxKeySize: // Key length can\u0026#39;t be more than uint16, as determined by table::header. To // keep things safe and allow badger move prefix and a timestamp suffix, let\u0026#39;s // cut it down to 65000, instead of using 65536. return exceedsSize(\u0026#34;Key\u0026#34;, maxKeySize, e.Key) // 判断vlog大小是否超出约定之 case int64(len(e.Value)) \u0026gt; txn.db.opt.ValueLogFileSize: return exceedsSize(\u0026#34;Value\u0026#34;, txn.db.opt.ValueLogFileSize, e.Value) case txn.db.opt.InMemory \u0026amp;\u0026amp; int64(len(e.Value)) \u0026gt; txn.db.valueThreshold(): return exceedsSize(\u0026#34;Value\u0026#34;, txn.db.valueThreshold(), e.Value) } // 检查事务的尺寸 if err := txn.checkSize(e); err != nil { return err } // The txn.conflictKeys is used for conflict detection. If conflict detection // is disabled, we don\u0026#39;t need to store key hashes in this map. // 判断当前事务是否开启事务冲突检测 if txn.db.opt.DetectConflicts { // 根据key的内存地址计算memHash (这里使用hash值来检测key的冲突,在一定程度上会有误判的情况) fp := z.MemHash(e.Key) // Avoid dealing with byte arrays. // 写到事务冲突的判断集合 txn.conflictKeys[fp] = struct{}{} } // If a duplicate entry was inserted in managed mode, move it to the duplicate writes slice. // Add the entry to duplicateWrites only if both the entries have different versions. For // same versions, we will overwrite the existing entry. // 获取老的entry,判断是否成功和是否重复提交 if oldEntry, ok := txn.pendingWrites[string(e.Key)]; ok \u0026amp;\u0026amp; oldEntry.version != e.version { // 如果是重复写入(版本号相同的key在一个事务中set多次) // 单独记录到duplicateWrites数组 txn.duplicateWrites = append(txn.duplicateWrites, oldEntry) } txn.pendingWrites[string(e.Key)] = e return nil } Txn 结构体\n1 2 3 4 5 6 type Txn struct { ... pendingWrites map[string]*Entry // cache stores any writes done by txn. duplicateWrites []*Entry // Used in managed mode to store duplicate entries. ... } txn.get(k []byte) 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 func (txn *Txn) Get(key []byte) (item *Item, rerr error) { // key为空直接返回错误 if len(key) == 0 { return nil, ErrEmptyKey // 如果事务已经结束则返回错误 } else if txn.discarded { return nil, ErrDiscardedTxn } item = new(Item) // 如果是读写事务 if txn.update { // 判断当前key是否在之前被写入过,判断key是否相等,此方法实现了事务的隔离性 if e, has := txn.pendingWrites[string(key)]; has \u0026amp;\u0026amp; bytes.Equal(key, e.Key) { // 如果相同则直接组装数据并返回 // 判断是否被删除或过期 if isDeletedOrExpired(e.meta, e.ExpiresAt) { return nil, ErrKeyNotFound } // Fulfill from cache. item.meta = e.meta item.val = e.Value item.userMeta = e.UserMeta item.key = key item.status = prefetched item.version = txn.readTs item.expiresAt = e.ExpiresAt // We probably don\u0026#39;t need to set db on item here. return item, nil } // Only track reads if this is update txn. No need to track read if txn serviced it // internally. // 标记当前key被读取,放入到一个read数组中,记录当前事务都读取了哪些key txn.addReadKey(key) } // 从lsm-tree中真正的读取数据,之后再详细解读 seek := y.KeyWithTs(key, txn.readTs) vs, err := txn.db.get(seek) if err != nil { return nil, y.Wrapf(err, \u0026#34;DB::Get key: %q\u0026#34;, key) } if vs.Value == nil \u0026amp;\u0026amp; vs.Meta == 0 { return nil, ErrKeyNotFound } if isDeletedOrExpired(vs.Meta, vs.ExpiresAt) { return nil, ErrKeyNotFound } item.key = key item.version = vs.Version item.meta = vs.Meta item.userMeta = vs.UserMeta item.vptr = y.SafeCopy(item.vptr, vs.Value) item.txn = txn item.expiresAt = vs.ExpiresAt return item, nil } txn.Commit() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (txn *Txn) Commit() error { // txn.conflictKeys can be zero if conflict detection is turned off. So we // should check txn.pendingWrites. // 判断当前txn中是否有set操作发生过 if len(txn.pendingWrites) == 0 { return nil // Nothing to do. } // Precheck before discarding txn. // 进行相关的预处理检查 if err := txn.commitPrecheck(); err != nil { return err } defer txn.Discard() // 真正的提交到oracle,通知oracle,当前的事务对象已经提交,可以更新水位线 // 即比水位时间戳小的读取事务继续执行 txnCb, err := txn.commitAndSend() if err != nil { return err } // If batchSet failed, LSM would not have been updated. So, no need to rollback anything. // 调用返回的闭包 return txnCb() } txn.commitPrecheck() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 func (txn *Txn) commitPrecheck() error { // 判断事务是否已提交 if txn.discarded { return errors.New(\u0026#34;Trying to commit a discarded txn\u0026#34;) } keepTogether := true // 遍历发生过修改的key,进行一些检查 for _, e := range txn.pendingWrites { if e.version != 0 { keepTogether = false } } // If keepTogether is True, it implies transaction markers will be added. // In that case, commitTs should not be never be zero. This might happen if // someone uses txn.Commit instead of txn.CommitAt in managed mode. This // should happen only in managed mode. In normal mode, keepTogether will // always be true. if keepTogether \u0026amp;\u0026amp; txn.db.opt.managedTxns \u0026amp;\u0026amp; txn.commitTs == 0 { return errors.New(\u0026#34;CommitTs cannot be zero. Please use commitAt instead\u0026#34;) } return nil } txn.commitAndSend() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 func (txn *Txn) commitAndSend() (func() error, error) { orc := txn.db.orc // Ensure that the order in which we get the commit timestamp is the same as // the order in which we push these updates to the write channel. So, we // acquire a writeChLock before getting a commit timestamp, and only release // it after pushing the entries to it. // 给oracle实例上写锁,以保证按事务提交的顺序写入到磁盘 orc.writeChLock.Lock() defer orc.writeChLock.Unlock() // 创建提交时间戳 commitTs, conflict := orc.newCommitTs(txn) // 检查冲突情况 if conflict { return nil, ErrConflict } keepTogether := true // 设置版本号,把key后面拼接一个后缀(版本号)的闭包 setVersion := func(e *Entry) { if e.version == 0 { e.version = commitTs } else { keepTogether = false } } // 遍历设置版本号 for _, e := range txn.pendingWrites { setVersion(e) } // The duplicateWrites slice will be non-empty only if there are duplicate // entries with different versions. // 遍历设置版本号 for _, e := range txn.duplicateWrites { setVersion(e) } // 把 pendingWrites 和 duplicateWrites 组装成一个entry数组 entries := make([]*Entry, 0, len(txn.pendingWrites)+len(txn.duplicateWrites)+1) // 处理enry的闭包 processEntry := func(e *Entry) { // Suffix the keys with commit ts, so the key versions are sorted in // descending order of commit timestamp. e.Key = y.KeyWithTs(e.Key, e.version) // Add bitTxn only if these entries are part of a transaction. We // support SetEntryAt(..) in managed mode which means a single // transaction can have entries with different timestamps. If entries // in a single transaction have different timestamps, we don\u0026#39;t add the // transaction markers. if keepTogether { e.meta |= bitTxn } entries = append(entries, e) } // The following debug information is what led to determining the cause of // bank txn violation bug, and it took a whole bunch of effort to narrow it // down to here. So, keep this around for at least a couple of months. // var b strings.Builder // fmt.Fprintf(\u0026amp;b, \u0026#34;Read: %d. Commit: %d. reads: %v. writes: %v. Keys: \u0026#34;, // txn.readTs, commitTs, txn.reads, txn.conflictKeys) // 遍历处理组装entry for _, e := range txn.pendingWrites { processEntry(e) } // 遍历处理组装entry for _, e := range txn.duplicateWrites { processEntry(e) } // 这里先不用管 if keepTogether { // CommitTs should not be zero if we\u0026#39;re inserting transaction markers. y.AssertTrue(commitTs != 0) e := \u0026amp;Entry{ Key: y.KeyWithTs(txnKey, commitTs), Value: []byte(strconv.FormatUint(commitTs, 10)), meta: bitFinTxn, } entries = append(entries, e) } // 把entry写请求打包好,批量发送给db实例进行异步写入 req, err := txn.db.sendToWriteCh(entries) if err != nil { orc.doneCommit(commitTs) return nil, err } // 返回ret的闭包,再commit的最后执行 ret := func() error { // 等待写操作完成 err := req.Wait() // Wait before marking commitTs as done. // We can\u0026#39;t defer doneCommit above, because it is being called from a // callback here. // 标记commit操作完成 orc.doneCommit(commitTs) return err } return ret, nil } oracle.newCommitTs()方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 func (o *oracle) newCommitTs(txn *Txn) (uint64, bool) { o.Lock() defer o.Unlock() // 检查活跃的事务是否冲突,已经提交的事务不需要检查 if o.hasConflict(txn) { return 0, true } var ts uint64 if !o.isManaged { // 对读取操作标记完成 o.doneRead(txn) // 清理已完成事务 o.cleanupCommittedTransactions() // This is the general case, when user doesn\u0026#39;t specify the read and commit ts. // 读取时间戳是next-1,提交时间戳是next ts = o.nextTxnTs o.nextTxnTs++ // 此时读取操作结束,进入事务提交阶段,不能再进行事务的其他操作(不需要上锁) o.txnMark.Begin(ts) } else { // If commitTs is set, use it instead. ts = txn.commitTs } y.AssertTrue(ts \u0026gt;= o.lastCleanupTs) // 冲突检测 if o.detectConflicts { // We should ensure that txns are not added to o.committedTxns slice when // conflict detection is disabled otherwise this slice would keep growing. // 读阶段完成,提交阶段没有完成的事务会记录到o.committedTxns o.committedTxns = append(o.committedTxns, committedTxn{ ts: ts, // 提交版本号 conflictKeys: txn.conflictKeys, // 冲突检查的set(事务写的key) }) } return ts, false } oracle.hasConflict() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // hasConflict must be called while having a lock. func (o *oracle) hasConflict(txn *Txn) bool { // reads数组为0则无冲突 if len(txn.reads) == 0 { return false } // commitedTxns: 表示活跃事务的数组 for _, committedTxn := range o.committedTxns { // If the committedTxn.ts is less than txn.readTs that implies that the // committedTxn finished before the current transaction started. // We don\u0026#39;t need to check for conflict in that case. // This change assumes linearizability. Lack of linearizability could // cause the read ts of a new txn to be lower than the commit ts of // a txn before it (@mrjn). // 判断事务时间戳是否小于读取时间戳 if committedTxn.ts \u0026lt;= txn.readTs { // 如果小于,则不会影响的事务的读取 continue } // 遍历事务读取的key,如果在别的事务中发生过修改操作,如果是则发生冲突 for _, ro := range txn.reads { if _, has := committedTxn.conflictKeys[ro]; has { return true } } } return false } oracle.doneRead() 方法 1 2 3 4 5 6 7 8 9 10 11 12 func (o *oracle) doneRead(txn *Txn) { if !txn.doneRead { txn.doneRead = true // 通知readMark完成 o.readMark.Done(txn.readTs) } } func (w *WaterMark) Done(index uint64) { // 创建一个mark实例,向markchannel发送消息 w.markCh \u0026lt;- mark{index: index, done: true} } oracle.cleanupCommittedTransactions() 方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 func (o *oracle) cleanupCommittedTransactions() { // Must be called under o.Lock // 检查版本冲突 if !o.detectConflicts { // When detectConflicts is set to false, we do not store any // committedTxns and so there\u0026#39;s nothing to clean up. return } // Same logic as discardAtOrBelow but unlocked var maxReadTs uint64 // 获取最大读取时间戳 if o.isManaged { maxReadTs = o.discardTs } else { // 获取读事务标记水位作为最大读取时间戳 maxReadTs = o.readMark.DoneUntil() } // 断言是否大于最后清理时间戳 y.AssertTrue(maxReadTs \u0026gt;= o.lastCleanupTs) // do not run clean up if the maxReadTs (read timestamp of the // oldest transaction that is still in flight) has not increased // 如果等于则直接返回 if maxReadTs == o.lastCleanupTs { return } // 如果不等于,则赋值最后清理时间戳为最大读取时间戳 o.lastCleanupTs = maxReadTs // 创建空切片 tmp := o.committedTxns[:0] // 小于水位的事务已经不会产生冲突了,清理数组 for _, txn := range o.committedTxns { if txn.ts \u0026lt;= maxReadTs { continue } // 活跃状态的保存 tmp = append(tmp, txn) } o.committedTxns = tmp } db.sendToWriteCh() 方法 异步写入\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 func (db *DB) sendToWriteCh(entries []*Entry) (*request, error) { if atomic.LoadInt32(\u0026amp;db.blockWrites) == 1 { return nil, ErrBlockedWrites } var count, size int64 // 遍历entrys,计算数据条数 for _, e := range entries { size += e.estimateSizeAndSetThreshold(db.valueThreshold()) count++ } // 现在单词事务最大写入 if count \u0026gt;= db.opt.maxBatchCount || size \u0026gt;= db.opt.maxBatchSize { return nil, ErrTxnTooBig } // We can only service one request because we need each txn to be stored in a contigous section. // Txns should not interleave among other txns or rewrites. req := requestPool.Get().(*request) req.reset() req.Entries = entries req.Wg.Add(1) req.IncrRef() // for db write // 打包好的整个事务请求,传到写事务channel,真正的写入到磁盘 db.writeCh \u0026lt;- req // Handled in doWrites. y.NumPutsAdd(db.opt.MetricsEnabled, int64(len(entries))) return req, nil } watermark.process() 方法 process用于处理Mark通道。这不是线程安全的，因此只为进程运行一个 goroutine。一个就足够了，因为所有 goroutine 操作都使用纯粹的内存和 cpu。每个索引必须按顺序发出至少一个开始水位，否则等待者可能会无限期地被阻塞。\n示例：我们在 100 处有一个水位，在 101 处有一个等待者，如果在索引 101 处没有发出水印，那么等待者将无限期地卡住，因为它无法决定 101 处的任务是否已决定不发出水位或它没有安排好了\n整个方法使用cas和局部变量，最终保证了原子性\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 // process is used to process the Mark channel. This is not thread-safe, // so only run one goroutine for process. One is sufficient, because // all goroutine ops use purely memory and cpu. // Each index has to emit atleast one begin watermark in serial order otherwise waiters // can get blocked idefinitely. Example: We had an watermark at 100 and a waiter at 101, // if no watermark is emitted at index 101 then waiter would get stuck indefinitely as it // can\u0026#39;t decide whether the task at 101 has decided not to emit watermark or it didn\u0026#39;t get // scheduled yet. func (w *WaterMark) process(closer *z.Closer) { defer closer.Done() // 创建一个堆 var indices uint64Heap // pending maps raft proposal index to the number of pending mutations for this proposal. // 记录并发冲突值的用于检测的实例 pending := make(map[uint64]int) // 存储回调channel, 一个时间戳上可以等待多个channel, 在orcale.readTs()中的waitForMark() waiters := make(map[uint64][]chan struct{}) // 初始化堆 heap.Init(\u0026amp;indices) // 真正执行逻辑的闭包函数 processOne := func(index uint64, done bool) { // If not already done, then set. Otherwise, don\u0026#39;t undo a done entry. // 通过传入的时间戳,从pending数组中取值 prev, present := pending[index] // 如果不存在则push进堆中 if !present { heap.Push(\u0026amp;indices, index) } delta := 1 // 根据done判断是开始事务还是结束事务进行置位1或-1 if done { delta = -1 } // 如果是一个begin操作,即开启事务的标记的时候,在pending数组计数位里+1 // 如果是一个commit操作,即终止事务的标记的时候,在pending数组计数位里-1 // 让所有事务都能感知到活跃事务之间的关联 pending[index] = prev + delta // Update mark by going through all indices in order; and checking if they have // been done. Stop at the first index, which isn\u0026#39;t done. // 获取当前的水位信息 doneUntil := w.DoneUntil() // 当前水位大于时间戳，证明已经不需要再去关注并发性了 if doneUntil \u0026gt; index { // 断言结束操作 AssertTruef(false, \u0026#34;Name: %s doneUntil: %d. Index: %d\u0026#34;, w.Name, doneUntil, index) } until := doneUntil loops := 0 // 循环对堆数组进行pop遍历操作,弹出最小的事务的时间戳 for len(indices) \u0026gt; 0 { min := indices[0] // 判断是否大于0,证明最小的事务时间戳没有结束 if done := pending[min]; done \u0026gt; 0 { // 没有其他事务在等待,跳出循环 break // len(indices) will be \u0026gt; 0. } // Even if done is called multiple times causing it to become // negative, we should still pop the index. // done \u0026lt;= 0 则说明事务已经提交,删除它曾经存在的痕迹 heap.Pop(\u0026amp;indices) delete(pending, min) // 水位移动 until = min loops++ } // 判断水位是否发生了变化 if until != doneUntil { // 有所变化则通过cas赋值 AssertTrue(atomic.CompareAndSwapUint64(\u0026amp;w.doneUntil, doneUntil, until)) } // 唤醒操作的闭包 notifyAndRemove := func(idx uint64, toNotify []chan struct{}) { // 遍历通知channel的数组,一个个close掉 for _, ch := range toNotify { close(ch) } // 在waiters中移除对应的时间戳 delete(waiters, idx) // Release the memory back. } // 如果水位发生移动 if until-doneUntil \u0026lt;= uint64(len(waiters)) { // Issue #908 showed that if doneUntil is close to 2^60, while until is zero, this loop // can hog up CPU just iterating over integers creating a busy-wait loop. So, only do // this path if until - doneUntil is less than the number of waiters. // 遍历原水位到当前水位 for idx := doneUntil + 1; idx \u0026lt;= until; idx++ { // 把水位中的index拿出,得到回调函数的channel if toNotify, ok := waiters[idx]; ok { // 进行逐个关闭 notifyAndRemove(idx, toNotify) } } } else { for idx, toNotify := range waiters { if idx \u0026lt;= until { notifyAndRemove(idx, toNotify) } } } // end of notifying waiters. } // 此方法的主体,循环for-select处理 for { select { // 关闭任务 case \u0026lt;-closer.HasBeenClosed(): return // 接收markChannel, 100长的channel case mark := \u0026lt;-w.markCh: // 判断有无水位的信息 if mark.waiter != nil { // 获取已提交事务的最大版本号的水位 doneUntil := atomic.LoadUint64(\u0026amp;w.doneUntil) // 比较时间戳大小关系,如果当前已提交事务时间戳大于读时间戳,不需要等待,直接close if doneUntil \u0026gt;= mark.index { close(mark.waiter) } else { // 否则的话,读时间戳大于水位时间戳 // 在之前有未完成的活跃事务,不能获取读取时间戳,否则可能读取道脏数据 // 创建waiters ws, ok := waiters[mark.index] if !ok { // 如果该读时间戳未在waiters中存在,创建channel数组 waiters[mark.index] = []chan struct{}{mark.waiter} } else { // 如果不空的话,说明之前已经有其他的事务在找个时间戳上等待,直接append waiters[mark.index] = append(ws, mark.waiter) } } // 读取时间戳和提交时间戳的操作都没有mark对象 } else { // 如果当前时间戳是有效的 if mark.index \u0026gt; 0 { // 对这个时间戳调用闭包进行逻辑处理 // mark.done是一个bool值,在begin的时候是false,在完成的时候为true processOne(mark.index, mark.done) } // 遍历堆数组,对所有的节点进行一次处理逻辑 for _, index := range mark.indices { processOne(index, mark.done) } } } } } 总结 读写事务代码总体的执行流程为:\n检查事务是否关闭 创建一个事务对象 如果是一个读写事务 创建一个存储哪些key存在冲突的记录map 记录在当前事务上发生写入的key的列表 分配一个事务读取时间戳 从 nextReadTnx中获取一个时间戳的值 然后标记为开始,记录最后的事物时间戳后发送给一个markChan 等待与这个时间戳冲突的事物提交完成 获取最后一个已提交的时间戳 创建一个用于wait回调的chan 等待waitChan的回调，或者上下文的取消 Defer 丢弃最终的事务 标记readTs时间戳已经完成 执行闭包函数 Set kv 检查kv的合法性 检查当前事务的执行的命令数量以及存储大小是否超过阈值 按照key计算一个hash值，然后加入冲突检查map中 如果这个key 在当前事务中被写入过，并且与之前的版本不同，则计入重复写入的数组中 将该key的写入操作记录到pending数组里 Get k 如果这是一个读写事务 如果在pending数组里存在一个key，并且没有过期 则复制数据并返回 提交事务 检查 pending数组是否为空，如果为空则直接返回 事务提交的前置检查 提交并发送日志返回一个回调函数进行等待 获取一把锁 创建一个提交时间戳 是否存在冲突 如果读时间戳大于已提交的时间戳则忽略 读时间戳小于已提交的时间戳则判断是否存在读后写的情况存在就冲突 拿到当前事务的readTs标记其为完成 清理已经提交的事务的记录数组 标记当前的事务开始进行提交，分配了一个新的提交时间戳 将当前提交事务的时间戳和冲突的key组成对象记录在已提交事务的数组中 遍历每个在当前事务中写入的key，为其分配唯一的版本号 遍历pending数组处理每一个实体kv对象 追加一条标记事务结束的内部kv实体 创建一个写入请求 发送给写者channel中 返回一个回调函数 等待批量写请求处理完成 标记事务已经提交完成 将buf写入到mmap关联的文件内存中 写入磁盘 如果值日志offset大于vlog最大文件大小，或者写入条数超购阈值 写入磁盘 如果设置了同步则会系统调用sync 最后根据offset进行截断 创建一个新的vlog文件 ","date":"2022-12-04T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/badger-cr.png","permalink":"https://Kirov7.github.io/p/badger%E6%BA%90%E7%A0%81%E5%AF%BC%E8%AF%BB%E4%BA%8C-%E8%AF%BB%E5%86%99%E4%BA%8B%E5%8A%A1/","title":"Badger源码导读(二) 读写事务"},{"content":"Badger源码导读 源码分析入口基准案例 先从Badger的基本使用入手\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 func main() { // 打开db db, _ := badger.Open(badger.DefaultOptions(\u0026#34;tmp/badger\u0026#34;)) defer db.Close() // 读写事务 err := db.Update(func(txn *badger.Txn) error { txn.Set([]byte(\u0026#34;answer\u0026#34;), []byte(\u0026#34;42\u0026#34;)) txn.Get([]byte(\u0026#34;answer\u0026#34;)) return nil }) // 只读事务 err = db.View(func(txn *badger.Txn) error { txn.Get([]byte(\u0026#34;answer_v1\u0026#34;)) return nil }) // 遍历keys err = db.View(func(txn *badger.Txn) error { opts := badger.DefaultIteratorOptions opts.PrefetchSize = 10 it := txn.NewIterator(opts) defer it.Close() for it.Rewind(); it.Valid(); it.Next() { item := it.Item() k := item.Key() err := item.Value(func(val []byte) error { fmt.Printf(\u0026#34;key=%s, value=%s\\n\u0026#34;, k, val) return nil }) if err != nil { return err } } return nil }) err = db.RunValueLogGC(0.7) _ = err } DB初始化过程 初始化参数 badger.open()传入的是一个option,先看一下option结构体的字段都有哪些\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 type Options struct { // Required options. // Dir: Badger是KV分离的存储引擎,Dir位置存储的是 Key 和指向Value的逻辑指针 // ValueDir: 存储的是Value日志,即值所在的地址,默认情况下Dir和ValueDir在同一个path目录下 Dir string ValueDir string // Usually modified options. // SyncWrites: 同步写,即写入的时候主动同步到磁盘(mmap不会立即刷盘) SyncWrites bool NumVersionsToKeep int // ReadOnly: 如其名,是否设置为只读 ReadOnly bool // Logger: 如其名,log对象 Logger Logger // Compression: 压缩归并的级别 Compression options.CompressionType // InMemory: 是否只基于内存 InMemory bool MetricsEnabled bool // Sets the Stream.numGo field NumGoroutines int // Fine tuning options. // MemTableSize: 内存表的尺寸限制 MemTableSize int64 BaseTableSize int64 BaseLevelSize int64 LevelSizeMultiplier int TableSizeMultiplier int // MaxLevels: 最大容忍的level级别,LSM-T的级数L0-L(max-1) MaxLevels int VLogPercentile float64 // ValueThreshold: 值大小的阈值,如果Value的大小不超过这个设定值,则不会将KV进行分离 // 此处是在工业实践中的一种权衡,KV分离会造成不可避免的读放大 // (两次的随机读,先在LSM-T中读取一次指针,再通过指针从ValueLog中读取一次值) ValueThreshold int64 // NumMemtables: 内存表的数量 NumMemtables int // Changing BlockSize across DB runs will not break badger. The block size is // read from the block index stored at the end of the table. // BlockSize: 每个block的大小(sst由block和index等组成) BlockSize int // BloomFalsePositive: 布隆过滤器假阳性的比例 BloomFalsePositive float64 // BlockCacheSize: 块缓存的大小 BlockCacheSize int64 // IndexCacheSize: 索引缓存的大小 IndexCacheSize int64 NumLevelZeroTables int NumLevelZeroTablesStall int // ValueLogFileSize: 存储值的Valuelog文件的最大大小 ValueLogFileSize int64 // ValueLogMaxEntries: 存储值的Valuelog文件的最大键值对数量 ValueLogMaxEntries uint32 // NumCompactors: 日志合并压缩协程同时运行的最大数量 NumCompactors int CompactL0OnClose bool LmaxCompaction bool ZSTDCompressionLevel int // When set, checksum will be validated for each entry read from the value log file. // VerifyValueChecksum: 是否进行参数校验值的检查 VerifyValueChecksum bool // Encryption related options. // EncryptionKey: 加密字段 EncryptionKey []byte // encryption key // EncryptionKeyRotationDuration: 加密字段有效时长 EncryptionKeyRotationDuration time.Duration // key rotation duration // BypassLockGuard will bypass the lock guard on badger. Bypassing lock // guard can cause data corruption if multiple badger instances are using // the same directory. Use this options with caution. BypassLockGuard bool // ChecksumVerificationMode decides when db should verify checksums for SSTable blocks. ChecksumVerificationMode options.ChecksumVerificationMode // DetectConflicts determines whether the transactions would be checked for // conflicts. The transactions can be processed at a higher rate when // conflict detection is disabled. // DetectConflicts: 事务的冲突检测 DetectConflicts bool // NamespaceOffset specifies the offset from where the next 8 bytes contains the namespace. NamespaceOffset int // Transaction start and commit timestamps are managed by end-user. // This is only useful for databases built on top of Badger (like Dgraph). // Not recommended for most users. managedTxns bool // 4. Flags for testing purposes // ------------------------------ // 有关批处理的参数 maxBatchCount int64 // max entries in batch maxBatchSize int64 // max batch size in bytes maxValueThreshold float64 } 传入指定的路径，并默认配置信息，如果有需要更改的信息可以使用 WithX() 方法（此处使用了建造者模式）\nbadger.DefaultOptions(\u0026quot;tmp/badger\u0026quot;)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // DefaultOptions sets a list of recommended options for good performance. // Feel free to modify these to suit your needs with the WithX methods. func DefaultOptions(path string) Options { return Options{ Dir: path, ValueDir: path, MemTableSize: 64 \u0026lt;\u0026lt; 20, BaseTableSize: 2 \u0026lt;\u0026lt; 20, BaseLevelSize: 10 \u0026lt;\u0026lt; 20, TableSizeMultiplier: 2, LevelSizeMultiplier: 10, MaxLevels: 7, NumGoroutines: 8, MetricsEnabled: true, NumCompactors: 4, // Run at least 2 compactors. Zero-th compactor prioritizes L0. NumLevelZeroTables: 5, NumLevelZeroTablesStall: 15, NumMemtables: 5, BloomFalsePositive: 0.01, BlockSize: 4 * 1024, SyncWrites: false, NumVersionsToKeep: 1, CompactL0OnClose: false, VerifyValueChecksum: false, Compression: options.Snappy, BlockCacheSize: 256 \u0026lt;\u0026lt; 20, IndexCacheSize: 0, // The following benchmarks were done on a 4 KB block size (default block size). The // compression is ratio supposed to increase with increasing compression level but since the // input for compression algorithm is small (4 KB), we don\u0026#39;t get significant benefit at // level 3. // NOTE: The benchmarks are with DataDog ZSTD that requires CGO. Hence, no longer valid. // no_compression-16 10\t502848865 ns/op\t165.46 MB/s\t- // zstd_compression/level_1-16 7\t739037966 ns/op\t112.58 MB/s\t2.93 // zstd_compression/level_3-16 7\t756950250 ns/op\t109.91 MB/s\t2.72 // zstd_compression/level_15-16 1\t11135686219 ns/op\t7.47 MB/s\t4.38 // Benchmark code can be found in table/builder_test.go file ZSTDCompressionLevel: 1, // Nothing to read/write value log using standard File I/O // MemoryMap to mmap() the value log files // (2^30 - 1)*2 when mmapping \u0026lt; 2^31 - 1, max int32. // -1 so 2*ValueLogFileSize won\u0026#39;t overflow on 32-bit systems. ValueLogFileSize: 1\u0026lt;\u0026lt;30 - 1, ValueLogMaxEntries: 1000000, VLogPercentile: 0.0, ValueThreshold: maxValueThreshold, Logger: defaultLogger(INFO), EncryptionKey: []byte{}, EncryptionKeyRotationDuration: 10 * 24 * time.Hour, // Default 10 days. DetectConflicts: true, NamespaceOffset: -1, } } Open函数(核心) badger.Open(opt) 函数\n此方法代码过长,在此只保留核心部分代码,部分逻辑将以伪代码或注释表示,并省去部分错误处理逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 func Open(opt Options) (*DB, error) { // 检查参数 checkAndSetOptions(\u0026amp;opt) // 创建了三个目录锁,防止其他进程注册到同一个目录造成冲突 var dirLockGuard, valueDirLockGuard *directoryLockGuard // Create directories and acquire lock on it only if badger is not running in InMemory mode. // We don\u0026#39;t have any directories/files in InMemory mode so we don\u0026#39;t need to acquire // any locks on them. // 判断参数配置为只基于内存 if !opt.InMemory { // 创建目录 createDirs(opt) var err error if !opt.BypassLockGuard { // 给Dir加目录锁 dirLockGuard, _ = acquireDirectoryLock(opt.Dir, lockFile, opt.ReadOnly) // 方法末尾释放锁 defer func() { if dirLockGuard != nil { _ = dirLockGuard.release() } }() // 获取Key\u0026amp;ValuePtr的绝对路径 absDir, _ := filepath.Abs(opt.Dir) // 获取ValueLog的绝对路径 absValueDir, _ := filepath.Abs(opt.ValueDir) // 如果ValueDir和Dir不相同,需要各自加锁 if absValueDir != absDir { // 给ValueDir加目录锁 valueDirLockGuard, _ = acquireDirectoryLock(opt.ValueDir, lockFile, opt.ReadOnly) // 释放锁 defer func() { if valueDirLockGuard != nil { _ = valueDirLockGuard.release() } }() } } } // 打开或创建Manifest文件,(采用mmap方式打开,在后面详细展开) manifestFile, manifest, _ := openOrCreateManifestFile(opt) // 关闭Manifest文件 defer func() { if manifestFile != nil { _ = manifestFile.close() } }() // 创建内存中的db数据结构 db := \u0026amp;DB{ // memtable, 因为有多个,所以要创建数组 imm: make([]*memTable, 0, opt.NumMemtables), // 刷新请求的channel flushChan: make(chan flushTask, opt.NumMemtables), // 写请求的channel writeCh: make(chan *request, kvWriteChCapacity), // 配置信息opt opt: opt, // 刚初始化好的manifest实例 manifest: manifestFile, // Key\u0026amp;ValuePtr目录锁 dirLockGuard: dirLockGuard, // Value目录锁 valueDirGuard: valueDirLockGuard, // Oracle的实例,一个KV引擎并发事务的管理器,负责分配事务的版本号,用来实现MVCC功能,在读写事务时详细展开 orc: newOracle(opt), pub: newPublisher(), allocPool: z.NewAllocatorPool(8), bannedNamespaces: \u0026amp;lockedKeys{keys: make(map[uint64]struct{})}, threshold: initVlogThreshold(\u0026amp;opt), } // Cleanup all the goroutines started by badger in case of an error. // 关闭badger的所有任务协程的钩子函数 defer func() { if err != nil { opt.Errorf(\u0026#34;Received err: %v. Cleaning up...\u0026#34;, err) db.cleanup() db = nil } }() // 块缓存相关配置 // LSM-T结构中SST里面数据是以块(block)为单位分割的 // 当开启块缓存之后,LSM-T会把最近被访问到的高热的块缓存在内存中,以加块响应速度 if opt.BlockCacheSize \u0026gt; 0 { // 缓存不在此次源码阅读的讨论范围之内,不影响核心功能,暂且略过 // 值得一提的是badger是使用的缓存是badger社区研发的一个高性能本地并发缓存的库,有兴趣的同学可以自行研究 numInCache := opt.BlockCacheSize / int64(opt.BlockSize) if numInCache == 0 { // Make the value of this variable at least one since the cache requires // the number of counters to be greater than zero. numInCache = 1 } config := ristretto.Config{ NumCounters: numInCache * 8, MaxCost: opt.BlockCacheSize, BufferItems: 64, Metrics: true, OnExit: table.BlockEvictHandler, } db.blockCache, err = ristretto.NewCache(\u0026amp;config) if err != nil { return nil, y.Wrap(err, \u0026#34;failed to create data cache\u0026#34;) } } // 索引缓存相关配置 // 索引是每个Key所对应的偏离量的值,每一个SSTable有一个元数据块即索引块 // 可以方便对Key的二分查找,定位当前的key在哪一个sstable文件里,在文件中的偏移量是多少 if opt.IndexCacheSize \u0026gt; 0 { // Index size is around 5% of the table size. indexSz := int64(float64(opt.MemTableSize) * 0.05) numInCache := opt.IndexCacheSize / indexSz if numInCache == 0 { // Make the value of this variable at least one since the cache requires // the number of counters to be greater than zero. numInCache = 1 } config := ristretto.Config{ NumCounters: numInCache * 8, MaxCost: opt.IndexCacheSize, BufferItems: 64, Metrics: true, } db.indexCache, err = ristretto.NewCache(\u0026amp;config) if err != nil { return nil, y.Wrap(err, \u0026#34;failed to create bf cache\u0026#34;) } } // 对缓存模块的监控检测 db.closers.cacheHealth = z.NewCloser(1) go db.monitorCache(db.closers.cacheHealth) // 如果仅基于内存 if db.opt.InMemory { // 默认关闭写同步 db.opt.SyncWrites = false // If badger is running in memory mode, push everything into the LSM Tree. // 把所有数据只写在LSM-T中 db.opt.ValueThreshold = math.MaxInt32 } // Key的注册,与并发事务相关,之后再详细展开 krOpt := KeyRegistryOptions{ ReadOnly: opt.ReadOnly, Dir: opt.Dir, EncryptionKey: opt.EncryptionKey, EncryptionKeyRotationDuration: opt.EncryptionKeyRotationDuration, InMemory: opt.InMemory, } db.registry, _ = OpenKeyRegistry(krOpt) // 计算消耗的内存等数据统计信息 db.calculateSize() db.closers.updateSize = z.NewCloser(1) go db.updateSize(db.closers.updateSize) // 打开一个memTable实例 // memtable是在内存中的一个复杂数据结构 if err := db.openMemTables(db.opt); err != nil { return nil, y.Wrapf(err, \u0026#34;while opening memtables\u0026#34;) } // 检查 if !db.opt.ReadOnly { // 创建一个新的.mem文件 // .mem文件就是LSM-T中的预写日志文件(wal) if db.mt, err = db.newMemTable(); err != nil { return nil, y.Wrapf(err, \u0026#34;cannot create memtable\u0026#34;) } } // newLevelsController potentially loads files in directory. // 创建内存中level管理器 // LSM-T是分层结构的, LevelsController实例负责维护整个层级结构 // 进行日志归并,压缩处理等操作,通过Manifest进行初始配置 // 或者是,manifest文件就是LevelController持久化之后的ondisk版本,可以加快badger的恢复重启速度 // 先打开SSTable,加载索引块,元数据块,缓存到内存当中 if db.lc, err = newLevelsController(db, \u0026amp;manifest); err != nil { return db, err } // Initialize vlog struct. // 初始化vlog db.vlog.init(db) if !opt.ReadOnly { // 启动日志归并的工作协程,后续再展开 db.closers.compactors = z.NewCloser(1) db.lc.startCompact(db.closers.compactors) db.closers.memtable = z.NewCloser(1) go func() { _ = db.flushMemtable(db.closers.memtable) // Need levels controller to be up. }() // Flush them to disk asap. for _, mt := range db.imm { db.flushChan \u0026lt;- flushTask{mt: mt} } } // We do increment nextTxnTs below. So, no need to do it here. // 拿到启动时最大事务的版本号(时间戳) db.orc.nextTxnTs = db.MaxVersion() db.opt.Infof(\u0026#34;Set nextTxnTs to %d\u0026#34;, db.orc.nextTxnTs) // 真正打开vlog文件 if err = db.vlog.open(db); err != nil { return db, y.Wrapf(err, \u0026#34;During db.vlog.open\u0026#34;) } // Let\u0026#39;s advance nextTxnTs to one more than whatever we observed via // replaying the logs. // 事务相关,等待之前事务的恢复 db.orc.txnMark.Done(db.orc.nextTxnTs) // In normal mode, we must update readMark so older versions of keys can be removed during // compaction when run in offline mode via the flatten tool. db.orc.readMark.Done(db.orc.nextTxnTs) // 事务号自增 db.orc.incrementNextTs() // 监听配置信息的更改 go db.threshold.listenForValueThresholdUpdate() // 从数据库中检索被禁止的命名空间并更新内存结构(非重点) if err := db.initBannedNamespaces(); err != nil { return db, errors.Wrapf(err, \u0026#34;While setting banned keys\u0026#34;) } // 启动处理磁盘写请求的协程 // badger的写任务是并发写任务,可以充分发挥ssd的性能 db.closers.writes = z.NewCloser(1) go db.doWrites(db.closers.writes) if !db.opt.InMemory { // 真正开启vlog的GC, 后面再详细讲解 db.closers.valueGC = z.NewCloser(1) go db.vlog.waitOnGC(db.closers.valueGC) } // 监听协程(非重点) db.closers.pub = z.NewCloser(1) go db.pub.listenForUpdates(db.closers.pub) // 释放锁 valueDirLockGuard = nil dirLockGuard = nil manifestFile = nil // 返回db return db, nil } 创建Manifest文件 openOrCreateManifestFile(opt) 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 func openOrCreateManifestFile(opt Options) (ret *manifestFile, result Manifest, err error) { // 如果Inmemory则返回空的Manifest if opt.InMemory { return \u0026amp;manifestFile{inMemory: true}, Manifest{}, nil } return helpOpenOrCreateManifestFile(opt.Dir, opt.ReadOnly, manifestDeletionsRewriteThreshold) } func helpOpenOrCreateManifestFile(dir string, readOnly bool, deletionsThreshold int) (*manifestFile, Manifest, error) { // 拼接path path := filepath.Join(dir, ManifestFilename) var flags y.Flags if readOnly { flags |= y.ReadOnly } // 尝试打开文件 fp, err := y.OpenExistingFile(path, flags) // We explicitly sync in addChanges, outside the lock. if err != nil { // 校验文件是否存在 if !os.IsNotExist(err) { return nil, Manifest{}, err } // 如果仅读则无法创建直接返回 if readOnly { return nil, Manifest{}, fmt.Errorf(\u0026#34;no manifest found, required for read-only db\u0026#34;) } // 真正创建manifest实例 m := createManifest() // 覆盖写,执行完此条语句后就可以在目录中看到MANIFEST文件存在了(此时MANIFEST文件中仅有魔数bdg) fp, netCreations, _ := helpRewrite(dir, \u0026amp;m) // 断言,确保创建成功 y.AssertTrue(netCreations == 0) // 创建manifestFile实例在内存中保存信息 mf := \u0026amp;manifestFile{ fp: fp, directory: dir, manifest: m.clone(), deletionsRewriteThreshold: deletionsThreshold, } return mf, m, nil } // 文件存在加载恢复的逻辑暂不展开 ...... } func createManifest() Manifest { levels := make([]levelManifest, 0) return Manifest{ Levels: levels, Tables: make(map[uint64]TableManifest), } // Tables: map[uint64]TableManifest // uint64: 行号,第n个level } 打开Memtable memtable 结构体\n1 2 3 4 5 6 7 8 9 10 // memTable structure stores a skiplist and a corresponding WAL. Writes to memTable are written // both to the WAL and the skiplist. On a crash, the WAL is replayed to bring the skiplist back to // its pre-crash form. type memTable struct { sl *skl.Skiplist wal *logFile maxVersion uint64 opt Options buf *bytes.Buffer } openMemTables(opt) 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 func (db *DB) openMemTables(opt Options) error { // We don\u0026#39;t need to open any tables in in-memory mode. // 如果是只基于内存则直接返回(那我走?) if db.opt.InMemory { return nil } // 读取目录中的全部文件 files, _ := ioutil.ReadDir(db.opt.Dir) var fids []int // 遍历目录中的文件 for _, file := range files { // 检查当前文件名是否包含一个.mem的后缀(在第一次初始化过程中肯定不会存在) // 此时目录中应有的文件为 LOCK MANIFEST KEYREGISTRY if !strings.HasSuffix(file.Name(), memFileExt) { continue } // 如果有.mem文件,则取文件的命名转为int值作为fid // 例: 000001.mem 000002.mem fsz := len(file.Name()) fid, _ := strconv.ParseInt(file.Name()[:fsz-len(memFileExt)], 10, 64) fids = append(fids, int(fid)) } // Sort in ascending order. // 按照fid排序 sort.Slice(fids, func(i, j int) bool { return fids[i] \u0026lt; fids[j] }) // 按照fid顺序遍历 for _, fid := range fids { flags := os.O_RDWR if db.opt.ReadOnly { flags = os.O_RDONLY } // 真正的打开.mem文件,采用mmap方式加载.mem文件中的数据 mt, err := db.openMemTable(fid, flags) if err != nil { return y.Wrapf(err, \u0026#34;while opening fid: %d\u0026#34;, fid) } // If this memtable is empty we don\u0026#39;t need to add it. This is a // memtable that was completely truncated. if mt.sl.Empty() { mt.DecrRef() continue } // These should no longer be written to. So, make them part of the imm. db.imm = append(db.imm, mt) } // 设置最新的fid序列号 if len(fids) != 0 { db.nextMemFid = fids[len(fids)-1] } db.nextMemFid++ return nil } 创建Memtable newMemTable() 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 func (db *DB) newMemTable() (*memTable, error) { // 真正创建.mem文件 mt, err := db.openMemTable(db.nextMemFid, os.O_CREATE|os.O_RDWR) if err == z.NewFile { db.nextMemFid++ return mt, nil } if err != nil { db.opt.Errorf(\u0026#34;Got error: %v for id: %d\\n\u0026#34;, err, db.nextMemFid) return nil, y.Wrapf(err, \u0026#34;newMemTable\u0026#34;) } return nil, errors.Errorf(\u0026#34;File %s already exists\u0026#34;, mt.wal.Fd.Name()) } openMemTable(fid, flags) 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 func (db *DB) openMemTable(fid, flags int) (*memTable, error) { // 拼接路径 filepath := db.mtFilePath(fid) // 创建memtable中的skiplist s := skl.NewSkiplist(arenaSize(db.opt)) // 创建memtable实例 mt := \u0026amp;memTable{ sl: s, opt: db.opt, buf: \u0026amp;bytes.Buffer{}, } // We don\u0026#39;t need to create the wal for the skiplist in in-memory mode so return the mt. // 如果只基于内存,则不需要创建wal文件,直接返回 if db.opt.InMemory { return mt, z.NewFile } // 创建wal文件实例 mt.wal = \u0026amp;logFile{ fid: uint32(fid), path: filepath, registry: db.registry, writeAt: vlogHeaderSize, opt: db.opt, } // 调用系统函数创建wal文件 lerr := mt.wal.open(filepath, flags, 2*db.opt.MemTableSize) // 如果未成功创建新文件或其他失败则返回err if lerr != z.NewFile \u0026amp;\u0026amp; lerr != nil { return nil, y.Wrapf(lerr, \u0026#34;While opening memtable: %s\u0026#34;, filepath) } // Have a callback set to delete WAL when skiplist reference count goes down to zero. That is, // when it gets flushed to L0. // 用来关闭的回调函数 s.OnClose = func() { if err := mt.wal.Delete(); err != nil { db.opt.Errorf(\u0026#34;while deleting file: %s, err: %v\u0026#34;, filepath, err) } } // 成功创建mmap则返回 lerr (z.NewFile) if lerr == z.NewFile { return mt, lerr } // 当且仅当MemTableSize设置为0时造成 lerr == nil的适合执行到此 // 此时mmap未进行截断,在UpdateSkipList()中遍历wal文件并重新截断,如果wal文件不存在会返回错误 err := mt.UpdateSkipList() return mt, y.Wrapf(err, \u0026#34;while updating skiplist\u0026#34;) } 创建levelController newLevelsController(db, mf) 函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 func newLevelsController(db *DB, mf *Manifest) (*levelsController, error) { // 断言,进行一些必要的校验 y.AssertTrue(db.opt.NumLevelZeroTablesStall \u0026gt; db.opt.NumLevelZeroTables) // 关联db实例,创建level数组对应层级关系(例:levels[0] =\u0026gt; L0层) // levelHandler就是真正负责某一层sst管理器的主要操作 s := \u0026amp;levelsController{ kv: db, levels: make([]*levelHandler, db.opt.MaxLevels), } // 状态统计的一个的对象(set结构),key为fid,用以判断对应的fid是否存在于这一层 s.cstatus.tables = make(map[uint64]struct{}) // 合并状态的信息 s.cstatus.levels = make([]*levelCompactStatus, db.opt.MaxLevels) // 按层遍历,每一层都创建一个levelhandler实例 for i := 0; i \u0026lt; db.opt.MaxLevels; i++ { s.levels[i] = newLevelHandler(db, i) s.cstatus.levels[i] = new(levelCompactStatus) } // 基于内存,那我走?🤡 if db.opt.InMemory { return s, nil } // Compare manifest against directory, check for existent/non-existent files, and remove. // 对manifest文件进行校验 if err := revertToManifest(db, mf, getIDMap(db.opt.Dir)); err != nil { return nil, err } var mu sync.Mutex tables := make([][]*table.Table, db.opt.MaxLevels) var maxFileID uint64 // We found that using 3 goroutines allows disk throughput to be utilized to its max. // Disk utilization is the main thing we should focus on, while trying to read the data. That\u0026#39;s // the one factor that remains constant between HDD and SSD. // 一种针对并发控制的负载均衡策略,对于ssd来说,创建3个协程能够最大的发挥ssd的优点 throttle := y.NewThrottle(3) start := time.Now() var numOpened int32 // 创建一个定时触发器进行超时控制 tick := time.NewTicker(3 * time.Second) // 钩子函数关闭定时器 defer tick.Stop() // manifest清单文件的Tables // 拿到每个table对应的fid // 第一次初始化的适合因为Tables为空,会直接跳过 for fileID, tf := range mf.Tables { fname := table.NewFilename(fileID, db.opt.Dir) select { case \u0026lt;-tick.C: db.opt.Infof(\u0026#34;%d tables out of %d opened in %s\\n\u0026#34;, atomic.LoadInt32(\u0026amp;numOpened), len(mf.Tables), time.Since(start).Round(time.Millisecond)) default: } if err := throttle.Do(); err != nil { closeAllTables(tables) return nil, err } if fileID \u0026gt; maxFileID { maxFileID = fileID } go func(fname string, tf TableManifest) { var rerr error defer func() { throttle.Done(rerr) atomic.AddInt32(\u0026amp;numOpened, 1) }() dk, err := db.registry.DataKey(tf.KeyID) if err != nil { rerr = y.Wrapf(err, \u0026#34;Error while reading datakey\u0026#34;) return } topt := buildTableOptions(db) // Explicitly set Compression and DataKey based on how the table was generated. topt.Compression = tf.Compression topt.DataKey = dk mf, err := z.OpenMmapFile(fname, db.opt.getFileFlags(), 0) if err != nil { rerr = y.Wrapf(err, \u0026#34;Opening file: %q\u0026#34;, fname) return } t, err := table.OpenTable(mf, topt) if err != nil { if strings.HasPrefix(err.Error(), \u0026#34;CHECKSUM_MISMATCH:\u0026#34;) { db.opt.Errorf(err.Error()) db.opt.Errorf(\u0026#34;Ignoring table %s\u0026#34;, mf.Fd.Name()) // Do not set rerr. We will continue without this table. } else { rerr = y.Wrapf(err, \u0026#34;Opening table: %q\u0026#34;, fname) } return } mu.Lock() tables[tf.Level] = append(tables[tf.Level], t) mu.Unlock() }(fname, tf) } // 关闭相关的任务协程 if err := throttle.Finish(); err != nil { closeAllTables(tables) return nil, err } db.opt.Infof(\u0026#34;All %d tables opened in %s\\n\u0026#34;, atomic.LoadInt32(\u0026amp;numOpened), time.Since(start).Round(time.Millisecond)) // 记录当前fid最大值 s.nextFileID = maxFileID + 1 // 初始化每个level的tables for i, tbls := range tables { s.levels[i].initTables(tbls) } // Make sure key ranges do not overlap etc. // 必要的数据校验 if err := s.validate(); err != nil { _ = s.cleanupLevels() return nil, y.Wrap(err, \u0026#34;Level validation\u0026#34;) } // Sync directory (because we have at least removed some files, or previously created the // manifest file). // 手动进行同步刷盘 if err := syncDir(db.opt.Dir); err != nil { _ = s.close() return nil, err } return s, nil } 创建levelHandler newLevelHandler(db, level) 函数\n1 2 3 4 5 6 7 func newLevelHandler(db *DB, level int) *levelHandler { return \u0026amp;levelHandler{ level: level, strLevel: fmt.Sprintf(\u0026#34;l%d\u0026#34;, level), db: db, } } 初始化tables initTables(tables) 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // initTables replaces s.tables with given tables. This is done during loading. func (s *levelHandler) initTables(tables []*table.Table) { // 加锁 s.Lock() defer s.Unlock() // 赋值与相关值的初始化 s.tables = tables s.totalSize = 0 s.totalStaleSize = 0 for _, t := range tables { s.addSize(t) } // 如果是L0层,需要拿每个fid排序 if s.level == 0 { // Key range will overlap. Just sort by fileID in ascending order // because newer tables are at the end of level 0. sort.Slice(s.tables, func(i, j int) bool { return s.tables[i].ID() \u0026lt; s.tables[j].ID() }) } else { // L0层往上,拿每个table文件的MinKey排序 // Sort tables by keys. sort.Slice(s.tables, func(i, j int) bool { return y.CompareKeys(s.tables[i].Smallest(), s.tables[j].Smallest()) \u0026lt; 0 }) } } 初始化vlog init(db) 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // init initializes the value log struct. This initialization needs to happen // before compactions start. func (vlog *valueLog) init(db *DB) { // 加载配置 vlog.opt = db.opt vlog.db = db // We don\u0026#39;t need to open any vlog files or collect stats for GC if DB is opened // in InMemory mode. InMemory mode doesn\u0026#39;t create any files/directories on disk. // inmem,那我走?🤡 if vlog.opt.InMemory { return } // 指定的vlog目录 vlog.dirPath = vlog.opt.ValueDir // GC模块用到的channel vlog.garbageCh = make(chan struct{}, 1) // Only allow one GC at a time. // 创建一个GC模块相关文件 lf, err := InitDiscardStats(vlog.opt) y.Check(err) vlog.discardStats = lf } 打开vlog open(db) 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 func (vlog *valueLog) open(db *DB) error { // We don\u0026#39;t need to open any vlog files or collect stats for GC if DB is opened // in InMemory mode. InMemory mode doesn\u0026#39;t create any files/directories on disk. // 不想再做解释了,inmem,那我走!!! if db.opt.InMemory { return nil } // 填充文件fid到filesMap if err := vlog.populateFilesMap(); err != nil { return err } // If no files are found, then create a new file. // 如果没有.vlog文件 if len(vlog.filesMap) == 0 { if vlog.opt.ReadOnly { return nil } // 创建一个.vlog文件 _, err := vlog.createVlogFile() return y.Wrapf(err, \u0026#34;Error while creating log file in valueLog.open\u0026#34;) } fids := vlog.sortedFids() for _, fid := range fids { lf, ok := vlog.filesMap[fid] y.AssertTrue(ok) // Just open in RDWR mode. This should not create a new log file. lf.opt = vlog.opt if err := lf.open(vlog.fpath(fid), os.O_RDWR, 2*vlog.opt.ValueLogFileSize); err != nil { return y.Wrapf(err, \u0026#34;Open existing file: %q\u0026#34;, lf.path) } // We shouldn\u0026#39;t delete the maxFid file. if lf.size == vlogHeaderSize \u0026amp;\u0026amp; fid != vlog.maxFid { vlog.opt.Infof(\u0026#34;Deleting empty file: %s\u0026#34;, lf.path) if err := lf.Delete(); err != nil { return y.Wrapf(err, \u0026#34;while trying to delete empty file: %s\u0026#34;, lf.path) } delete(vlog.filesMap, fid) } } if vlog.opt.ReadOnly { return nil } // Now we can read the latest value log file, and see if it needs truncation. We could // technically do this over all the value log files, but that would mean slowing down the value // log open. last, ok := vlog.filesMap[vlog.maxFid] y.AssertTrue(ok) lastOff, err := last.iterate(vlog.opt.ReadOnly, vlogHeaderSize, func(_ Entry, vp valuePointer) error { return nil }) if err != nil { return y.Wrapf(err, \u0026#34;while iterating over: %s\u0026#34;, last.path) } if err := last.Truncate(int64(lastOff)); err != nil { return y.Wrapf(err, \u0026#34;while truncating last value log file: %s\u0026#34;, last.path) } // Don\u0026#39;t write to the old log file. Always create a new one. if _, err := vlog.createVlogFile(); err != nil { return y.Wrapf(err, \u0026#34;Error while creating log file in valueLog.open\u0026#34;) } return nil } populateFilesMap() 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 func (vlog *valueLog) populateFilesMap() error { vlog.filesMap = make(map[uint32]*logFile) // 从目录中拿到每个文件的句柄 files, _ := ioutil.ReadDir(vlog.dirPath) found := make(map[uint64]struct{}) for _, file := range files { // 判断是否以.vlog作为后缀 if !strings.HasSuffix(file.Name(), \u0026#34;.vlog\u0026#34;) { continue } // 对.vlog文件进行校验,去除fid,进行消重判断 fsz := len(file.Name()) fid, err := strconv.ParseUint(file.Name()[:fsz-5], 10, 32) if err != nil { return errFile(err, file.Name(), \u0026#34;Unable to parse log id.\u0026#34;) } if _, ok := found[fid]; ok { return errFile(err, file.Name(), \u0026#34;Duplicate file found. Please delete one.\u0026#34;) } found[fid] = struct{}{} lf := \u0026amp;logFile{ fid: uint32(fid), path: vlog.fpath(uint32(fid)), registry: vlog.db.registry, } // 最后保存到vlog的filesMap当中 vlog.filesMap[uint32(fid)] = lf if vlog.maxFid \u0026lt; uint32(fid) { vlog.maxFid = uint32(fid) } } // 直到每个.vlog文件的fid都添加到了map中 // 第一次初始化时没有.vlog文件,故直接跳过 return nil } 创建vlog文件 createVlogFile() 方法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 func (vlog *valueLog) createVlogFile() (*logFile, error) { // 最大的fid fid := vlog.maxFid + 1 // 根据fid命名 path := vlog.fpath(fid) // 创建一个句柄实例 lf := \u0026amp;logFile{ fid: fid, path: path, registry: vlog.db.registry, writeAt: vlogHeaderSize, opt: vlog.opt, } // 进行系统调用打开文件,通过mmap的方式 // .vlog文件初始化时会创建一个2G的文件 err := lf.open(path, os.O_RDWR|os.O_CREATE|os.O_EXCL, 2*vlog.opt.ValueLogFileSize) if err != z.NewFile \u0026amp;\u0026amp; err != nil { return nil, err } // 进行数据初始化更新的操作 vlog.filesLock.Lock() vlog.filesMap[fid] = lf y.AssertTrue(vlog.maxFid \u0026lt; fid) vlog.maxFid = fid // writableLogOffset is only written by write func, by read by Read func. // To avoid a race condition, all reads and updates to this variable must be // done via atomics. atomic.StoreUint32(\u0026amp;vlog.writableLogOffset, vlogHeaderSize) vlog.numEntriesWritten = 0 vlog.filesLock.Unlock() return lf, nil } 小结 通过本章，我们走上了Badger源码路上的第一步，了解了一个LSM-T结构的存储引擎初始化时都要做哪些准备\n","date":"2022-11-18T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/badger-cr.png","permalink":"https://Kirov7.github.io/p/badger%E6%BA%90%E7%A0%81%E5%AF%BC%E8%AF%BB%E4%B8%80-db%E5%88%9D%E5%A7%8B%E5%8C%96/","title":"Badger源码导读(一) DB初始化"},{"content":"快读了解HDD与SSD的基本原理 作为MIS专业的小弱鸡，对硬件组成的了解并不深入，而本人正在学习LSM-T结构的存储引擎，发现有些内容一定是要对硬件有所了解之后才能又更好的认知，比如在阅读了LSM-T的经典开山论文后，有了解到LSM-T结构化随机写为顺序写的特性，可以契合HDD的特点可以极大的加快磁盘写入的速度。而在Wiskey论文中，又提出了对SSD友好的KV分离式存储结构，并通过并行读取最大化发挥SSD的优势。逐渐意识到，在软件性能上再多的优化都是建立在硬件之上的，而底层硬件的改变可能对整体的性能产生极大的质变，所以，还是很有必要对存储硬件有些基本的学习与认知。\n因为本人有尖端恐惧症，看电子元器件的针脚等精细尖锐的东西会产生比较强烈的生理不适感，故曾经发誓绝对不会去做硬件相关的东西 XD\n本篇文章部分整理自网络资料，供个人学习记录与分享，有任何问题请及时指出，若有侵权立即删除\n机械硬盘工作原理 机械硬盘的内部结构主要由马达、磁盘、磁头臂、磁头组成。\n机械硬盘在工作的时候，磁头会悬浮于磁盘面上方几纳米的距离。磁盘面上有很多的小格子，小格子内有很多的小磁粒。\n这些磁盘上的磁粒有一定的极性，当磁粒极性朝下的时候记为0，磁粒极性朝上的时候记为1，这样磁头就可以通过识别磁盘磁粒的极性读取数据了。\n而磁头也可以利用其变化的磁场改变磁盘磁粒的极性，这样就做到写入和改写磁盘数据了。\n为了能够精准定位数据所在磁盘面上的位置，磁盘本身又被划分了无数的扇区和磁道。\n假设：\n数据存放在磁盘的第五磁道的第七扇区上：\n那磁头就会先摆动到第五磁道上空，然后等待第七扇区转过来当第七扇区转到磁头下面的时候，才可以读取数据。\n这就是机械硬盘的工作原理，也正是因为机械硬盘是利用磁性极粒来存储数据的，所以机械硬盘通常又被称作磁盘。\n而固态硬盘同机械硬盘的工作原理完全不同，固态硬盘采用纯电子结构。\n固态硬盘工作原理 固态硬盘存储数据的基本单元叫浮栅晶体管，基本结构有：存储电子的浮栅层，控制极G、衬底P、源极D与漏极S。\n我们将浮栅层中的电子数量高于一定值计为0，低于一定值计为1。\n那固态硬盘具体是如何工作的呢？接着往下看。\n写入数据 写入数据时，需要在控制极G施加一个高压，这样电子就可以穿过隧穿层，进入浮栅层，因为有绝缘层的存在，电子不能再向前移动了，就被囚禁在了浮栅层。\n而当我们把电压撤去，这些电子依然会被囚禁在浮栅层，因为隧穿层本质上也相当于绝缘体，所以电子们只能被关押着，这样一位数据就被存储进去了。\n**这些电子能被“囚禁”多长时间也就是固态硬盘能够存储数据的年限，一般一块新的固态硬盘能够保存数据的年限为10年。**因为随着时间的流逝，不断地有电子“越狱”成功。\n等“越狱”的电子多到一定的数量，我们保存的数据就不见了。\n读取数据 关于它读取数据的原理也非常简单。\n当浮栅层中不存在电子时（存储数据为1），我们给控制级一个低压，由于电压低，电子只能被吸引到靠近隧穿层的位置，却无法穿过隧穿层，因而源极漏极可以导通，形成电流。\n如果检测到电流，那么说明它没有储存电子，则读取数据为1。\n当浮栅层中存在电子时（存储数据为0），我们还给控制极一个低压，由于浮栅层里面的电子对这些电子有排斥作用，所以电子无法被吸引到靠近隧穿层的位置，源极漏极不会导通，不会形成电流。\n如果无法检测到电流，那么说明浮栅层储存一定量电子，则读取数据为0。\n无数的浮栅晶体管堆叠在一块就可以存储大量的0和1，它们就类似于图书馆当中的书架一样，存储着无限的0101数据。\n相对于机械硬盘这种机械结构，固态硬盘这种纯电子结构在存取速度方面的优势就非常突出。\n总结 在机械硬盘在读取数据之前，需要先摆动磁头臂到对应的磁道上方，再等待对应的扇区转过来。\n尽管目前的机械硬盘大部分都是7200转/分钟或者5400转/分钟的，看起来已经很快了，但是这两个操作依然会导致大约十几毫秒的延迟。\n这种延迟对于人类来讲确实微不足道，但是对于计算机内存和CPU来讲，就确实会产生显著影响。\n而固态硬盘全程都是电子交互，电子信号的速度要远超磁头臂和磁盘这种机械结构。\n如果你的数据是随机分散在磁盘的各个角落，那机械硬盘需要经过多次的寻道和寻址，多次等待扇区转动到磁头底下，所以机械硬盘在读取分散性文件的时候，性能就显得非常弱，速度很慢，即随机读写性能低下。\n","date":"2022-10-17T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/20230218223854.png","permalink":"https://Kirov7.github.io/p/%E5%BF%AB%E8%AF%BB%E4%BA%86%E8%A7%A3hdd%E4%B8%8Essd%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%8E%9F%E7%90%86/","title":"快读了解HDD与SSD的基本原理"},{"content":"由于最近在看一些IM系统相关的内容，学习到了webSocket协议，感觉很有意思，但是感觉感觉网上没有找到很清晰描述webSocket的文章，故有此篇，文章整理了网络上的一些资料并加上我的个人理解，如有错误，欢迎指出\nWebSocket WebSocket是一种网络传输协议，可在单个TCP连接上进行全双工通信，WebSocket使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。在WebSocket API中，浏览器和服务器只需要完成一次握手，两者之间就可以建立持久性的连接，并进行双向数据传输。WebSocket是为了在浏览器中使用长连接而定义的协议。因此，它是在http超文本传输协议的基础上升级而来，Http和WebSocket协议都是基于TCP协议的。\nWebSocket 与 HTTP/2 一样，都是为了解决 HTTP 某方面的缺陷而诞生的。HTTP/2 针对的是“队头阻塞”，而 WebSocket 针对的是“请求 - 应答”通信模式。\n那么，“请求 - 应答”有什么不好的地方呢？\n“请求 - 应答”是一种“半双工”的通信模式，虽然可以双向收发数据，但同一时刻只能一个方向上有动作，传输效率低。更关键的一点，它是一种“被动”通信模式，服务器只能“被动”响应客户端的请求，无法主动向客户端发送数据。\n虽然后来的 HTTP/2、HTTP/3 新增了 Stream、Server Push 等特性，但“请求 - 应答”依然是主要的工作方式。这就导致 HTTP 难以应用在动态页面、即时消息、网络游戏等要求“实时通信”的领域。\n在 WebSocket 出现之前，在浏览器环境里用 JavaScript 开发实时 Web 应用很麻烦。因为浏览器是一个“受限的沙盒”，不能用 TCP，只有 HTTP 协议可用，所以就出现了很多“变通”的技术，“轮询”（polling）就是比较常用的的一种。\n简单地说，轮询就是不停地向服务器发送 HTTP 请求，问有没有数据，有数据的话服务器就用响应报文回应。如果轮询的频率比较高，那么就可以近似地实现“实时通信”的效果。\n但轮询的缺点也很明显，反复发送无效查询请求耗费了大量的带宽和 CPU 资源，非常不经济。\n所以，为了克服 HTTP“请求 - 应答”模式的缺点，WebSocket 就“应运而生”了。它原来是 HTML5 的一部分，后来“自立门户”，形成了一个单独的标准，RFC 文档编号是 6455。\nWebSocket 采用了二进制帧结构，语法、语义与 HTTP 完全不兼容，但因为它的主要运行环境是浏览器，为了便于推广和应用，就不得不“搭便车”，在使用习惯上尽量向 HTTP 靠拢，这就是它名字里“Web”的含义。\n服务发现方面，WebSocket 没有使用 TCP 的“IP 地址 + 端口号”，而是延用了 HTTP 的 URI 格式，但开头的协议名不是“http”，引入的是两个新的名字：“ws”和“wss”，分别表示明文和加密的 WebSocket 协议。\nWebSocket 的默认端口也选择了 80 和 443，因为现在互联网上的防火墙屏蔽了绝大多数的端口，只对 HTTP 的 80、443 端口“放行”，所以 WebSocket 就可以“伪装”成 HTTP 协议，比较容易地“穿透”防火墙，与服务器建立连接。\nWebSocket 协议格式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ WebSocket 和 HTTP/2 的关注点不同，WebSocket 更侧重于“实时通信”，而 HTTP/2 更侧重于提高传输效率，所以两者的帧结构也有很大的区别。\nWebSocket 虽然有“帧”，但却没有像 HTTP/2 那样定义“流”，也就不存在“多路复用”“优先级”等复杂的特性，而它自身就是“全双工”的，也就不需要“服务器推送”。所以综合起来，WebSocket 的帧学习起来会简单一些。\n上面就是 WebSocket 的帧结构定义，长度不固定，最少 2 个字节，最多 14 字节，看着好像很复杂，实际非常简单。\n开头的两个字节是必须的，也是最关键的。\n第一个字节的第一位“FIN”是消息结束的标志位，相当于 HTTP/2 里的“END_STREAM”，表示数据发送完毕。一个消息可以拆成多个帧，接收方看到“FIN”后，就可以把前面的帧拼起来，组成完整的消息。\n“FIN”后面的三个位是保留位，目前没有任何意义，但必须是 0。\n第一个字节的后 4 位很重要，叫“Opcode”，操作码，其实就是帧类型，比如 1 表示帧内容是纯文本，2 表示帧内容是二进制数据，8 是关闭连接，9 和 10 分别是连接保活的 PING 和 PONG。\n第二个字节第一位是掩码标志位“MASK”，表示帧内容是否使用异或操作（xor）做简单的加密。目前的 WebSocket 标准规定，客户端发送数据必须使用掩码，而服务器发送则必须不使用掩码。\n第二个字节后 7 位是“Payload len”，表示帧内容的长度。它是另一种变长编码，最少 7 位，最多是 7+64 位，也就是额外增加 8 个字节，所以一个 WebSocket 帧最大是 2^64。\n长度字段后面是“Masking-key”，掩码密钥，它是由上面的标志位“MASK”决定的，如果使用掩码就是 4 个字节的随机数，否则就不存在。\n这么分析下来，其实 WebSocket 的帧头就四个部分：“结束标志位 + 操作码 + 帧长度 + 掩码”，只是使用了变长编码的“小花招”，不像 HTTP/2 定长报文头那么简单明了。\nWebSocket 握手 和 TCP、TLS 一样，WebSocket 也要有一个握手过程，然后才能正式收发数据。\n这里它还是搭上了 HTTP 的“便车”，利用了 HTTP 本身的“协议升级”特性，“伪装”成 HTTP，这样就能绕过浏览器沙盒、网络防火墙等等限制，这也是 WebSocket 与 HTTP 的另一个重要关联点。\nWebSocket 的握手是一个标准的 HTTP GET 请求，但要带上两个协议升级的专用头字段：\n“Connection: Upgrade”，表示要求协议“升级”；\n“Upgrade: websocket”，表示要“升级”成 WebSocket 协议。\n另外，为了防止普通的 HTTP 消息被“意外”识别成 WebSocket，握手消息还增加了两个额外的认证用头字段（所谓的“挑战”，Challenge）：\nSec-WebSocket-Key：一个 Base64 编码的 16 字节随机数，作为简单的认证密钥； Sec-WebSocket-Version：协议的版本号，当前必须是 13。 来自客户端的握手如下所示：\n1 2 3 4 5 6 7 8 GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== Origin: http://example.com Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 服务器收到 HTTP 请求报文，看到上面的四个字段，就知道这不是一个普通的 GET 请求，而是 WebSocket 的升级请求，于是就不走普通的 HTTP 处理流程，而是构造一个特殊的“101 Switching Protocols”响应报文，通知客户端，接下来就不用 HTTP 了，全改用 WebSocket 协议通信。（有点像 TLS 的“Change Cipher Spec”）\nWebSocket 的握手响应报文也是有特殊格式的，要用字段“Sec-WebSocket-Accept”验证客户端请求报文，同样也是为了防止误连接。\n具体的做法是把请求头里“Sec-WebSocket-Key”的值，加上一个专用的 UUID “258EAFA5-E914-47DA-95CA-C5AB0DC85B11”，再计算 SHA-1 摘要。\n1 encode_base64(sha1(Sec-WebSocket-Key + \u0026#39;258EAFA5-E914-47DA-95CA-C5AB0DC85B11\u0026#39; )) 客户端收到响应报文，就可以用同样的算法，比对值是否相等，如果相等，就说明返回的报文确实是刚才握手时连接的服务器，认证成功。返回握手信息。\n握手完成，后续传输的数据就不再是 HTTP 报文，而是 WebSocket 格式的二进制帧了。\n来自服务器的握手如下所示:\n1 2 3 4 5 HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= Sec-WebSocket-Protocol: chat 大致意思就是告诉服务器，我要升级为websocket长连，如果服务器同意，就必须返回101状态，告诉客户端，升级成功。\n服务器不可返回200状态码\n总结 浏览器是一个“沙盒”环境，有很多的限制，不允许建立 TCP 连接收发数据，而有了 WebSocket，我们就可以在浏览器里与服务器直接建立“TCP 连接”，获得更多的自由。\n不过自由也是有代价的，WebSocket 虽然是在应用层，但使用方式却与“TCP Socket”差不多，过于“原始”，用户必须自己管理连接、缓存、状态，开发上比 HTTP 复杂的多，所以是否要在项目中引入 WebSocket 必须慎重考虑。\nWebSocket 特点：\n全双工通信，相当于对 TCP 做了一层“薄薄的包装”，让它运行在浏览器环境里。 WebSocket 使用二进制帧，结构比较简单，特殊的地方是有个“掩码”操作，客户端发数据必须掩码，服务器则不用。 Websocket与HTTP和HTTPS使用相同的TCP端口，可以绕过大多数防火墙的限制。 Websocket协议使用80端口；运行在TLS之上时，默认使用443端口。 协议头大小可变，节省空间。 opcode：自带心跳ping/pong协议码。 相比TCP缺点：\n增加了协议头，对流量有一点影响。 客户端发送数据载体时必须做一个编码(MASK=1)，这会增加cpu负载。 服务端解析HTTP Upgrade头会增加消耗。 tips:\nWebSocket 标准诞生于2011年，HTTP/2 诞生于2015年 WebSocket 不兼容URI后面的 # 标识，需要编码为 %23 WebSocket 强制要求客户端发送数据使用掩码，是为了提供最基本的安全防护，让每次发送的消息都是随机、不可预测的，抵御”缓存中毒“攻击。但如果运行在SSL/TLS上，采用加密通信，那么掩码就没有必要了 WebSocket 协议里的 PING、PONG 帧，对于保持长连接很重要，可以让链路上总有数据在传输，防止被服务器、路由、网关认为是”无效连接“而意外关闭 ","date":"2022-10-11T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/20221111164027.png","permalink":"https://Kirov7.github.io/p/%E9%80%9F%E9%80%9Awebsocket%E5%8D%8F%E8%AE%AE/","title":"速通WebSocket协议"},{"content":"WEB服务端系统架构演进概述 注：本系列内容为个人整理与总结的架构演进的鸟瞰图，其中部分概念的解释由我个人总结得出，仅代表我个人的理解，难免存在纰漏，如有任何问题均可随时提出并指正\n服务端 or 客户端 什么是服务端和客户端，它和前端后端有什么关联和区别\n认识 “服务” 服务，是根据功能抽象出的概念。比如说，处理用户登录信息的认证服务,负责持久化存储数据的数据库服务，以及为了加快查询速度的缓存服务等\n服务、进程、端口？ 端口的主要作用是表示一台计算机中的特定进程所提供的服务。网络中的计算机是通过 IP地址 来代表其身份的，它只能表示某台特定的计算机，但是一台计算机上可以同时提供很多个服务，如数据库服务、FTP服务(文件传输)、Web服务等，我们就通过端口号来区别相同计算机所提供的这些不同的服务，如常见的端口号80表示的是HTTP服务端口，端口号3306是MySQL的默认端口号，端口号8080是Java的开源的流行Web应用服务器Tomcat的默认端口号等。一个IP地址的端口通过16bit进行编号，最多可以有65536个端口，即端口号的取值范围是0 ~ 65535，其中0～1023是被规定好了的，被称作“众所周知的端口”(Well Known Ports)，且在同一台计算机上端口号不能重复，否则，就会产生端口号冲突这样的例外\nGo语言搭建一个最简单的Web服务器 http://120.48.87.191:9999\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func IndexHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintln(w, \u0026#34;hello world\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, IndexHandler) http.ListenAndServe(\u0026#34;:9999\u0026#34;, nil) } 前端后端，分？还是不分？ 我们所说的前后端分离到底是什么样的\n前后端一体模板引擎渲染方式的架构示例：\n现流行的前后端分离式架构示例：CSR\n前后端分离的优势与劣势 优势：\n以实现真正的前后端解耦，优化开发流程，划分职责界限\n减少后端服务器的并发负载压力\n更友好的错误提示\n\u0026hellip;\n劣势：\n前端响应较慢，资源消耗严重，在业务复杂的情况下，一个页面可能要发起多次HTTP请求才能将页面渲染完毕，且在Json返回的数据量比较大的情况下，渲染的十分缓慢，会出现页面卡顿的情况 不利于SEO，搜索引擎的爬虫无法爬下JS异步渲染的数据 为了解决不足，后续在前后端分离的基础上衍生出了引入NodeJS作为中间层的进行服务端渲染的架构方案\u0026hellip;\u0026hellip;\n服务端与客户端的交互 数据传递主要方式：\nform表单 ajax Ajax(Asynchronous JavaScript and XML) 异步JavaScript和XML，一种用于创建快速动态网页的异步刷新技术。通过在后台与服务器进行少量数据交换，AJAX 可以使网页实现异步更新。即可以在不重新加载整个网页的情况下，对网页的某部分进行更新。 数据传递主要格式：\nXML JSON JSON(JavaScript Object Notation,) 是一种轻量级的数据交换格式，采用完全独立于编程语言的文本格式来存储和表示数据。简洁和清晰的层次结构使得 JSON 成为理想的数据交换语言。 易于阅读和编写，同时也易于机器解析和生成，并有效地提升网络传输效率。 前后端 JSON通信API示例 评论列表功能\n接口url：/comments/article/{id}\n请求方式：GET\n请求参数：\n参数名称 参数类型 说明 id long 文章id（路径参数） 返回数据：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 { \u0026#34;success\u0026#34;: true, \u0026#34;code\u0026#34;: 200, \u0026#34;msg\u0026#34;: \u0026#34;success\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;id\u0026#34;: 1, \u0026#34;author\u0026#34;: { \u0026#34;nickname\u0026#34;: \u0026#34;GodLanBo\u0026#34;, \u0026#34;avatar\u0026#34;: \u0026#34;http://tva1.sinaimg.cn/large/005Uj3w8ly1h68mgfr3bcj31hc0u0mz9.jpg\u0026#34;, \u0026#34;id\u0026#34;: 202 }, \u0026#34;content\u0026#34;: \u0026#34;很久没和朋友去唱歌了🎤，一下午嗓子都莫得了「=。=」\u0026#34;, \u0026#34;childrens\u0026#34;: [ { \u0026#34;id\u0026#34;: 2, \u0026#34;author\u0026#34;: { \u0026#34;nickname\u0026#34;: \u0026#34;群垫底\u0026#34;, \u0026#34;avatar\u0026#34;: \u0026#34;http://tva1.sinaimg.cn/large/005Uj3w8ly1h68mgfr3bcj31hc0u0mz9.jpg\u0026#34;, \u0026#34;id\u0026#34;: 203 }, \u0026#34;content\u0026#34;: \u0026#34;和朋友一起玩桌游，简简单单四个角色，玩不腻=。=\u0026#34;, \u0026#34;childrens\u0026#34;: [], \u0026#34;createDate\u0026#34;: \u0026#34;2013-01-14 20:30\u0026#34;, \u0026#34;level\u0026#34;: 2, \u0026#34;toUser\u0026#34;: { \u0026#34;nickname\u0026#34;: \u0026#34;GodLanBo\u0026#34;, \u0026#34;avatar\u0026#34;: \u0026#34;http://tva1.sinaimg.cn/large/005Uj3w8ly1h68mgfr3bcj31hc0u0mz9.jpg\u0026#34;, \u0026#34;id\u0026#34;: 1 } } ], \u0026#34;createDate\u0026#34;: \u0026#34;2013-01-14 02:03\u0026#34;, \u0026#34;level\u0026#34;: 1, \u0026#34;toUser\u0026#34;: null } ] } JSON应用示例 http://120.48.87.191:9998\n代码实例通过共享屏幕展示\n被追认的名号 - 单体架构 “单体”只是表明系统中主要的过程调用都是进程内调用，不会发生进程间通信，仅此而已。\n什么是单体架构 “单体架构”在整个软件架构演进的历史进程里，是出现时间最早、应用范围最广、使用人数最多、统治历史最长的一种架构风格，但“单体”这个名称，却是在微服务开始流行之后才“事后追认”所形成的概念。\n单体架构不可拆分？ 说起单体架构、巨石系统的缺点时，在脑海中闪过的第一个特点就是它的“不可拆分”，难以扩展，因此才不能支撑越来越大的软件规模。这种想法看似合理，其实是有失偏颇的，至少不完整。\n从纵向角度看，没有哪个系统是不分层的，分层架构（Layered Architecture）已是现在几乎所有信息系统建设中都普遍认可、采用的软件设计方法，无论是单体还是微服务，抑或是其他架构风格，都会对代码进行纵向层次划分，收到的外部请求在各层之间以不同形式的数据结构进行流转传递，触及最末端的数据库后按相反的顺序回馈响应，如图所示。对于这个意义上的“可拆分”，单体架构完全不会展露出丝毫的弱势，反而可能会因更容易开发、部署、测试而获得一些便捷性上的好处。\n从横向角度来看，单体架构也可以支持按照技术、功能、职责等维度，将软件拆分为各种模块，以便重用和管理代码。横向扩展（Scale Horizontally）的角度来衡量，在负载均衡器之后同时部署若干个相同的单体系统副本，以达到分摊流量压力的效果。\n拓展：三层架构与MVC架构 三层架构\n对应上图的Presentation Layer、Business Layer、Persistence Layer\n三层架构有时也被称作：表示层(web层)、业务逻辑层(service层)、数据访问层(dao层)\n三层架构是从整个业务应用角度对程序的划分，其分层逻辑来源于“高内聚，低耦合”的思想。\n1、表现层（UI）：通俗讲就是展现给用户的界面，即用户在使用一个系统的时候他的所见所得。 2、业务逻辑层（BLL）：针对具体问题的操作，也可以说是对数据层的操作，对数据业务逻辑处理。 3、数据访问层（DAL）：该层所做事务直接操作数据库，针对数据的增添、删除、修改、更新、查找等。\nMVC架构\nMVC模式实现了数据和视图的分离\n属于组合设计模式的范畴，就如同其他设计模式一样，模式的出现就是为了对某种功能的优化，而MVC模式可以看做是对三层架构中表现层的一种细分优化。\n1、模型（Model）：模型持有所有的数据、状态和程序逻辑。模型独立于视图和控制器。 2、视图（View）：用来呈现模型。视图通常直接从模型中取得它需要显示的状态与数据。对于相同的信息可以有多个不同的显示形式或视图。 3、控制器（Controller）：位于视图和模型中间，负责接受用户的输入，将输入进行解析并反馈给模型。\nMVC架构工作流程：\n（1）用户通过 View 页面向服务端提出请求，可以是表单请求、超链接请求、AJAX 请求等 （2）服务端 Controller 控制器接收到请求后对请求进行解析，找到相应的 Model 对用户请求进行处理 （3）Model 处理后，将处理结果再交给 Controller （4）Controller 在接到处理结果后，根据处理结果找到要作为向客户端发回的响应 View 页面。页面经渲染（数据填充）后，再\n三层架构和MVC架构的关联\n在当下前后端分离的主流趋势下，MVC架构进行不断的改进，但其中数据与视图分离的思想是一直受用的。\n可以简单的认为前后端分离将View从后端中分离了出来交给前端处理，即浏览器发送Ajax请求，然后服务端接受该请求并返回JSON数据返回给浏览器，最后在浏览器中进行界面渲染。\n即如图所示：\n单体架构的优点与瓶颈 对于小型系统——即由单台机器就足以支撑其良好运行的系统，单体不仅易于开发、易于测试、易于部署，且由于系统中各个功能、模块、方法的调用过程都是进程内调用，不会发生进程间通信（Inter-Process Communication，IPC。广义上讲，可以认为 RPC 属于 IPC 的一种特例，这里两个“PC”不是同个单词的缩写），因此也是运行效率最高的一种架构风格。\n只有基于软件的性能需求超过了单机，软件的开发人员规模明显超过了“2 Pizza Team的\u0026quot;大型的单体架构系统\u0026quot;才能更明显的体现出单体架构的瓶颈。\n在“拆分”这方面，单体系统的真正缺陷不在如何拆分，而在拆分之后的隔离与自治能力上的欠缺。由于所有代码都运行在同一个进程空间之内，所有模块、方法的调用都无须考虑网络分区、对象复制这些麻烦的事和性能损失。获得了进程内调用的简单、高效等好处的同时，也意味着如果任何一部分代码出现了缺陷，过度消耗了进程空间内的资源，所造成的影响也是全局性的、难以隔离的。譬如内存泄漏、线程爆炸、阻塞、死循环等问题，都将会影响整个程序，而不仅仅是影响某一个功能、模块本身的正常运作。如果消耗的是某些更高层次的公共资源，譬如端口号或者数据库连接池泄漏，影响还将会波及整台机器，甚至是集群中其他单体副本的正常工作。\n同样，由于所有代码都共享着同一个进程空间，不能隔离，也就很难做到单独停止、更新、升级某一部分代码，因为不可能有“停掉半个进程，重启 1/4 个程序”这样不合逻辑的操作，所以从可维护性来说，单体系统也是不占优势的。程序升级、修改缺陷往往需要制定专门的停机更新计划，做灰度发布、A/B 测试也相对更复杂。\n由于隔离能力的缺失，单体除了难以阻断错误传播、不便于动态更新程序以外，还面临难以技术异构的困难，每个模块的代码都通常需要使用一样的程序语言，乃至一样的编程框架去开发。\n为了允许程序出错，为了获得隔离、自治的能力，为了可以技术异构等目标，是继为了性能与算力之后，让程序选择分布式又一个理由。\n集群与分布式架构 从追求“尽量不出错”，到正视“出错是必然”\n集群（cluster）就是一组计算机，它们作为一个整体向用户提供一组网络资源，这些单个的计算机系统就是集群的节点（node）。集群提供了以下关键的特性。\n**可扩展性。**集群的性能不限于单一的服务实体，新的服务实体可以动态的加入到集群，从而增强集群的性能。\n**高可用性。**集群通过服务实体冗余使客户端免于轻易遭遇到“out of service”警告。当一台节点服务器发生故障的时候，这台服务器上所运行的应用程序将在另一节点服务器上被自动接管。消除单点故障对于增强数据可用性、可达性和可靠性是非常重要的。\n**负载均衡。**负载均衡能把任务比较均匀的分布到集群环境下的计算和网络资源，以便提高数据吞吐量。\n**错误恢复。**如果集群中的某一台服务器由于故障或者维护需要而无法使用，资源和应用程序将转移到可用的集群节点上。这种由于某个节点中的资源不能工作，另一个可用节点中的资源能够透明的接管并继续完成任务的过程叫做错误恢复。\n一个比较典型的例子，由Nginx负载的多web节点集群架构。\n分布式系统是一组计算机，透过网络相互连接传递消息与通信后并协调它们的行为而形成的系统。组件之间彼此进行交互以实现一个共同的目标。\n分布式与集群的联系与区别如下：\n(一) 分布式是指将不同的业务分布在不同的地方。\n(二) 而集群指的是将几台服务器集中在一起，实现同一业务。\n(三) 分布式的每一个节点，都可以做集群，而集群并不一定就是分布式的。而分布式，从狭义上理解，也与集群差不多，但是它的组织比较松散，不像集群，有一定组织性，一台服务器宕了，其他的服务器可以顶上来。分布式的每一个节点，都完成不同的业务，一个节点宕了，这个业务就不可访问了。\n革命性质的探索 - 面向服务的架构(SOA) 面向服务的架构是一次具体地、系统性地成功解决分布式服务主要问题的架构模式。\n垂直拆分与服务拆分 在前面提到的各种将服务进行拆分方法，最终的效果都是单体的，每个最终运行的服务都是包含了所有功能的整体，这就会导致每个运行的服务中的任意应用出现问题时都会影响到整个服务，也就是前面提到的隔离与自治能力上的欠缺。但是如果当某些应用相对独立，与其他应用没有直接交互的情况下（比如不同的报表生成业务应用），我们可以尝试将其进行垂直拆分，将互不直接影响的应用搬到不同的进程上运行，这样，当某一应用发生问题之后，其爆炸半径不会直接波及到其他独立的正常运行的应用。但是老死不相往来的应用比较稀少，这种垂直拆分并没有太高的工程实践上的可行性。\n但是既然可以根据应用把架构做垂直拆分，那么根据模块/职责对架构进行水平拆分并相互建立通信的方式是否有可行性呢？\n按照这个思路，可以把原本包含了众多复杂逻辑的模块，按照功能但愿抽象成多个服务，以服务为一等公民，并为服务之间的通信定义标准，随后便演进出了SOA架构的雏形。\n再谈服务与通信标准 服务，是根据功能抽象出的概念。比如说，处理用户登录信息的认证服务，负责持久化存储数据的数据库服务，以及为了加快查询速度的缓存服务等 通讯标准，是服务之间通信的基石。没有实现定义好的通信标准，不同服务之间就不能相互调用，难以协作 为了服务之间更好的通信，有两个大的发展方向：中心化和去中心化。在历史的进程中，率先冲锋的便是中心化的模式。\nSOA 的野蛮生长 如图所示两种SOA发展中有代表性的SOA架构。当系统演化至事件驱动架构时，远程服务调用协议SOAP诞生了。此时“面向服务的架构”（Service Oriented Architecture，SOA）已经有了它登上软件架构舞台所需要的全部前置条件。许多巨头科技公司一起创立了Open CSA (opens new window)组织（Open Composite Services Architecture），这便是 SOA 的官方管理机构。OpenCAS制定了一系列精密严谨成体系的基础平台与技术组件，从技术可行性上 SOA 成功地解决了分布式环境下出现的主要技术问题。\n不同的服务间采用 SOAP 作为远程调用的协议，利用一个被称为企业服务总线 (opens new window)（Enterprise Service Bus，ESB）的消息管道来实现各个子系统之间的通信交互，初次之外还定义了很多其他的组件严谨的解决了多方面的问题。\n但是，过于严格的规范定义带来过度的复杂性。而构建在 SOAP 基础之上的 ESB、BPM、SCA、SDO 等诸多上层建筑，进一步加剧了这种复杂性。过于精密的流程和理论也需要懂得复杂概念的专业人员才能够驾驭。最终很难作为一种具有广泛普适性的软件架构风格来推广。\n遍地开花的时代 - 微服务架构 当SOA革命以最终无人问津的结局告终之时，去中心化的分布式方案在悄然生长，而去中心化的最终形态，就是微服务架构。\n微服务是一种通过多个小型服务组合来构建单个应用的架构风格，这些服务围绕业务能力而非特定的技术标准来构建。各个服务可以采用不同的编程语言，不同的数据存储技术，运行在不同的进程之中。服务采取轻量级的通信机制和自动化的部署机制实现通信与运维。\n在微服务时代，以服务来划分团队工作，服务对应的开发团队有直接对服务运行质量负责的责任，也应该有着不受外界干预地掌控服务各个方面的权力，譬如选择与其他服务异构的技术来实现自己的服务。\n微服务明确地提倡数据应该按领域分散管理、更新、维护、存储，在单体服务中，一个系统的各个功能模块通常会使用同一个数据库，诚然中心化的存储天生就更容易避免一致性问题，但是，同一个数据实体在不同服务的视角里，它的抽象形态往往也是不同的。譬如，Bookstore 应用中的书本，在销售领域中关注的是价格，在仓储领域中关注的库存数量，在商品展示领域中关注的是书籍的介绍信息，如果作为中心化的存储，所有领域都必须修改和映射到同一个实体之中，这便使得不同的服务很可能会互相产生影响而丧失掉独立性。因此，服务拆分，数据库也进行拆分，松解服务之间的耦合，每个团队可以更专注于自身负责的业务，也分散减轻了数据库的访问压力。\n微服务组件 注册中心 注册中心可以说是微服务架构中的地址簿，它记录了服务和服务地址的映射关系，在分布式架构中，服务会注册到这里，当服务需要调用其他服务时，就在这里找到服务的地址，进行调用。\n服务注册中心给客户端提供可供调用的服务列表，客户端在进行远程服务调用时，根据服务列表然后选择服务提供方的服务地址进行服务调用。服务注册中心在分布式系统中大量应用，是分布式系统中不可获取的组件。 注册中心是整个服务调用的核心部分，如果服务不存在注册中心，那么通过网关会调用不到，导致失败。 配置中心 管理各个环境的配置文件参数，比如说数据库，缓存，存储，业务应用并且支持管理每个不同的环境的配置。\n本地配置在服务启动加载，修改配置不需要重启服务 多个环境（dev，prod，sit，uat）容易混淆，会产生错误，导致服务运行异常 出现配置错误时，不容易回滚到指定的版本 API网关 API网关是微服务架构中提供路由转发与鉴权等功能，首先，它会提供最基本的路由服务，将客户端请求转发后台业务服务；其次，作为一个入口，它还可以进行认证，鉴权，限流等操作。\n客户端访问的统一对接接口 防止内部接口直接暴露给外部客户端（隐藏内部服务） API网关通过提供一个额外的保护层来防止恶意攻击，例如SQL注入，XML解析器漏洞和拒绝服务 服务网关的前置过滤器中，所有请求过来进行权限校验 日志访问与审计 服务限流 服务限流：指当系统资源不够的情况下，不足以应对大量的用户与数据接口请求时，为了保证优先的资源能够正常服务，因此对系统按照预设的规则进行流量限制或功能限制的一种方法。\n发生错误或者超时，不让调用接口，调用本地fallback（容错） 解决高并发请求，一旦达到规定请求，熔断，报错 链路跟踪 调用链是整个分布式系统中跟踪一个用户请求的过程，包括数据采集，数据传输，数据存储，数据分析和数据可视化展示工具，也是微服务中代码的调试和服务监控的性能分析工具。\n分布式web系统中，客户端的一次请求操作，可能需要经过系统中多个模块，多个中间件，多台机器的相互协作才能完成，并且这一系列调用请求中，有些是串行处理的，有些是并发执行的，那么如何确定客户端的一次操作背后调用了哪些应用，哪些模块，经过了哪些节点，每个模块的调用先后顺序是怎样的，每个模块的性能问题如何？随着业务系统模型的日趋复杂化，分布式系统中继续一套链路追踪（trace）系统来解决这些问题（快速定位）。\nRPC调用 RPC就是从一台机器（客户端）上通过参数传递的方式调用另一台机器（服务器）上的一个函数或方法（可以统称为服务）并得到返回的结果。\nRPC 会隐藏底层的通讯细节（不需要直接处理Socket通讯或Http通讯） RPC 是一个请求响应模型。\n客户端发起请求，服务器返回响应（类似于Http的工作方式） RPC 在使用形式上像调用本地函数（或方法）一样去调用远程的函数（或方法）。\n微服务架构实例 烂大街的谷粒商城项目\n云计算与云原生 如今被炒的火热的云计算和云原生到底是什么\n虚拟化与容器技术 因为不同的应用或者程序可能并不适用于同一个系统中，理想状态下可以每台服务器用于一个特定的任务或者应用程序，但问题是，但多数服务器在运行计算时只会使用他们整体处理能力的一小部分，不能充分利用服务器的处理能力。\n虚拟化就解决了这个问题，将多台服务器整合到一台服务器中，运行多个虚拟环境，每个VM都有自己的操作系统（这些操作系统可以是不同的），可以在其上安装应用程序。\n虚拟机的设计原理彼此间是隔离的，并且与虚拟主机隔离，这意味着一个应用程序中的安全问题不会影响在另一个虚拟机中运行的另一个应用程序。同样，如果一个应用程序崩溃并需要重新启动服务器，那么可以重新启动它的VM，而不影响任何其他VM的运行。此外虚拟化还有利于可扩展性，VM是以计算机文件的形式存在的，因此这个文件可以很容易地通过网络(甚至通过存储介质)复制或移动到新的虚拟主机上，也就有了更强的可移植性。\n但是虚拟机模拟了整个操作系统，而这层操作系统往往都是可以通用的，即VM的操作相对更重，将操作系统复制了多份造成了一些不必要的开销，一台服务器中可以运行的虚拟机数量比较有限。\n于是，可以共享操作系统的容器技术登上了舞台\n与虚拟化相反，容器主机需要运行自己的操作系统以及容器系统。容器由单个应用程序（或微服务）以及需要运行的其他重要文件组成，利用容器主机的操作系统内核、二进制文件和库来运行。这些共享文件作为只读文件公开给容器。在容器主机上运行的其他容器也共享主机的内核、二进制文件和库。容器技术的核心（以Docker为例），主要基于Linux内核提供资源操作，进行资源隔离(namespace)、资源分配控制(Cgroup)、镜像的制作与加载(UnionFS)。\n由于容器比虚拟机“轻”得多，并且启动速度也快得多，这也使得它们成为运行微服务的理想工具，当对微服务的需求扩大时，可以启用容器，当需求减少时可以删除。它们也可以在公有云和私有云以及传统数据中心之间轻松移动。\n虚拟机与容器\n由于多个容器之间使用的还是同一个宿主机的操作系统内核，因此导致了容器与虚拟机之间存在一些重要区别：\n容器比虚拟机小得多或“轻”得多，通常由几兆字节组成，并且所需的硬件资源也少得多。这意味着一台物理服务器可以承载的容器比虚拟机要多得多。 容器可以在几秒甚至几毫秒内启动。相比之下，虚拟机的启动时间比较长。 由于容器都共享其主机的操作系统，因此所有应用程序都必须在同一操作系统上运行。相比之下，运行在虚拟主机上的虚拟机可以运行不同的操作系统（例如Linux，Unix和Windows）。 使用容器时，只需要对容器主机的操作系统进行补丁和更新。而虚拟机则需对每个操作系统都进行补丁和更新。 如果一个容器导致容器主机的操作系统崩溃，则在该主机上运行的所有容器都将失败。 容器主机的操作系统内核中的安全漏洞将影响其所托管的所有容器。 容器技术也是虚拟化技术的子类\n容器编排工具\n当应用服务的数量不断增加，部署的容器数量开始变的庞大，一个应用数十乃至数百个松散结合的容器式组件构成，而这些组件需要通过相互间的协同合作。这时对单独组件和应用层的工作进行组织的流程的容器编排管理系统也有了存在的必要。Docker Swarm、Apache Mesos 和 Kubernetes 也随之登上舞台。\n云计算的蓬勃 云计算：即通过网络按需提供可动态伸缩的廉价计算资源服务。 计算资源的层次划分\n第一层次，是最底层的硬件资源，主要包括CPU（计算资源），硬盘（存储资源），还有网卡（网络资源）等。\n第二层次，要高级一些，用户不直接使用硬件资源，而是使用云厂商直接提供配置好底层环境的各类中间服务，如负载均衡服务、数据库服务、对象存储服务、缓存服务等\n第三层次，更高级一些，用户直接使用厂商提供的专门的垂直软件应用服务，不需要关注底层的架构与实现细节，做到真正开箱即用的软件服务\n以上三个层次的划分，对应了云计算中的三个重要概念\nIaaS: Infrastructure-as-a-Service（基础设施即服务） PaaS: Platform-as-a-Service（平台即服务） SaaS: Software-as-a-Service（软件即服务） 云原生时代的到来 云原生，实际是云原生计算的简称，它是云计算发展到现在的这一种形态。\n云原生技术可以为企业在公有云、私有云、混合云等新型的动态环境中，构建和运行可弹性拓展的应用提供了可能。\n云原生主要涉及四个大方面：\n弹性资源：基于虚拟化容器以及灵活的编排调度机制，可以为云服务体哦概念股快速扩缩容能力，而且极大程度地提高了物理资源的利用率。在这方面。**Kubernetes（k8s）**技术已经成为了行业的标准。 微服务架构：微服务也是云原生的重要基石之一。依托于功能单元解构，使得云服务具备了快速迭代的可能，业务得以循序发展；统一的通信标准能够帮助越来越多的组件加入到云原生的生态中，同时使得各组件之间的交互变得更容易。 DevOps：设计 =\u0026gt; 开发 =\u0026gt; 测试 =\u0026gt; 交付 =\u0026gt; 开发 =\u0026gt; 测试 =\u0026gt; 交付，自动化的流程使得软件的工作流程更高效，将微服务架构的优势进一步发挥。 服务网格：如果说微服务架构中最重要的进步，是将庞大的单体服务按照业务功能解耦开来，那么，服务网格的重要进步就是将业务逻辑于网络通信和治理解耦开来。业务不再需要关心异构系统中RPC中间件治理能力的不统一，这样使得复杂的治理能力成为可能 后微服务时代 - 云原生架构 从软件层面独力应对微服务架构问题，发展到软、硬一体，合力应对架构问题的时代，此即为云原生所引领的“后微服务时代”。\nAll-in-Kubernetes ？ 微服务时代所取得的成就，本身就离不开以 Docker 为代表的早期容器化技术的巨大贡献。在早期的容时候器只被简单地视为一种可快速启动的服务运行环境，目的是方便程序的分发部署，这个阶段针对单个应用进行封装的容器并未真正参与到分布式问题的解决之中。\n这个状况一直持续到2017 年，各个容器技术的公司，都主动或被迫纷纷支持起了 k8s 的集成， Kubernetes 赢得容器战争的胜利正式宣告结束。\n在以往的架构演进中，许多软件解决的问题都有对应的硬件解决方案，如负载均衡问题可以不知负载均衡器，服务发现问题可以设置DNS服务器。通过配置硬件的方式，业务开发人员就可以不必过多关心由硬件直接解决的问题。但在微服务时代，人们选择在软件的代码层面而不是硬件的基础设施层面去解决复杂分布式问题，很大程度上是因为由硬件构成的基础设施，跟不上由软件构成的应用服务的灵活性的无奈之举。\n在容器技术的发展之下，构建在Linux操作系统之上的K8S将底层的操作系统中的概念进一步封装，已经能够被看做一个可对容器调度分配控制的“云操作系统”，在这个“云操作系统”的平台上，可以对服务发现、配置中心、服务网关、负载均衡、服务安全、跟踪监控提供的”基础设施层面“的解决方案。至此软件与硬件的界限便已经模糊。一旦虚拟化的硬件能够跟上软件的灵活性，那些与业务无关的技术性问题便有可能从软件层面剥离，悄无声息地解决于硬件基础设施之内，让软件得以只专注业务。\n服务网格(Service Mesh) Kubernetes 成为容器战争胜利者标志着后微服务时代的开端，但是 k8s 基础设施的解决方案仍有缺陷，甚至单从功能性上来看，全部依托于k8s 还不如基于Spring Cloud这些微服务框架的提供的方案，基础设施是针对整个容器来管理的，粒度相对粗旷，只能到容器层面，对单个远程服务就很难有效管控。\n举个例子，微服务 A 调用了微服务 B 的两个服务，称为 B1和 B2，假设 B1表现正常但 B2出现了持续的 500 错，那在达到一定阈值之后就应该对 B2进行熔断，以避免产生雪崩效应。如果仅在基础设施层面来处理，这会遇到一个两难问题，切断 A 到 B 的网络通路则会影响到 B1的正常调用，不切断的话则持续受 B2的错误影响。\n为了解决这一类问题，虚拟化的基础设施很快完成了第二次进化，引入了今天被称为“服务网格”（Service Mesh）的“边车代理模式”（Sidecar Proxy）\n这个场景里指的具体含义是由系统自动在服务容器（通常是指 Kubernetes 的 Pod）中注入一个通信代理服务器，相当于那个挎斗，以类似网络安全里中间人攻击的方式进行流量劫持，在应用毫无感知的情况下，悄然接管应用所有对外通信。这个代理除了实现正常的服务间通信外（称为数据平面通信），还接收来自控制器的指令（称为控制平面通信），根据控制平面中的配置，对数据平面通信的内容进行分析处理，以实现熔断、认证、度量、监控、负载均衡等各种附加功能。这样便实现了既不需要在应用层面加入额外的处理代码，也提供了几乎不亚于程序代码的精细管理能力。\n探索中的Serverless架构 如果说微服务架构是分布式系统这条路的极致，那无服务架构，也许就是“不分布式”的云端系统这条路的起点。\n人们研究分布式架构，最初是由于单台机器的性能无法满足系统的运行需要，尽管在后来架构演进过程中，容错能力、技术异构、职责划分等各方面因素都成为架构需要考虑的问题，但其中获得更好性能的需求在架构设计中依然占很大的比重。对软件研发而言，不去做分布式无疑才是最简单的，如果单台服务器的性能可以是无限的，那架构演进的结果肯定会与今天有很大的差别，分布式也好，容器化也好，微服务也好，恐怕都未必会如期出现，最起码不必一定是像今天这个样子。\n真正的无限性能是肯定无法做到的，但是相对意义的无限性能已经成为了现实，依靠云原生提供的快速扩缩容能力，云厂商可以向我们提供一种我们可以认为是可靠的服务，让我们不去关心服务的性能问题。开发人员就可以专心于业务，只需要写好代码上传到云厂商提供的平台。这便是Serverless架构（无服务），无服务指的更多的是一种不需要关注服务器的思维角度，专业的事”让专业的人做“，服务性能的保障完全交给云厂商。\n除此之外无服务的架构还为云厂商和使用者提供了一种新的商业收费模式，即按量付费，可以根据资源占用量和占用时间进行收费，实现使用多少资源花多少钱。这使得资源的利用效率可以得到明显的提升。\n无服务现在还没有一个特别权威的“官方”定义，但它的概念并没有前面各种架构那么复杂，本来无服务也是以“简单”为主要卖点的，它只涉及两块内容：后端设施（Backend）和函数（Function）。\n后端设施是指数据库、消息队列、日志、存储，等等这一类用于支撑业务逻辑运行，但本身无业务含义的技术组件，这些后端设施都运行在云中，无服务中称其为“后端即服务”（Backend as a Service，BaaS）。 函数是指业务逻辑代码，这里函数的概念与粒度，都已经很接近于程序编码角度的函数了，其区别是无服务中的函数运行在云端，不必考虑算力问题，不必考虑容量规划（从技术角度可以不考虑，从计费的角度你的钱包够不够用还是要掂量一下的），无服务中称其为“函数即服务”（Function as a Service，FaaS）。 无服务的愿景是让开发者只需要纯粹地关注业务，不需要考虑技术组件，后端的技术组件是现成的，可以直接取用，没有采购、版权和选型的烦恼；不需要考虑如何部署，部署过程完全是托管到云端的，工作由云端自动完成；不需要考虑算力，有整个数据中心支撑，算力可以认为是无限的；也不需要操心运维，维护系统持续平稳运行是云计算服务商的责任而不再是开发者的责任。\n在当前阶段来看，无服务天生“无限算力”的假设决定了它必须要按使用量（函数运算的时间和占用的内存）计费以控制消耗算力的规模，因而函数不会一直以活动状态常驻服务器，请求到了才会开始运行，这导致了函数不便依赖服务端状态，也导致了函数会有冷启动时间，响应的性能不可能太好（目前无服务的冷启动过程大概是在数十到百毫秒级别，对于 Java 这类启动性能差的应用，甚至能到接近秒的级别）。\nserverless与”微服务“和”云原生“并不是迭代演进的关系，并不是说serverless就比前几种架构更先进，serverless目前还在发展的阶段，对无服务未来的发展仍应持谨慎乐观的态度。在未来也许分布式与非分布式的界限也会变得模糊，两条看似不同路线最终在云端的数据中心交汇。\nWe can only see a short distance ahead, but we can see plenty there that needs to be done.\n尽管目光所及之处，只是不远的前方，即使如此，依然可以看到那里有许多值得去完成的工作在等待我们。\n—— Alan Turing ，1950\n​\t~END~\n","date":"2022-09-18T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/cfclogo03.png","permalink":"https://Kirov7.github.io/p/web%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84%E6%BC%94%E8%BF%9B%E6%A6%82%E8%BF%B0/","title":"WEB服务端系统架构演进概述"},{"content":"在最近写的一个项目中需要用到一个TCP反向代理的模块，但是在golang的标准库中没有为tcp直接提供像http那样简单易用的服务框架，本篇则简单实现一个易用的TCP服务器\n主体思路 我们的实现的主题思路分为以下四个内容\n监听服务 获取构建新连接对象并设置超时时间及keepalive 设置方法退出时连接关闭 调用回调接口 TcpHandler 主要结构体和接口 首先是TCPServer的结构体，我们希望用户可以自由构建TcpServer并设置超时时间等自定义选项\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type TcpServer struct { Addr string Handler TCPHandler \u0026lt;- 对外提供的服务方法接口 err error BaseCtx context.Context WriteTimeout time.Duration ReadTimeout time.Duration KeepAliveTimeout time.Duration mu sync.Mutex inShutdown int32 doneChan chan struct{} l *onceCloseListener } 像httpHandler一样，对外提供抽象的ServeTCP方法\n1 2 3 type TCPHandler interface { ServeTCP(ctx context.Context, conn net.Conn) } 服务启动方法 用户可以通过自行构建TcpServer实例再通过ListenAndServe()调用服务，或通过tcp.ListenAndServe(\u0026quot;:8080\u0026quot;, handler) 使用默认的TcpServer实例快速启动服务。\n在 ListenAndServe() 方法中，进行参数的校验和初始化操作\nServe(l net.Listener) 方法中，通过 l.Accept() 接收信息，包装接收到的conn并另起一个协程处理服务\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 func ListenAndServe(addr string, handler TCPHandler) error { server := \u0026amp;TcpServer{Addr: addr, Handler: handler, doneChan: make(chan struct{})} return server.ListenAndServe() } func (s *TcpServer) ListenAndServe() error { if s.shuttingDown() { return ErrServerClosed } if s.doneChan == nil { s.doneChan = make(chan struct{}) } addr := s.Addr if addr == \u0026#34;\u0026#34; { return errors.New(\u0026#34;need addr\u0026#34;) } ln, err := net.Listen(\u0026#34;tcp\u0026#34;, addr) if err != nil { return err } return s.Serve(tcpKeepAliveListener{ ln.(*net.TCPListener)}) } func (s *TcpServer) Serve(l net.Listener) error { s.l = \u0026amp;onceCloseListener{Listener: l} defer s.l.Close() //执行listener关闭 if s.BaseCtx == nil { s.BaseCtx = context.Background() } baseCtx := s.BaseCtx ctx := context.WithValue(baseCtx, ServerContextKey, s) \u0026lt;- 将TcpServer实例存入context中 for { rw, e := l.Accept() if e != nil { select { case \u0026lt;-s.getDoneChan(): return ErrServerClosed default: } fmt.Printf(\u0026#34;accept fail, err: %v\\n\u0026#34;, e) continue } c := s.newConn(rw) go c.serve(ctx) } return nil } 包装 net.Conn 为 tcp.conn\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 type conn struct { server *TcpServer // 反引用TcpServer remoteAddr string // 发送端地址 rwc net.Conn } func (s *TcpServer) newConn(rwc net.Conn) *conn { c := \u0026amp;conn{ server: s, rwc: rwc, } // 设置参数 if d := c.server.ReadTimeout; d != 0 { c.rwc.SetReadDeadline(time.Now().Add(d)) } if d := c.server.WriteTimeout; d != 0 { c.rwc.SetWriteDeadline(time.Now().Add(d)) } if d := c.server.KeepAliveTimeout; d != 0 { if tcpConn, ok := c.rwc.(*net.TCPConn); ok { tcpConn.SetKeepAlive(true) tcpConn.SetKeepAlivePeriod(d) } } return c } 由 tcp.conn.Server(ctx) 调用回调函数进行服务处理\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 func (c *conn) serve(ctx context.Context) { defer func() { if err := recover(); err != nil \u0026amp;\u0026amp; err != ErrAbortHandler { const size = 64 \u0026lt;\u0026lt; 10 buf := make([]byte, size) buf = buf[:runtime.Stack(buf, false)] fmt.Printf(\u0026#34;tcp: panic serving %v: %v\\n%s\u0026#34;, c.remoteAddr, err, buf) } c.close() }() c.remoteAddr = c.rwc.RemoteAddr().String() ctx = context.WithValue(ctx, LocalAddrContextKey, c.rwc.LocalAddr()) if c.server.Handler == nil { panic(\u0026#34;handler empty\u0026#34;) } c.server.Handler.ServeTCP(ctx, c.rwc) } 这样，一个简单易用的TCP服务框架就搭建完成了，其中一些像 close() 等方法在此处没有展示出来，更多详细代码可在我的代码仓库中查看：https://github.com/Kirov7/fayUtils/tree/master/net/tcp\n扩展中间件的实现 扩展中间件功能的实现思路\n方法构建 构建中间件URL路由 构建URL的中间件方法数组 使用Use方法整合路由与方法数组 方法调用 构建方法请求逻辑 封装TCPHandler接口与TcpServer整合 TcpSliceRouter.Group(path) 方法，初始化路由分组（默认只能全局）\n1 2 3 4 5 6 7 8 9 10 // 创建 Group func (g *TcpSliceRouter) Group(path string) *TcpSliceGroup { if path != \u0026#34;/\u0026#34; { panic(\u0026#34;only accept path=/\u0026#34;) } return \u0026amp;TcpSliceGroup{ TcpSliceRouter: g, path: path, } } TcpSliceGroup.Use(middlewares ...TcpHandlerFunc) 构造回调方法\n调用 Use 方法传入中间件集合，添加到切片 c.handlers 中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // 构造回调方法 func (g *TcpSliceGroup) Use(middlewares ...TcpHandlerFunc) *TcpSliceGroup { g.handlers = append(g.handlers, middlewares...) existsFlag := false for _, oldGroup := range g.TcpSliceRouter.groups { if oldGroup == g { existsFlag = true } } if !existsFlag { g.TcpSliceRouter.groups = append(g.TcpSliceRouter.groups, g) } return g } 通过 NewTcpSliceRouterHandler 方法传入最后调用的逻辑方法coreFunc并传入已经 Use 了中间件的， TcpSliceRouter\n1 2 3 4 5 6 func NewTcpSliceRouterHandler(coreFunc func(*TcpSliceRouterContext) tcp_server.TCPHandler, router *TcpSliceRouter) *TcpSliceRouterHandler { return \u0026amp;TcpSliceRouterHandler{ coreFunc: coreFunc, router: router, } } 最终的回调函数 ServeTCP((ctx context.Context, conn net.Conn)，初始化 context 之后将 coreFunc 追加到 c.handlers，重置执行光标，从第一个 c.handlers 开始执行中间件\n1 2 3 4 5 6 7 8 func (w *TcpSliceRouterHandler) ServeTCP(ctx context.Context, conn net.Conn) { c := newTcpSliceRouterContext(conn, w.router, ctx) c.handlers = append(c.handlers, func(c *TcpSliceRouterContext) { w.coreFunc(c).ServeTCP(ctx, conn) }) c.Reset() c.Next() } 在中间件中自行调用Next()、Abort()等中间件逻辑，最后所有中间件执行完毕之后执行 coreFunc（已经被追加到c.handlers的最后位置）\n1 2 3 4 5 6 7 8 9 10 11 12 13 // 从最先加入中间件开始回调 func (c *TcpSliceRouterContext) Next() { c.index++ for c.index \u0026lt; int8(len(c.handlers)) { c.handlers[c.index](c) c.index++ } } // 跳出中间件方法 func (c *TcpSliceRouterContext) Abort() { c.index = abortIndex } ","date":"2022-08-16T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/20230218223854.png","permalink":"https://Kirov7.github.io/p/golang%E5%AE%9E%E7%8E%B0%E6%94%AF%E6%8C%81%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E7%AE%80%E6%98%93tcp%E6%A1%86%E6%9E%B6/","title":"Golang实现支持中间件的简易TCP框架"},{"content":"负载均衡算法实现 随机负载 随机挑选目标服务器ip\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 type RandomBalance struct { curIndex int rss []string } // 添加新的服务ip func (r *RandomBalance) Add(params ...string) error { if len(params) == 0 { return errors.New(\u0026#34;param len 1 at least\u0026#34;) } addr := params[0] r.rss = append(r.rss, addr) return nil } // 采用rand.Intn随机取一个服务ip func (r *RandomBalance) Next() string { if len(r.rss) == 0 { return \u0026#34;\u0026#34; } r.curIndex = rand.Intn(len(r.rss)) return r.rss[r.curIndex] } func (r *RandomBalance) Get(key string) (string, error) { return r.Next(), nil } 轮询负载 ABC三台服务器,A B C A B C依次轮询\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 type RoundRobinBalance struct { curIndex int rss []string } func (r *RoundRobinBalance) Add(params ...string) error { if len(params) == 0 { return errors.New(\u0026#34;param len 1 at least\u0026#34;) } addr := params[0] r.rss = append(r.rss, addr) return nil } func (r *RoundRobinBalance) Next() string { if len(r.rss) == 0 { return \u0026#34;\u0026#34; } lens := len(r.rss) if r.curIndex \u0026gt;= lens { r.curIndex = 0 } // 保存一个服务ip的游标 curAddr := r.rss[r.curIndex] r.curIndex = (r.curIndex + 1) % lens return curAddr } func (r *RoundRobinBalance) Get(key string) (string, error) { return r.Next(), nil } 加权负载 给目标设置访问权重,按照权重轮询\nnginx的加权负载均衡策略\n计算策略：\ncurrentWeight += effectiveWeight 选出最大的currentWeight节点作为选中节点 currentWeight -= totalWeight 其中effectiveWeight的值不变，只有当服务异常的时候减少 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 type WeightRoundRobinBalance struct { curIndex int rss []*WeightNode rsw []int } type WeightNode struct { addr string weight int //权重值 currentWeight int //节点当前权重 effectiveWeight int //有效权重 } func (r *WeightRoundRobinBalance) Add(params ...string) error { if len(params) != 2 { return errors.New(\u0026#34;param len need 2\u0026#34;) } parInt, err := strconv.ParseInt(params[1], 10, 64) if err != nil { return err } node := \u0026amp;WeightNode{addr: params[0], weight: int(parInt)} node.effectiveWeight = node.weight r.rss = append(r.rss, node) return nil } // Next 参考了 nginx 的加权负载均衡的策略 func (r *WeightRoundRobinBalance) Next() string { total := 0 var best *WeightNode for i := 0; i \u0026lt; len(r.rss); i++ { w := r.rss[i] //step 1 统计所有有效权重之和 total += w.effectiveWeight //step 2 变更节点临时权重为的节点临时权重+节点有效权重 w.currentWeight += w.effectiveWeight //step 3 有效权重默认与权重相同，通讯异常时-1, 通讯成功+1，直到恢复到weight大小 if w.effectiveWeight \u0026lt; w.weight { w.effectiveWeight++ } //step 4 选择最大临时权重点节点 if best == nil || w.currentWeight \u0026gt; best.currentWeight { best = w } } if best == nil { return \u0026#34;\u0026#34; } //step 5 变更临时权重为 临时权重-有效权重之和 best.currentWeight -= total return best.addr } func (r *WeightRoundRobinBalance) Get(key string) (string, error) { return r.Next(), nil } 一致性hash负载 请求固定URL访问指定IP\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 type Hash func(data []byte) uint32 type UInt32Slice []uint32 func (s UInt32Slice) Len() int { return len(s) } func (s UInt32Slice) Less(i, j int) bool { return s[i] \u0026lt; s[j] } func (s UInt32Slice) Swap(i, j int) { s[i], s[j] = s[j], s[i] } type ConsistentHashBanlance struct { mux sync.RWMutex hash Hash replicas int // 复制因子 keys UInt32Slice // 已排序的节点hash切片 hashMap map[uint32]string // 节点哈希和Key的map,键是hash值，值是节点key } func NewConsistentHashBanlance(replicas int, fn Hash) *ConsistentHashBanlance { m := \u0026amp;ConsistentHashBanlance{ replicas: replicas, hash: fn, hashMap: make(map[uint32]string), } if m.hash == nil { //最多32位,保证是一个2^32-1环 m.hash = crc32.ChecksumIEEE } return m } // 验证是否为空 func (c *ConsistentHashBanlance) IsEmpty() bool { return len(c.keys) == 0 } // Add 方法用来添加缓存节点，参数为节点key，比如使用IP func (c *ConsistentHashBanlance) Add(params ...string) error { if len(params) == 0 { return errors.New(\u0026#34;param len 1 at least\u0026#34;) } addr := params[0] c.mux.Lock() defer c.mux.Unlock() // 结合复制因子计算所有虚拟节点的hash值，并存入m.keys中，同时在m.hashMap中保存哈希值和key的映射 for i := 0; i \u0026lt; c.replicas; i++ { hash := c.hash([]byte(strconv.Itoa(i) + addr)) c.keys = append(c.keys, hash) c.hashMap[hash] = addr } // 对所有虚拟节点的哈希值进行排序，方便之后进行二分查找 sort.Sort(c.keys) return nil } // Get 方法根据给定的对象获取最靠近它的那个节点 func (c *ConsistentHashBanlance) Get(key string) (string, error) { if c.IsEmpty() { return \u0026#34;\u0026#34;, errors.New(\u0026#34;node is empty\u0026#34;) } hash := c.hash([]byte(key)) // 通过二分查找获取最优节点，第一个\u0026#34;服务器hash\u0026#34;值大于\u0026#34;数据hash\u0026#34;值的就是最优\u0026#34;服务器节点\u0026#34; idx := sort.Search(len(c.keys), func(i int) bool { return c.keys[i] \u0026gt;= hash }) // 如果查找结果 大于 服务器节点哈希数组的最大索引，表示此时该对象哈希值位于最后一个节点之后，那么放入第一个节点中 if idx == len(c.keys) { idx = 0 } c.mux.RLock() defer c.mux.RUnlock() return c.hashMap[c.keys[idx]], nil } func (c *ConsistentHashBanlance) SetConf(conf LoadBalanceConf) { c.conf = conf } ","date":"2022-08-10T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/20230218223753.png","permalink":"https://Kirov7.github.io/p/golang%E5%AE%9E%E7%8E%B0%E5%9B%9B%E7%A7%8D%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/","title":"Golang实现四种负载均衡算法"},{"content":"在某个项目中，有个数据验证的业务，即在数据库中查询数据是否存在，若数据已存在则返回错误并给前端提示。稍想了一下就能写出如下代码Func01\nFunc01\n1 2 3 4 5 6 7 8 func (t *ServiceInfo) Find(c *gin.Context, tx *gorm.DB, search *ServiceInfo) (*ServiceInfo, error) { out := \u0026amp;ServiceInfo{} err := tx.WithContext(c).Where(search).Find(out).Error if err != nil { return nil, err } return out, nil } gorm在之前的版本中，因为gorm的查询是链式的语句，所以中间出现的错误会存入到Error的参数集中处理。而且当没有查询到数据的时候也会得到错误ErrRecordNotFound。所以此代码就把错误同一处理，当controller中没有收到任何错误时，可以说明数据库中查询到了此数据，即校验重复了。\n但是经过测试后发现无论如何err都是nil，且RowsAffected也明明为0。在网上也没有直接搜到这个坑的blog，于是我去翻了gorm最新的文档，发现了此段话！\n即说明Find()方法不会再得到ErrRecordNotFound的错误\n于是我采用了First()进行了测试\nFunc02\n1 2 3 4 5 6 7 8 9 10 11 12 func (t *ServiceInfo) Find(c *gin.Context, tx *gorm.DB, search *ServiceInfo) (*ServiceInfo, error) { out := \u0026amp;ServiceInfo{} resultFind := tx.WithContext(c).Where(search).Find(out) resultFirst := tx.WithContext(c).Where(search).First(out) log.Print(\u0026#34;Find() Err: \u0026#34;, resultFind.Error, \u0026#34;\\tFind Rows Affected: \u0026#34;, resultFind.RowsAffected) log.Print(\u0026#34;First() Err: \u0026#34;, resultFirst.Error, \u0026#34;\\tFind Rows Affected: \u0026#34;, resultFirst.RowsAffected) err := resultFind.Error if err != nil { return nil, err } return out, nil } 得到输出\n1 2 2022/07/25 10:00:35 Find() Err: \u0026lt;nil\u0026gt; Find Rows Affected: 0 2022/07/25 10:00:35 First() Err: record not found Find Rows Affected: 0 很明显，当查询不到结果的时候First()方法会返回ErrRecordNotFound，而Find()方法并不会\n因此，若不改变代码原有的逻辑基础上，可以通过手动添加Error的方法来完成数据校验的工作\nFunc03\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func (t *ServiceInfo) Find(c *gin.Context, tx *gorm.DB, search *ServiceInfo) (*ServiceInfo, error) { out := \u0026amp;ServiceInfo{} resultFind := tx.WithContext(c).Where(search).Find(out) if resultFind.RowsAffected \u0026lt; 1 { err := resultFind.AddError(gorm.ErrRecordNotFound) if err != nil { return nil, err } } err := resultFind.Error if err != nil { return nil, err } return out, nil } 即通过resultFind.RowsAffected \u0026lt; 1来判断是否查询到数据，再通过 resultFind.AddError(gorm.ErrRecordNotFound) 手动添加\nErrRecordNotFound错误，藉此来完成在旧版本中存在的功能。\nPS：我个人并不是很理解为什么要取消Find()方法中的这个错误提示\n​\t此实现方式仅供参考，如有更漂亮的方法希望不吝赐教\n","date":"2022-07-20T00:00:00Z","permalink":"https://Kirov7.github.io/p/%E8%AE%B0%E4%B8%80%E6%AC%A1gorm.errrecordnotfound%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","title":"记一次gorm.ErrRecordNotFound踩坑记录"},{"content":"MySQL索引及其优化总结 MySQL的基础架构 Server层 ：核心服务功能与跨引擎功能的实现（如所有的内置函数、存储过程、触发器等） 连接器：管理连接，权限验证 命中缓存：命中缓存则直接返回结果（8.0版本后删除） 分析器：词法分析，语法分析 优化器：执行计划生成，索引选择 执行器：操作引擎返回结果 存储引擎：数据的存储与提取，插件式的架构模式 InnoDB * (重点) MyISMA SQL语句的执行流程 一条SQL查询语句是怎么执行的\n1 SELECT * FROM student WHERE id = 12004030124; 在整体架构层面分析此条语句的执行过程\n连接器\n连接器负责跟客户端建立连接、获取权限、维持和管理连接。并负责校验用户身份。\n1 mysql [-h$ip -p$port] -u$user -p [password 不建议把密码写在此条语句] 命令行中的mysql是客户端工具，在执行完词条语句之后将会与服务器进行连接，即通过TCP三次握手建立连接之后会校验用户身份\n连接器会验证用户输入的用户名和密码，若存在问题则会返回错误并且客户端程序结束执行\n在通过身份登录验证之后，连接器会查询该用户的权限并保存，接下来所有的操作权限都基于此次查询，即使用户权限发生了更改，在此次连接没有重新的建立的情况下，用户的权限不会直接更改。\n查询缓存\n在建立好连接之后就可以进行sql语句的执行了。\n执行逻辑将会来到第二部：查询缓存\n在拿到查询请求的适合，会先去查询缓存，缓存中以key-value的形式存储查询操作和查询结果，如果缓存中记录了执行过此查询操作，则直接返回该查询操作所对用的结果，即不需要再向下执行复杂的查询工作，可以直接返回查询操作的结果大大的简化了执行时间，如果说没有命中缓存，则向下执行通过IO过程查询，在返回时将查询结果返回到查询缓存中存储。使用缓存是需要代价的，而且往往弊大于利，因为每次表更新都会将查询结果清空，所以对于更新压力大的业务数据库来说，缓存命中率极低，在很多情况下查询缓存甚至是一种性能负担，所以在非表更新极少的静态表之外，不建议使用查询缓存。\n注：在mysql8.0之后查询缓存被彻底的删除\n分析器\n在没有命中缓存的情况下，就到了分析器\n先进行 \u0026ldquo;词法分析\u0026rdquo;，mysql需要知道sql语句中的内容，识别关键字，例如识别到select关键字，并分析出student为表名，id为列名。在完成\u0026quot;词法分析\u0026quot;后，分析器将进行\u0026quot;语法分析\u0026quot;，分析sql语句是否存在语法问题，若存在则返回错误提示并终止执行。\n优化器\n在分析完执行内容之后，优化器会进行相应的优化\n优化器会选择如何使用索引和如何进行表连接顺序，并选择执行效率最高的方案执行语句。\n执行器\n在优化器选择好执行方案之后，执行器就开始执行sql语句\n首先执行器会判断当前用户是否拥有查询此表的权限啊，若无权限在返回错误并终止执行。若有权限打开表使用存储引擎的接口进行操作。例如在此条语句中，因为表中没有定义索引，执行过程大致如下：\n调用存储引擎接口读取表的第一行，判断是否与条件匹配，即id是否等于0 调用存储引擎接口读取下一行，判断是否匹配，重复执行直到读取完最后一行 将查询到的结果集返回给客户端 如果表中存在索引，查询方式也大致相同，调用的是满足条件的第一行和下一行\n索引 什么是索引 在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是表中一列或多列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。\n索引（Index）是帮助MySQL⾼效获取数据的数据结构。提取句⼦ 主⼲，就可以得到索引的本质：索引是数据结构\n索引的作用 保证数据的准确性 提高检索速度 提高系统性能 索引的类型 system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; all\nInnoDB索引的数据结构 ⼀般来说，索引本身也很⼤，不可能全部存储在内存中，因此索引往往以索引⽂件的形式存储的 磁盘上。这样的话，索引查找过程中就要产⽣磁盘I/O消耗，相对于内存存取，I/O存取的消耗要⾼⼏个 数量级，所以评价⼀个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进 复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。\n分析: 有哪些数据结构可以用来作为索引的存储容器?\nHashTable 优点： HashTable是字典（dict）的一种经典实现，通过对Key进行散列值计算，我们可以直接得到对应数据的存放位置，可以实现时间复杂度为O(1)的极快的查找速度。\n缺点：\n不支持模糊匹配，由于哈希计算没有局部特性，例如hash(枫阿雨)跟hash(枫阿)没有关系 不支持范围匹配，没有顺序性 不支持组合索引，因为hash值需要合在一起计算，所以不能支持最左匹配原则 哈希冲突问题 跳表 优点： 跳表基于链式结构，可以多点之间的直接连接，每个节点可以有多个指针指向不同的next节点，查询的时间复杂度为O(n)，但如果节点指针设计的好，可以跳过某些不需要查询的节点，直接定位到数据，可以让n的值变小，从而带来比较大的性能提升\n缺点：\nMySQL数据库的存储介质在磁盘当中，而链式结构的结构体存放在内存当中，而且MySLQL进行数据索引的时候是以块的形式，即每个块为16KB的内存页，然后在内存页中进行数据的定位，而跳表所使用的是我们所谓的链表中的Node节点，而且指针管理非常复杂，不适用于磁盘存储介质 MySQL中涉及的查询较多且复杂，如果使用联合索引在跳表的数据结构下，假设有两个字段做联合索引，首先我们需要按首字段进行排序，基于此基础上再对第二个字段进行排序，如果在查询过程中使用跳表，除了要维护第一个的多个节点的跳跃指针，还要想办法维护第二个节点的跳跃指针，指针的管理将会非常的困难，而且还要分别进行不同列的标记。如果多个字段的联合索引则更复杂。 客观上，跳表这种数据结构的出现并应用的时间较晚，此时MySQL已有了自己的实现方式 红黑树 优点： 红黑树是一种近似平衡（不完全平衡），结点非黑即红的树，它的树高最高不会超过 2logn，因此查找的时间复杂度为 O(logn)，无论是增删改查，它的性能都十分稳定。\n缺点：\n因为二叉树的只有两个子节点，相同存储容量时，树的高度太高，每次节点的访问都对应着一次磁盘IO，红黑树属于一种二叉树，虽然拥有稳定平衡的功能，但是大量的磁盘IO在应用程序中是灾难性的，即若红黑树的高度为20，那么最坏情况下读取一个数据需要进行20次磁盘IO这显然是无法接受的 B-树 优点： B-树是一种专门为磁盘数据读取设计的一种度为n的多路平衡查找树。既然二叉树因为每个结点最多只有两个子结点，最终在存储大量数据时导致树高太高，因此不适合当做 MySQL 的索引，那么让树的每个结点尽可能多的拥有多个子结点，这样在大量储存数据时，树高就相对低很多了，磁盘IO的次数也就大大减少 缺点： 每个节点中既要存索引信息，又要存其对应的数据，如果数据很大，那么当树的体量很大时，每次读到内存中的树的信息就会不太够。 B树遍历整个树的过程和二叉树本质上是一样的，仍需要中序遍历，B树相对二叉树虽然提高了磁盘IO性能，但并没有解决遍历元素效率低下的问题。 B+树 优点： B+树相比B树，本质上是一样的，区别就在与B+树的所有根节点都不带有任何数据信息，只有索引信息，所有数据信息全部存储在叶子节点里，这样，整个树的每个节点所占的内存空间就变小了，读到内存中的索引信息就会更多一些，相当于减少了磁盘IO次数，且所有叶子节点都会在同一层，B+树会以一个链表的形式将所有叶子节点的信息全部串联起来，这样，遍历所有数据信息只需要顺序遍历叶子节点就可以了。不仅如此，B+树还有一个相应的优质特性，就是B+树的查询效率是非常稳定的，因为所有信息都存储在了叶子节点里面，从根节点到所有叶子节点的路径是相同的。\n缺点： B+树在非叶子节点上不存储数据，有些时候会相对B树有更多的磁盘IO\n索引组织表 相比于正常存储方式。优化了遍历搜索的性能损失。\n聚集索引 辅助索引（非聚集索引） 回表： 通过辅助索引定位到聚集索引\n索引的优化 使用层面 索引列选择 选择适当的索引，索引应有区分度。如果某个字段的取值范围很广，几乎没有重复，即属于高选择性 的字段适合作为索引\n最左前缀原则 如果进行模糊查询，查找 name 的第一个字为”孙“开头的所有人的id，即SQL语句为\n1 SELECT id FROM student WHERE name like \u0026#39;孙%\u0026#39;; 由于在B+ 树结构的索引中，索引项时按照索引定义里面出现的字段顺序排序的，索引在查找的时候，可以快速定位到ID为 100 的 “孙a” ，然后直接向右遍历所有姓名为 “孙” 开头的人，直到条件不满足位置。也就是说，我们找到第一个满足条件的之后，直接向右遍历就可以了，由于索引是有序的，所有满足条件的人都会聚集到一起。\n而这种定位到最左边，然后向右遍历寻找，就是我们所说的最左前缀原则。\n联合索引 联合索引时指对表上的多个列进行索引\n1 2 3 ALTER TABLE buy_log ADD KEY(user_id); ALTER TABLE buy_log ADD KEY(user_id, buy_date); ALTER TABLE buy_log ADD KEY(user_id, buy_date, price); 情况1： 如果只对于userid进行查询\n1 SELECT * FROM buy_log WHERE user_id = 2; 索引选择：优化器的最终选择是索引userid，因为该索引的叶子节点包含单个键值，所以理论上一个页能存放的记录应该更多。\n情况2： 对于userid查询并根据buy_date排序，或 对于userid和buy_date查询并根据price排序\n1 2 SELECT * FROM buy_log WHERE user_id = 1 ORDER BY buy_date DESC LIMIT 3; SELECT * FROM buy_log WHERE user_id = 1 AND buy_date = 2020 ORDER BY price DESC LIMIT 3; 索引选择：优化器最终选择的是联合索引(user_id, buy_date)，因为在联合索引中buy_date已经排序好了。根据该联合索引去除数据，无须再对buy_date做一次额外的排序操作。\n情况三： 对于userid查询并根据price排序\n1 SELECT * FROM buy_log WHERE user_id = 1 ORDER BY price DESC LIMIT 3; 此时联合索引不能直接得到结果，其还需要执行一次排序操作，因为索引（user_id，price）并未排序\n覆盖索引 即从辅助索引中就可以得到查询的记录（此时不能够使用select * 操作，只能对特定的索引字段进行select），而不需要查询聚集索引的记录。使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以 减少大量的IO操作 。\n1 SELECT COUNT(*) FROM buy_log; InnoDB存储引擎并不会选择通过查询聚集索引来进行统计。由于buy_log表上还有辅助索引，而辅助索引远小于聚集索引，而辅助索引远小于聚集索引，选择辅助索引可以减少IO操作。\n用一句人话概括：直接从辅助索引拿数据\n避免索引失效 Like 开头以%开头 导致失效\n1 SELECT id FROM student WHERE name = ‘%三’; OR 前后有任意一项不是索引字段则失效\n1 2 3 4 -- age 为索引字段 SELECT id FROM student WHERE age \u0026gt; 10 OR age \u0026lt; 20；-- 索引正常使用 SELECT id FROM student WHERE age \u0026gt; 10 OR score \u0026gt; 80；-- 索引失效 SELECT id FROM student WHERE score \u0026gt; 80 OR age \u0026gt; 10；-- 索引失效 联合查询\n1 2 3 4 -- 联合索引（age，score）id为主键 SELECT id FROM student WHERE age \u0026gt; 10 AND score \u0026gt; 80; -- 索引正常使用 SELECT id FROM student WHERE score \u0026gt; 80; -- 索引失效 -- 没有从联合索引的首元素开始进行索引，则索引失效 索引字段进行算数运算 导致索引失效\n1 2 SELECT id FROM student WHERE age = 10; -- 索引正常使用 SELECT id FROM student WHERE age - 1 = 10; -- 索引失效 NOT 取负面（取非）的结果集 导致索引失效\n1 2 3 SELECT id FROM student WHERE age != 10; -- 索引失效 SELECT id FROM student WHERE age \u0026lt;\u0026gt; 10; -- 索引失效 SELECT id FROM student WHERE age IS NOT 10; -- 索引失效 NULL 可能 导致索引失效\n1 2 3 4 5 -- 并不会百分百造成索引失效， -- MySQL不会对NULL值创建索引，即NULL值在创建索引时会被抛弃 -- （所以逻辑上永远不会为空的字段应加上非空约束，如有逻辑上为空的情况，建议设置默认值约束） SELECT id FROM student WHERE age IS NULL; -- 索引失效 SELECT id FROM student WHERE age IS NOT NULL; -- 索引失效 方法函数 索引列使用内置函数时 可能 导致索引失效\n1 2 3 -- SELECT birth_date FROM student WHERE DATE_ADD(birth_date, -1) = CURRENT_DATE(); -- 索引失效 SELECT birth_date FROM student WHERE birth_date = CURRENT_DATE() + 1; -- 正常使用 类型转换 导致索引失效\n1 2 3 4 5 6 -- phone varchar(11) -- MySQL中的内置函数默认自动把字段值数字类型转换为字符，以匹配phone的类型 -- 因为字符串转整型会出现很多种情况，如\u0026#34;111\u0026#34; \u0026#34; 111\u0026#34; \u0026#34;111a\u0026#34;都会转换为整型的 111，故此时不使用索引 SELECT phone FROM student WHERE phone = 12345678901; -- 索引失效 SELECT phone FROM student WHERE phone = \u0026#39;12345678901\u0026#39;; -- 索引正常使用 -- 注：当隐式转换时 整型 转 字符串 则不受影响，因为整型转字符串的结果是唯一的 同一语句在某些版本 可能 导致索引失效\n1 2 -- age 为索引字段 SELECT * FROM student age \u0026gt; 3; 是否使用索引？\n首先，age是辅助索引，根据age查找到的是主键，仍需回表去查询聚簇索引来获得整行的数据。所以有两种可能。\n因为age已经排好序，通过索引查找 age \u0026gt; 3 效率很高。所以有使用age索引的必要。 因为有回表的过程，排好序对应的主键id未必是排好序的，仍需多次额外的io查找，不如直接遍历聚簇索引 两种理由都有道理。MySQL在 5.6版本 前后有不同的选择。\n5.6版本 之前，无论是否有age的辅助索引，都要走全表扫描，即遍历聚簇索引，不会使用辅助索引。\n如果直接回表的话会有3次IO多次查询，如果有n条数据需要回表，即额外需要 n* 3 = 3n 次IO，代价较大（这其实就是离散读的概念），\n如果直接全表扫描的话就是聚簇索引3次IO定位到叶子节点，然后根据叶子节点的链表遍历，可能也有多次IO，也并非轻松\n所以MySQL设置了一个阈值，当需要查询的数据占到总数据的一定量的时候就会全表扫描，没有到达阈值的时候就根据辅助索引回表多次查询。所以可能失效也可能不失效。\n5.6版本 之后，引入了 Multi-Range Read (MRR)优化，专门为解决离散读的问题。\n执行上述查询语句的时候会进行3次IO使用辅助索引找到所有 age \u0026gt; 3 的主键id，然后将这些数据放在缓存中，并将这些id进行了排序（在InnoDB引擎层面进行这些操作）。然后根据这些排序的主键id进行查询，省略了多次回表的过程。在支持MRR优化后，针对离散读的场景，能够优化10倍以上的效率。\n存储引擎层面 MRR优化（针对离散读） 离散读：\n假设表：t_index。其中 id 为主键；c1 与 c2 组成了联合索引（c1，c2）；此外 c1 还是一个 单独索引。\n​\t进行如下查找操作：\n1 SELECT * FROM t_index WHERE c1 \u0026gt; 1 AND c1 \u0026lt; 100000; 在最后的索引使用中，优化器选择了 PRIMARY id 聚集索引，也就是表扫描（table scan），而非 c1 辅助索引扫描（index scan）。\n因为如果强制使用c1索引，就会造成离散读。具体原因在于用户要选取的数据是整行信息，而c1作为辅助索引不能覆盖到我们要查询的信息，因此在对c1索引查询到指定数据后，还需要一次书签访问来查找整行数据的信息。虽然c1索引中数据是顺序存放的，但是再进行聚簇索引查找的数据是无序的，因此变味了磁盘上的离散读操作。如果要求访问的数据量很小，则优化器还会选择辅助索引，但是当访问的数据占整个表中数据的蛮大一部分时（一般是20%左右），优化器会选择通过聚簇索引来查找数据。\nMRR：\n在MySQL 5.6之后开始支持Multi-Range Read（MRR）优化。MRR 优化的目的就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问，这对于IO-bound类型的SQL查询语句可带来性能极大的提升。MRR可适用于eq_ref、ref、range级别的索引\n索引的级别：system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; all\nMRR优化的执行过程：\n将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据时根据辅助索引键值排序的。 将缓存中的键值根据RowID进行排序 根据RowID的排序顺序来访问实际的数据文件 MRR 还可以将某些范围查询拆分为键值对，以此来进行批量的数据查询。这样的好处是可以在拆分过程中，直接过过滤一些不符合条件的数据\n1 SELECT * FROM student WHERE id \u0026gt;= 1000 AND id \u0026lt; 2000 AND age = 1000; 表 student 有 （id, age）的联合索引，因此索引根据id、age的位置关系进行排序。若没有MRR，此时查询类型为Range，SQL优化器会先将id大于1000且小于2000的数据都去除，即使age不等于1000。待取出行数据后再根据age条件进行过滤。这会导致无用的数据被取出。如果有大量的数据且其age不等于1000，则启用MRR优化会使性能有巨大的提升。\n若启用MRR优化，优化器会先将查询条件进行拆分，然后再进行数据查询。久上述查询语句而言。优化器会将查询条件拆分为 (1000, 1000), (1001, 1000), (1002, 1000) , \u0026hellip;, (1999, 1000)，最后再根据这些拆分出的条件进行数据的查询。\n优化策略：在非必要的情况，拒绝使用 select * ，在必须 select * 的情况下，尽量使用MySQL 5.6 以后的版本并开启MRR\nICP优化 和MRR优化一样，Index Condition Pushdown (ICP) 同样是MySQL 5.6开始支持的一种根据索引进行查询的优化方式。在之前的版本中，当进行索引查询时，首先根据索引来查找记录，然后再根据WHERE条件来过滤记录。在支持ICP后。MySQL数据库会在取出索引的同时，判断是否可以进行WHERE条件的过滤，也就是将WHERE的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层SQL层对记录的索取（fetch），从而提高数据库的整体性能\nFIC（快速索引创建）优化 在5.5版本之前，MySQL数据库对于索引的添加或者删除的DDL操作，MySQL数据库的操作过程为以下几步：\n首先创建一张新的临时表，表结构为通过命令ALTER TABLE新定义的结构 然后把原表中的数据导入到临时表 接着删除原表 最后把临时表重命名为原来的表名 如果对于一张大表进行索引的添加和删除操作，那么会需要很长的时间。更关键的是若有大量事务需要访问正在被修改的表，这意味着数据库服务不可用。\n从InnoDB 1.0.x 版本开始支持一宗称为 FIC （Fast Index Creation）的索引创建方式\n对于辅助索引的创建，InnoDB存储引擎会对创建索引的表加上一个 S锁 。在创建的过程中，不需要重建表，因此速度较之前提高很多，并且数据库的可用性也得到了提高。删除辅助索引操作就更难了，InnoDB存储引擎只需要更新内部视图，并将辅助索引的空间标记为可用（不影响辅助索引的使用，因为可读），同时删除MySQL数据库内部视图上对该表的索引定义即可\n但是，由于FIC在索引的创建过程中对表加上了S锁，因此在创建的过程中只能对该表进行读操作，若有大量的事务需要对目标表进行写操作，那么数据库的服务同样不可用。此外，FIC反射光hi只限定于辅助索引，对于主键的创建和删除通用需要重建一张表\nOnline DDL（在线数据定义） 在MySQL5.6版本开始支持Online DDL操作，其允许辅助索引创建的同时，还允许其他诸如INSERT、UPDATE、DELETE这类DML操作，极大地提高了MySQL数据库在生产环境中的可用性\n不仅是辅助索引，以下几类DDL操作东可以通过“在线”的方式进行操作：\n辅助索引的创建与删除 改变子增值 添加或删除外键约束 列的重命名 使用语法：\n1 2 3 4 5 ALTER TABLE tbl_name | ADD{INDEX | KEY} [index_name] [index_type] (index_col_name,...) [index_option]... ALGORITHM [=] {DEFAULT | INPLACE | COPY} LOCK [=] {DEFAULT | NONE |SHARED | EXCLUSIVE} ALGORITHM 制定了创建或删除索引的算法，COPY 表示按照MySQL 5.1版本之前的工作方式，即创建临时表的方式。INPLACE 表示索引创建或删除操作不需要创建临时表。 DEFAULT 表示根据参数 old_alter_table 来判断是通过 INPLACE 还是 COPY的算法，该参数的默认值为OFF，表示采用个INPLACE的方式\nLOCK 部分索引创建或删除时对表添加锁的情况：\nNONE\n执行索引创建或者删除操作时，对目标表不添加任何的锁，即事务仍然可以进行读写操作，不会受到阻塞。因此这种模式可以获得最大的并发度。\nSHARE\n和之前的FIC类似，执行索引创建或删除操作时，对目标表加上一个S锁，对于并发地读事务，依然可以执行，但是遇到写事务，就会发生等待操作。\nEXCULSIVE\n在EXCULSIVE模式下，执行索引创建或删除操作时，对目标表加上一个X锁。读写事务都不能进行，因此会阻塞所有的线程，这和COPY方式运行得到的状态类似，但是不需要像COPY方式那也创建一张临时表。\nDEFAULT\nDEFAULT模式会先判断当前操作是否可以使用NONE模式，若不能，则判断是否可以使用SHARE模式，最后判断是否可以使用EXCLUSIVE模式，也就是说DEFAULT会通过判断事务的最大并发性来判断执行DDL的模式。\nInnoDB存储引擎实现Online DDL 的原理是在执行创建或者删除操作的同时，将INSERT、UPDATE、DELETE这类DML操作日志写入到一个缓存中，待完成索引创建后再将重做应用到表上，以此达到数据的一致性。\n由于Online DDL 在创建索引完成后再通过重做日志达到数据库的最终一致性，这意味着再索引创建过程中，SQL优化器不会选择正在创建中的索引。\nMySQL表设计与索引调优 表的设计阶段 单行数据量的要求，MySQL底层的内存页的大小为16KB，所以一条数据如果是16KB，则一个内存页只能存储一条数据，这是不可接受的，如果1条数据为1KB则能存储16条数据。之所以提到内存页，因为MySQL的每次IO就是读取一个内存页的数据，所以要保证单行数据量的值要尽量的小。为此，在初期需求分析的时候就要做到数据尽量的小，比如存放一个UUID，如果要存放32位的UUID，则直接定死为32位，不要浪费存储空间，否则当数据达到一定规模的时候会影响到B+树的整体结构，B+树拥有高扇出性，每一个节点对应着16KB的内存页，对于3层高的B+树，根节点存放着16KB的主键与指针，假设主键为bigint8个字节，指针固定为6个字节，所有对应着有16KB / 14B 约等于 1170 个指针，每个指针指向一个节点，第二层的每个节点的结构与根节点均相似，所以第二层则总共扇出1170 * 1170 个页子节点，若每条数据长1KB，则一个三层高的B+树能够存储 1170 * 1170 * 16 条数据，约等于两千万多条，如果一个数据大小为16KB则存储容量就大打折扣了。所以在设计阶段就要保证数据大小。在做设计的时候也应该或用枚举，比如性别男女分别用0和1来表示，一可以保证检索快速二可以控制数据量的大小，就能增加相同高度的B+树的数据容纳量。\n数据操作时索引的设计 MySQL中的三种索引，聚簇索引、辅助索引、覆盖索引。\n聚簇索引，每张表只有一个，即 PRIMARY KEY；辅助索引，是开发时额外增加的索引，每个辅助索引对应着一颗B+树；覆盖索引，本质是没有树的。在SQL的设计的时候首先要确保一点，不要使用SELECT *，它必须要走聚集索引，也就是要全表扫描，只有在聚集索引中才有全部的数据。如果要使用的话尽量使用5.6以后的版本，因为5.6以后有了针对离散读的MRR优化和ICP优化，这样 SELECT * 的查询速度会更快。着重提一下覆盖索引，在对于索引进行设计的时候，如果需要查询n个字段，如果保证这个n个字段都可以作为索引的话就尽量设置索引，因为在辅助索引中储存索引的值和主键的值，就可以避免回表查询。在书写SQL的时候，多使用执行计划查看索引是否失效，因为在特定的场景和函数下，MySQL的索引可能会失效\n","date":"2022-04-17T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/cfclogo03.png","permalink":"https://Kirov7.github.io/p/mysql%E7%B4%A2%E5%BC%95%E5%8F%8A%E5%85%B6%E4%BC%98%E5%8C%96%E6%80%BB%E7%BB%93/","title":"MySQL索引及其优化总结"},{"content":"Volatile 全解读 Volatile 的定义 在多线程并发编程中synchronized和volatile都扮演着重要的角色，volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。\nJava语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便（读多写少）。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。\n保证可见性； 禁止指令重排序。\nVolatile 的实现原理 - 可见性 volatile是如何来保证可见性的呢？对volatile进行写操作时，CPU会做什么事情。\n如 Java代码如下。\n1 instance = new Singleton(); // instance是volatile变量 转变成汇编代码，如下。\n1 2 0x01a3de1d: movb $0×0,0×1104800(%esi); 0x01a3de24: lock addl $0×0,(%esp); 有volatile变量修饰的共享变量进行写操作的时候会多出第二行汇编代码，通过查IA-32架构软件开发者手册可知，Lock前缀的指令在多核处理器下会引发了两件事情。\n1）将当前处理器缓存行的数据写回到系统内存（主存。声言Lock信号）。 2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。\nLock前缀指令会引起处理器缓存回写到内存。Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存（主存只有当前处理器一个人可以访问，锁总线）。但是，在最近的处理器里，LOCK＃信号一般不锁总线，而是锁缓存，毕竟锁总线开销的比较大。 对于Intel486和Pentium处理器，在锁操作时，总是在总线上声言LOCK#信号。但在P6和目前的处理器中，如果访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，它会锁定这块内存区域的缓存并回写到内存（总线锁定声言lock信号的，为了提高性能，高级的处理器走的是缓存锁定，改哪里锁定哪里，所以不需要声言lock信号。），并使用缓存一致性机制来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时修改由两个以上处理器缓存的内存区域数据。\n一个处理器的缓存回写到内存会导致其他处理器的缓存无效。IA-32处理器和Intel 64处理器使用MESI（修改、独占、共享、无效）控制协议去维护内部缓存和其他处理器缓存的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如，在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。\nvolatile可见性原理总结：\n为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。\nVolatile 使用的优化 著名的Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类Linked-TransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。LinkedTransferQueue的代码如下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //队列中的头部节点 private transient final PaddedAtomicReference\u0026lt;QNode\u0026gt; head; //队列中的尾部节点 private transient final PaddedAtomicReference\u0026lt;QNode\u0026gt; tail; static final class PaddedAtomicReference \u0026lt;T\u0026gt; extends AtomicReference T\u0026gt; { //使用很多4个字节的引用追加到64个字节 Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe; PaddedAtomicReference(T r) { super(r); } } public class AtomicReference \u0026lt;V\u0026gt; implements java.io Serializable { private volatile V value; //省略其他代码 } 追加字节能优化性能？这种方式看起来很神奇，但如果深入理解处理器架构就能理解其中的奥秘。让我们先来看看LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，它追加了15个变量（共占60个字节），再加上父类的value变量，一共64个字节。\nVolatile 实现原理 - 禁止指令重排序 为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。\n下面是基于保守策略的JMM内存屏障插入策略。\n在每个volatile写操作的前面插入一个StoreStore屏障。\n在每个volatile写操作的后面插入一个StoreLoad屏障。\n在每个volatile读操作的后面插入一个LoadLoad屏障。\n在每个volatile读操作的后面插入一个LoadStore屏障。\n上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。\n如图：StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。\n这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile读的前面 插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。 当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。\n图中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。\n上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面通过具体的示例代码进行说明。\n1 2 3 4 5 6 7 8 9 10 11 12 13 class VolatileBarrierExample { int a; volatile int v1 = 1; volatile int v2 = 2; void readAndWrite() { int i= v1; //第一个volatile读 int j = v2; //第二个volatile读 a = i+j; //普通写 v1 = i+ 1; //第一个volatile写 v2 = j * 2; //第二个volatile写 } ... //其他方法 } JSR-133增强volatile的内存语义 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。\n当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。\n当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。\n在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量重排序。这样会产生问题。\n在旧的内存模型中，当1和2之间没有数据依赖关系时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。\n未使用 Volatile 下的双重检查锁 基于 Volatile 的解决方案 大众式的讲解。因为面试过程中，绝大多数面试官都认为是volatile禁止了 new 对象里边三行代码的重排序。 因为new instance 他是一个 JVM 指令码，对应的是 new 指令。 Volatile能够保障单个JVM 指令的原子性，所以此处， new instace相当于是volatiole写，会在 new instance前加 storestore，后加storeload屏障，b线程就必须在storeload 屏障后边读取。（不建议面试使用。）实质上，new对象里边的三个小步骤，依然可以重排序，真正的控制是在外层的内存屏障控制。\n基于类初始化的解决方案 JVM在类的初始化阶段（即在Class被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。\n","date":"2022-03-06T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/Javaconcurrency.png","permalink":"https://Kirov7.github.io/p/%E7%B2%BE%E8%AF%BBjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF%E5%9B%9B/","title":"精读《Java并发编程的艺术》(四)"},{"content":"Redis 底层数据结构 动态字符串 SDS (Simple Dynamic String) 1 2 3 4 5 6 7 8 9 10 11 12 13 struct sdshdr { //SDS所保存字符串的长度 int len; // 记录buf数组中未使用字节的数量 int free; // 字节数组，用于保存字符串 char buf[]; }; // set msg “hello world” // 对于 msg 来说，它的 sdshdr 这个对象的值是： len=3； free=3；buf[]= [‘m’, ‘s’, ‘g’,‘\\0’] SDS的核心优势 C语言中的字符串如果想要得到长度，需要进行遍历，意味着时间复杂度为O(n)，如果使用SDS，可以直接从len属性中获取长度O(1)\nC语言的字符串如果进行扩展或者缩减，必须提前分配内存空间或有意识的进行空间的释放。无论是进行扩展还是缩减，都需要进行内存的重新分配。SDS不会造成缓冲区溢出的问题\n当创建SDS对象的时候，free空间也会分配当前的字符串相同大小的空间，预防进行字符串的扩展，扩展时可以直接使用，无需进行空间分配，即空间预分配。如果存储的key是超过1MB的字符串，free就分配1MB，当需要对字符串进行缩减时，惰性空间释放\n二进制安全问题。C语言的字符串是二进制不安全的，因为C语言空字符结尾的设计，如果一个字符串中间有空字符串，那么C语言的字符串二进制转化会遗弃第一个空字符出现的后边的所有内容。SDS则不会，SDS是二次封装的对象，能够支持二进制的安全。\nC语言的空字符结尾有二进制问题，为什么SDS的buf里面还是以空字符串的结尾？\n因为SDS基于C语言实现，也需要使用C语言中字符串的一些方法，所以为了兼容一部分C语言中字符串的操作，所以以空字符串结尾\n链表结构 列表键的底层实现就是一个链表，链表中的每个节点都保存了一个数值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 typedef struct list { // 表头节点 listNode * head; // 表尾节点 listNode * tail; // 链表所包含的节点数量 unsigned long len; // 节点值复制函数 void *(*dup)(void *ptr); // 节点值释放函数 void (*free)(void *ptr); // 节点值对比函数 int (*match)(void *ptr,void *key); } list; // lpush list 0 1 2 \u0026#34;hello\u0026#34; \u0026#39;a\u0026#39; // list 就代表了我们的 typedef struct list 结构体, listNode就是底层实现的链表节点 typedef struct listNode { // 前置节点 struct listNode *prev; // 后置节点 struct listNode *next; // 节点的值 void *value; }listNode; // 为什么是 void? // void 这里代表的是 多态 // 对于 redis 来说，由于 list 里可以存放各种类型的数值，那么，如果你要进行多种类型值的一些统一操作的话，需要使用 void 的返回值类型，这里体现了 我们 多态的一个性质。 列表，链表，字符串的关系示例 1 rpush list \u0026#34;a\u0026#34; \u0026#34;b\u0026#34; \u0026#34;c\u0026#34; list就是列表（源码时list：listNode的关系，底层实现为链表ListNode） SDS 第一个SDS：为key \u0026ldquo;list\u0026quot;准备，free = 4; len = 4; buf = [list\\0]；，这是列表的名称，列表的key 第二个SDS：为a准备，以此类推，第四个SDS时给c准备的 SDS的a b c这三个对象保存到listNode源码里边的 void *value属性中（多态） ","date":"2022-02-28T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/redis-study.png","permalink":"https://Kirov7.github.io/p/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%BA%8C--%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-sds%E5%92%8C%E9%93%BE%E8%A1%A8/","title":"Redis学习笔记(二)--底层数据结构 SDS和链表"},{"content":"Java内存模型 - JMM Java内存模型技术 Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。\n在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享（“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local Variables），方法定义参数（Java语言规范称之为Formal Method Parameters）和异常处理器参数（Exception Handler Parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。\nJava线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。\n指令重排序 在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。\n1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。\n对于处理器重排序，JMM的处理器重排序规则会要求 Java编译器 在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。\nJMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。\n内存屏障 StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。\nHappen-Before 原则 happens-before是JMM最核心的概念。对应Java程序员来说，理解happens-before是理解JMM的关键。\n从JDK 5开始，Java使用新的JSR-133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。\n与程序员密切相关的happens-before规则如下。 1）程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。 2）监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。 3）volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。 4）传递性：如果A happens-before B，且B happens-before C，那么A happens-before C。 5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。 6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。\n两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前\nas-if-serial语义 as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。\n为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。\nhappens-before关系本质上和as-if-serial语义是一回事。\nas-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。 as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。 as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。\n锁的获取与释放的内存语义 1 2 3 4 5 6 7 8 9 10 class MonitorExample { int a = 0; public synchronized void writer() {　// 1 a++;　// 2 }　// 3 public synchronized void reader() {　// 4 int i = a;　// 5 …… }　// 6 } 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。（隐式通信） ","date":"2022-02-21T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/Javaconcurrency.png","permalink":"https://Kirov7.github.io/p/%E7%B2%BE%E8%AF%BBjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF%E4%B8%89/","title":"精读《Java并发编程的艺术》(三)"},{"content":"Redis 基础 基本命令 通用命令 select\n示例：\n1 2 select 0 # 选择0号数据库 keys\n示例：\n1 2 3 4 5 keys he* keys he[h-l]* keys ph? # 根据Pattern表达式查询符合条件的Key # 注意：不要在生产环境中使用，会阻塞线程 dbsize\n示例：\n1 2 dbsize # 返回key的总数 exists\n示例：\n1 2 exists a # 查询key=a是否存在 del\n示例：\n1 2 del a # 删除key=a的数据 expire\n示例：\n1 2 expire hello 20 # 设置key=hello 在20s后过期 ttl\n示例：\n1 2 ttl hello # 查看key=a的过期剩余时间 flashdb\n示例：\n1 2 flashdb # 清空当前数据库中的所有数据 flashall\n示例：\n1 2 flashall # 删除所有数据库中的所有数据 Redis 常用的五种数据结构 Redis 数据类型 - 字符串 value可以是字符串，可以是数字，可以是位数字\nString最大512MB，建议单个KV不超过100KB\n字符串结构应用类型 缓存 秒杀 分布式锁 配置中心 对象序列化 计数器 Redis 字符串指令 get\n示例：\n1 2 get hello # 获得key=hello的结果 set\n示例：\n1 2 set hello world # 设置key=hello , value=world mset / mget\n示例：\n1 2 3 mset hello world java best mget hello java # 一次性 设置 或者 获取 多个kv getset\n示例：\n1 2 setget db mongodb # 设置新值返回旧值，若没有旧值则返回null并赋予新值 setnx\n1 2 3 setnx job programmer setnx job farmer # 执行失败 # 指定key不存在时设置，若存在则不设置 del\n示例：\n1 2 del hello # 删除key=hello的数据 incr / decr\n示例：\n1 2 3 incr count decr count # key值 自增 / 自减 1 incrby / decrby\n示例：\n1 2 3 incrby count 99 decrby count 99 # key值 自增 / 自减 指定步长 Redis 数据类型 - hash Redis hash 是一个 string 类型的 field (字段) 和 value (值) 的映射表，hash 特别适合用于存储对象。Redis 中每个 hash 可以存储 2^32^ -1 个键值对（40多亿）。可以理解为每个key存储了一个HashMap对象，通过一个Key可以保存一个数据结构。\nhash应用场景 Hash用于存储结构化数据，比如员工i谢谢你，用户信息等等\nRedis Hash 命令 hset\n示例：\n1 2 hset myhash field \u0026#34;foo\u0026#34; # 设置单个hash字值段 hmset\n1 2 hmset myhash field1 \u0026#34;hello\u0026#34; field2 \u0026#34;world\u0026#34; # 设置多个hash字值段 hget\n1 2 hget myhash field1 # 提取一个redis的key的某个哈希值 hgetall\n1 2 hgetall myhash # 提取一个redis的key的所有哈希值，以键/n值/n的形式返回 hexists\n1 hexists myhash field hdel\n1 2 hdel myhash field1 filed2 # 删除n条记录 hval\n1 2 hval myhash # 返回hash的value的列表，key不存在返回空表 Redis 数据类型 - List List列表是简单的字符串列表，按照插入顺序排序。可以添加元素到列表的头部（左边）或者尾部（右边）\n一个列表最多可以包含 2^32^-1个元素\nList 应用场景 保存有需数据队列，例如：排行榜ID队列 / XX购物车商品ID队列 / XX班级ID队列\n获取到ID队列后，再根据每一个ID获取对应的HASH对象\nRedis List 命令 rpush\n1 2 rpush listkey c b a # 在队尾插入新数据 lpush\n1 2 lpush listkey f e d # 在队首插入新数据 lrange\n1 2 3 4 5 6 lrange listkey 0 -1 # d e f c b a # 获取所有 lrange listkey 0 2 # d e f # 获取队列数据 rpop\n1 2 3 rpop listkey # a # 从右侧弹出数据 lpop\n1 2 3 lpop listkey # d # 从左侧弹出数据 Redis 数据类型 - Set Redis 的 Set 是 String 类型的无序集合。集合成员是唯一的，即不会存在重复的数据\nRedis 中 Set 集合是通过 哈希表 实现的，故添加、删除。查找的复杂度都是O(1)，对Set操作的执行效率极高\n集合中的最大成员数为 2^32^-1 个元素\nRedis Set 应用场景 Set数据类型常用于交际 / 并集 / 差集 运算\n典型场景为：\n我与XX位好友共同关注了XXX 将两个数据源的数据清单进行合并 找出X与Y集合的差异 抽奖活动 Redis Set 命令 sadd\n1 2 3 sadd user:1:follow fay sadd user:1:follow kirov faye harry # 新增set数据 smembers\n1 2 3 smembers user:1:follow # fay harry faye kirov (不保证顺序) # 查看set数据 srandmember\n1 2 srandmember user:1:follow 2 # fay kirov (不保证顺序,不改变原集合中的顺序) spop\n1 2 3 spop user:1:follow # fay (随机且改变原集合) # 随机弹出一个元素 sdiff\n1 2 3 sdiff user:2:follow user:1:follow # sports ent news # sdiff计算的是以左侧Set为基准，查找在右侧Set不存在的条目 sinter\n1 2 sinter user:1:follow user:2:follow # 计算交集 sunion\n1 2 sunion user:1:follow user:2:follow # 计算并集 Redis 数据类型 - ZSet Redis 的 ZSet 是 String 类型的有序Set集合。集合成员是唯一的，即不会存在重复的数据\nZSet 和 List 的区别\nList 强调数据是按存储顺序有序排列，存储顺序与迭代顺序是一致的\nZSet 则是给出分数进行排序，存储顺序与迭代顺序是不一致的\nRedis ZSet 应用场景 各种多维度排行榜\nRedis ZSet 命令 zadd\n1 2 zadd player:ranke 1000 fay 900 kirov 800 pinkman 600 grovy # 新增数据 zrange\n1 2 3 4 5 zrange player:rank 0 -1 # grovy pinkman kirov fay zrange player:rank 0 -1 with scores # grovy 600 pinkman 800 kirov 900 fay 1000 (将分值一并写出) # 根据分值从小到大进行排列 zscore\n1 2 zscore play:rank fay # 获取分数 zrank\n1 2 zrank play:rank fay # 获取排名 zrevrank\n1 2 zrank play:rank fay # 反向排名 zrevrange\n1 2 3 zrevrange player:rank 0 -1 zrevrange player:rank 0 -1 with scores # 反向排序 zrem\n1 2 zrem play:rank grovy # 移除指定元素 zcount\n1 2 3 zcount player:rank 700 1000 # 3 # 获取符合分数要求数据量 zrangebyscore\n1 2 zrangebyscore player:rank 700 1000 wiht scores # pinkman 800 kirov 900 fay 1000 Redis 开发规约 Key 的设计 不同类型的应用场景 Redis 的安全建议 Redis 不要在外网被访问，禁止：bind 0.0.0.0 - bind 192.168.132.128 更改 Redis 端口，不要6379 port : 8838 Redis 使用非 root 启动 Redis 没有设置密码或者弱密码，不要与登陆密码相同 requirepass 与 masterauth 定期备份，save 命令 配置号 Linux 防火墙规则 ","date":"2022-02-17T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/redis-study.png","permalink":"https://Kirov7.github.io/p/redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80--%E5%9F%BA%E7%A1%80%E5%91%BD%E4%BB%A4/","title":"Redis学习笔记(一)--基础命令"},{"content":"synchronized 全解读 Synchronized的特性 有序性\n读读、写写、写读、读写 都是互斥的，只有一条线程拿到当前的锁，当前锁不释放，其他线程只能处于BLOCK状态，等待锁的释放，然后加入下一步的竞争\n可见性\n完全排他\n原子性\n本质上是线程互斥保证的原子性\n可重入性\nSynchronized锁升级 - Mark Word（32bit） Synchronized锁升级 - 偏向锁 至少JDK1.6 版本且开启了偏向锁配置。 偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。\n被加锁的对象，没有真正、或者隐式的调用父类 Object 里边的hashcode方法。\n如果一旦调用了object的hashcode方法，那么我们的对象头里边就有真正的hashcode值了，如果偏向锁来进行markword的替换，至少要提供一个保存hashcode的地方吧？可惜的是，偏向锁并没有地方进行markword的保存，只有轻量级锁才会有“displace mark word”\n为了让线程获得锁的代价更低而引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头（存储线程id） 和栈帧中的锁记录里（线程有自己的栈帧，LOCK RECORD: 存储当前线程id） 存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向 当前线程的偏向锁。（id的匹配） 如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的 偏向锁指向当前线程（ 其实是cas竞争替换 线程id）。\n注：相当于给每个每个对象固定“偏向”某个线程，没有竞争时只需要线程确认栈内记录的身份是否还偏向自己，如果身份还是匹配，则不需要真正的加锁。如果mark word中偏向的线程不是自己，则检测是否是偏向锁，如果不是则CAS锁升级争夺轻量级锁。如果目标是偏向锁，则用CAS更改mark word中偏向的线程\nSynchronized锁升级 - 偏向锁的撤销 偏向锁使用了一种等到竞争出现才释放锁的机制，一旦有竞争则升级到轻量级锁（简单且不严谨的说法）\n偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。 （包括锁不升级时的严谨说法）\nA线程获取偏向锁，并且A线程死亡退出。B线程争抢偏向锁，会直接升级当前对象的锁为轻量级锁。这只是针对我们争抢了一次。 A线程获取偏向锁，并且A线程没有释放偏向锁（），还在syhnc的代码块里边。B线程此时过来争抢偏向锁，会直接升级为重量级锁。 A线程获取偏向锁，并且A线程释放了锁，但是A线程并没有死亡还在活跃状态。B线程过来争抢，会直接升级为轻量级锁。 综上所述，当我们尝试第一次竞争偏向锁时，如果A线程已经死亡，升级为轻量级锁；如果A线程未死亡，并且未释放锁，直接升级为重量级锁；如果A线程未死亡，并且已经释放了锁，直接升级为轻量级锁。 A线程获取偏向锁，并且A线程没有释放偏向锁（），还在syhnc的代码块里边。B线程多次争抢锁，会在加锁过程中采用重量级锁；但是，一旦锁被释放，当前对象还是会以轻量级锁的初始状态执行。 A线程获取偏向锁，并且A线程释放了锁，但是A线程并没有死亡还在活跃状态。B线程过来争抢。部分争抢会升级为轻量级锁；部分争抢会依旧保持偏向锁。 Synchronized锁升级 - 偏向锁的重偏向与批量撤销 偏向锁状态变化与最终升级为轻量级锁：\nA 线程获取偏向锁成功，已经退出执行不再是活跃线程； B线程过来获取偏向锁，默认前20次直接升级为轻量级锁 （触发批量重偏向阈值之前， 默认为 20次争抢，不同机器环境参数配置不一样）； A 线程获取偏向锁成功，已经退出执行不再是活跃线程； B线程过来获取偏向锁，默认20次以后，直接偏向线程 B。达到40次阈值后，若再有其他线程C过来争抢，则触发批量撤销。该对象不再有任何偏向锁的情况。 批量重偏向： 当我们的一个对象，Object 类，在经过默认 20次的争抢的情况下，会将后边的所有争抢从新偏向争抢的线程。当B线程争抢第 18 次的时候，触发了批量重偏向的阈值；在第20次以及以后的争抢里，jvm会将线程偏向线程b，因为jvm认为，这个对象更加适合线程B\n批量撤销： 如果基于批量重偏向的基础上，还在继续进行争抢达到40次，并且有第三条线程C加入了，这个时候会触发批量撤销。JVM会标记该对象不能使用偏向锁，以后新创建的对象，直接以轻量级锁开始。 这个时候，才是真正的完成了锁升级。\n真正的锁升级，是依赖于 class 的（加锁对象实例对应的类），而并不是依赖于 某一个 new出来的对象（偏向锁升级为轻量级锁）。\nSynchronized锁升级 - 轻量级锁加锁与解除 （1）轻量级锁加锁 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间（Lock Record记录），并将对象头中的Mark Word（前30位 （25位的hashcode，4位的分代年龄，1位是否为偏向锁））复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针（指向线程栈帧里边的Lock Record的指针）。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。\n（2）轻量级锁解锁 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word（Lock Record记录）替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。\n轻量级锁升级为重量级锁：这个时候，只要我们的线程发生了竞争，并且CAS替换失败，就会发起锁膨胀，升级为重量级锁（针对的是一个对象实例）\nSynchronized锁升级 - 轻量级锁升级为重量级锁 轻量级锁\u0026mdash;重量级锁： 释放锁（前四步）并唤醒等待线程\n线程1 初始化monitor 对象； 将状态设置为膨胀中（inflating）； 将monitor里边的header属性，set称为对象的markword；（将自己lock record里边的存放的mark word的hashcode，分代年龄，是否为偏向锁 set 到 objectmonitor对象的header属性里） 设置对象头为重量级锁状态（标记为改为00）；然后将前30位指向第1步初始化的monitor 对象；（真正的锁升级是由线程1操控的） 唤醒线程2； 线程2 开始争抢重量级锁。（线程2就干了一件事儿，就是弄了一个临时的重量级锁指针吧？还不是最后的重量级锁指针。因为最后的重量级锁指针是线程1初始化的并且是线程1修改的。 而且，线程2被唤醒之后，还不一定能够抢到这个重量级锁。Sync是非公平锁。 线程2费力不讨好，但是线程2做了一件伟大的事情：他是锁升级的奠基者。） Synchronized锁升级 - Markword转化过程（重难点） 创建一个对象，此时对象里边没有hashcode，所以该对象可以使用我们的偏向锁，偏向锁不会考虑hashcode， 他会直接将自己的线程id放到我们的markword里边，不需要考虑后续的替换问题。 所以呢，一旦我们的对象主动调用了Object的hashcode方法，我们的偏向锁就自动不可用了。\n如果我们的对象有了hashcode和分代年龄和是否为偏向锁（30位）。在轻量级锁的状态下，这30位会被复制到我们的轻量级锁线程持有者的栈帧里的lock record里边记录。与此同时，我们的对象的markword里边存放的是我们的指向轻量级锁线程持有者的栈帧的lock recod里。如果一直存在轻量级锁竞争，在未发生锁膨胀的前提下，一直会保持轻量级锁，A线程释放的时候，会将markword替换回对象的markword里边，B线程下次再从新走一遍displace mark word；\n一旦发生了轻量级膨胀为重量级锁。前提，A线程持有锁；B线程争抢。 B线程将marikword里边A线程的指针替换成一个临时的（过渡的）重量级锁指针，为了让A线程在cas往回替换markword的时候失败。 A线程替换回markword失败后，会发起：1.初始化monitor对象；2. 将状态设置为膨胀中；3 将替换失败的 markword 放到 objectmonitr o的head属性里； 4。改变markword的锁标志为10；将markword里的 30 位设置为指向自己第一步初始化的那个monitor对象；5唤醒B线程； 6以后这个对象只能作为重量级锁；\nMarkword从未丢失。\n死锁 - 产生条件与避免 （学院派的严谨理论）\n死锁产生的四个必要条件：\n互斥：一个资源每次只能被一个进程使用 (资源独立)。 请求与保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放 (不释放锁)。 不剥夺：进程已获得的资源，在未使用之前，不能强行剥夺 (抢夺资源)。 循环等待：若干进程之间形成一种头尾相接的循环等待的资源关闭 (死循环)。 如何避免死锁：\n破坏” 互斥” 条件：系统里取消互斥、若资源一般不被一个进程独占使用，那么死锁是肯定不会发生的，但一般 “互斥” 条件是无法破坏的，因此，在死锁预防里主要是破坏其他三个必要条件，而不去涉及破坏 “互斥” 条件。 破坏 “请求和保持” 条件： 方法 1：所有的进程在开始运行之前，必须一次性的申请其在整个运行过程各种所需要的全部资源。 优点：简单易实施且安全。 缺点：因为某项资源不满足，进程无法启动，而其他已经满足了的资源也不会得到利用，严重降低了资源的利用率，造成资源浪费。 方法 2：该方法是对第一种方法的改进，允许进程只获得运行初期需要的资源，便开始运行，在运行过程中逐步释放掉分配到，已经使用完毕的资源，然后再去请求新的资源。这样的话资源的利用率会得到提高，也会减少进程的饥饿问题。 破坏 “不剥夺” 条件：当一个已经持有了一些资源的进程在提出新的资源请求没有得到满足时，它必须释放已经保持的所有资源，待以后需要使用的时候再重新申请。这就意味着进程已占有的资源会被短暂的释放或者说被抢占了。 破坏 “循环等待” 条件：可以通过定义资源类型的线性顺序来预防，可以将每个资源编号，当一个进程占有编号为 i 的资源时，那么它下一次申请资源只能申请编号大于 i 的资源。 （简易说法）\n避免死锁的几个常见方法：\n避免一个线程同时获取多个锁。 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。 对于数据库锁，加锁和解锁必须在一个数据库连接里（分布式数据库），否则会出现解锁失败的情况。 ObjectMonitor的五个重要属性 header ： 重量级锁保存markword的地方 own: 指向我们持有锁的线程；对象的markword里边也保存了指向monitor的指针； _cxq 队列： 竞争队列。 A线程持有锁没有释放； B和C线程同时过来争抢锁，都被block了，此时会将B和C线程加入到 该队列。 EntryList队列：同步队列。A线程释放锁，B和C线程中会选定一个继承者（可以去争抢锁的这个线程），另外一个线程会被放入我们的EntryList队列里边。 waitset：等待队列。Object wait的线程。 A线程持有锁，BC线程过来竞争失败，进入cxq \u0026ndash; 下轮竞争会把 cxq里的线程移动到EntrylIst中。假设B线程竞争到了锁，然后B线程调用了 Object.Wait方法，这时候B线程进入waitset，并释放锁。C线程拿到了锁，然后唤醒B线程。B线程会从waitset里边出来，直接竞争锁。如果竞争失败进入cxq，继续轮回，如果竞争成功，ok了。\nCPU的用户态与内核态 CPU 的两种工作状态：内核态（管态）和用户态（目态）。\n内核态：\n系统中既有操作系统的程序，也有普通用户程序。为了安全性和稳定性，操作系统的程序不能随便访问，这就是内核态。即需要执行操作系统的程序就必须转换到内核态才能执行！ 内核态可以使用计算机所有的硬件资源！ 用户态： 不能直接使用系统资源，也不能改变 CPU 的工作状态，并且只能访问这个用户程序自己的存储空间！\n当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为 3 级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3 状态不能访问 Ring0 的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为 0 级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。\n用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。如果要执行文件操作、网络数据发送等操作必须通过 write、send 等系统调用，这些系统调用会调用内核的代码。进程会切换到 Ring0，然后进入内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到 Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。\n用户态与内核态切换的触发条件 当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。 用户态切换到内核态的 3 种方式 （1）系统调用 这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如 fork（）就是执行了一个创建新进程的系统调用。系统调用的机制是使用了操作系统为用户特别开放的一个中断来实现，如 Linux 的 int 80h 中断。 （2）异常 当 cpu 在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。 （3）外围设备的中断 当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。\n这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤有事一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。\n","date":"2022-02-08T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/Javaconcurrency.png","permalink":"https://Kirov7.github.io/p/%E7%B2%BE%E8%AF%BBjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF%E4%BA%8C/","title":"精读《Java并发编程的艺术》(二)"},{"content":"并发编程初探 Java天生的多线程 当前的main函数就是一个JVM进程，在IDEA中可以看到共有6条线程\n查看线程信息：jps（拿到线程的tid） + jstack（查看线程日志）\nprio是进程中的优先级，os_prio是操作系统给线程定义的优先级，prio前加上deamo则为守护线程\n[6] Monitor Ctrl-Break （跟JVM 关系不大，他是 IDEA 通过反射的方式，开启一个随着我们运行的jvm进程开启与关闭的一个监听线程。）\ndaemon prio=5 （可延迟开启）\n**[5] Attach Listener **（附加监听器。 简单来说，他是jdk里边一个工具类提供的jvm 进程之间通信的工具。 cmd \u0026ndash; java -version; jvm \u0026ndash; jstack、jmap、dump） 进程间的通信。\ndaemon prio=5 （可延迟开启）\n开启我们这个线程的两个方式： 1. 通过jvm参数开启。-XX: StartAttachListener延迟开启： cmd \u0026ndash; java -version \u0026ndash;\u0026gt; JVM 适时开启A L 线程\n[4] Signal Dispatcher （信号分发器。 我们通过cmd 发送jstack，传到了jvm进程，这时候信号分发器就要发挥作用了。）\ndaemon prio=9\n[3] Finalizer JVM 垃圾回收相关的内容。\ndaemon prio=10 高优先级的守护线程。 只有当开始一轮垃圾收集的时候，才会开始调用finalize方法。 jvm在垃圾收集的时候，会将失去引用的对象封装到我们的 Fianlizer 对象（Reference）， 放入我们的 F-queue 队列中。由 Finalizer 线程执行inalize方法 Finalizer 专注垃圾收集，垃圾收集 \u0026ndash; 并行收集，不阻碍用户线程，低优先级线程。 prio=8 他是一个守护线程啊。而且这个线程目前并没有真正的开启，不足以发生minorgc或者是 full gc [2] Reference Handler （引用处理的线程。强，软，弱，虚。 -GC 有不同表现 - JVM深入分析）\n引用处理线程-GC相关线程\ndaemon prio=10（GC很重要，优先级较高）\n[1] main 主线程\nprio=5\n操作系统面向的是JVM 进程，JVM 进程里面向的是 我们的main函数，。所以对于我们的操作系统如何看待我们的main函数优先级，无所谓。 只要os 给我们jvm进程足够公平的优先级就行。\n线程的状态 注：上图的 Obejct.join() 应为 Thread.join()\nThread.Sleep() 和 Object.Wait() Thread.Sleep()\n不释放锁 响应中断（对中断敏感） 会释放CPU Obeject.wait()\n会释放锁 响应中断（对中断敏感） 会释放CPU，让出时间片并进入等待队列 注：wait(0)表示永久等待\nThread.join() 底层调用Object.Wait()\n会释放锁\nThread的join方法，释放的是当前调用 join方法的那个对象的锁。\n1 2 3 4 5 6 synchronized (obj){ thread.join();//不释放锁 } synchronized (Thread.currentThread){ thread.join();//释放锁 } 响应中断（对中断敏感）\n线程间的通讯方式 volitate 、synchronize、lock。（都保证可见性）\nwait、notify、await() 、 signal\n管道输入、输出流**（已过时）**\n管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要用于线程之间的数据传输，而传输的媒介为内存。管道输入/输出流主要包括了如下4种具体实现：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，而后两种面向字符。\nThread.join() ： 隐式唤醒。等待其他线程执行完成，其他线程会发送唤醒信号。\nThradLocal()：支持子线程集成的一种形式。\n线程中断\n线程中断时，sleep()会先清理中断标记，再抛出异常，导致thread.interupted = flase\n","date":"2022-01-24T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/Javaconcurrency.png","permalink":"https://Kirov7.github.io/p/%E7%B2%BE%E8%AF%BBjava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF%E4%B8%80/","title":"精读《Java并发编程的艺术》(一)"},{"content":"Java并发编程学习笔记 Java 创建线程的三种方式 先看一看在Thread类源码中的注释是怎么写的\nThere are two ways to create a new thread of execution. One is to declare a class to be a subclass of Thread. This subclass should override the run method of class Thread. An instance of the subclass can then be allocated and started. For example, a thread that computes primes larger than a stated value could be written as follows:\n1 2 3 4 5 6 7 8 9 10 11 class PrimeThread extends Thread { long minPrime; PrimeThread(long minPrime) { this.minPrime = minPrime; } public void run() { // compute primes larger than minPrime . . . } } The following code would then create a thread and start it running:\n1 2 PrimeThread p = new PrimeThread(143); p.start(); The other way to create a thread is to declare a class that implements the Runnable interface. That class then implements the run method. An instance of the class can then be allocated, passed as an argument when creating Thread, and started. The same example in this other style looks like the following:\n1 2 3 4 5 6 7 8 9 10 11 class PrimeRun implements Runnable { long minPrime; PrimeRun(long minPrime) { this.minPrime = minPrime; } public void run() { // compute primes larger than minPrime . . . } } The following code would then create a thread and start it running:\n1 2 PrimeRun p = new PrimeRun(143); new Thread(p).start(); Every thread has a name for identification purposes. More than one thread may have the same name. If a name is not specified when a thread is created, a new name is generated for it.\n1. 继承Thread类创建线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class lab1 { public static void main(String[] args) { //创建一个新的线程 Runner person01 = new Runner(); //给线程命名 person01.setName(\u0026#34;PERSON01\u0026#34;); //启动线程 Runner person02 = new Runner(); person02.setName(\u0026#34;PERSON02\u0026#34;); person01.start(); person02.start(); } } class Runner extends Thread{ @Override public void run() { Integer speed = new Random().nextInt(100); for (int i = 0; i \u0026lt;= 100; i++) { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(this.getName() + \u0026#34;已前进\u0026#34; + (i * speed) + \u0026#34;米(\u0026#34; + speed +\u0026#34;米/秒)\u0026#34;); } } } 此时在这段Java程序中有哪几个线程?\n主线程 PERSON01线程 PERSON02线程 垃圾回收监听线程 即Java在运行时永远不会是单一的线程\n2. 实现Runnable接口创建线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class lab2 { public static void main(String[] args) { Runner02 person03 = new Runner02(); Thread thread03 = new Thread(person03); thread03.setName(\u0026#34;PERSON03\u0026#34;); Thread person04 = new Thread(new Runner02()); person04.setName(\u0026#34;PERSON04\u0026#34;); new Thread(new Runner02()).start(); thread03.start(); person04.start(); } } class Runner02 implements Runnable{ @Override public void run() { Integer speed = new Random().nextInt(100); for (int i = 0; i \u0026lt;= 100; i++) { try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } //Thread.currentThread().getName() 用于获取当前执行的线程对象 //在 Runnable 中是无法使用 this 获取到当前线程对象的 System.out.println(Thread.currentThread().getName() + \u0026#34;已前进\u0026#34; + (i * speed) + \u0026#34;米(\u0026#34; + speed +\u0026#34;米/秒)\u0026#34;); } } } 3. 使用Callable和Future创建线程 jDK1.5以后为我们专门提供了一个并发工具包java.util.concurrent java.util.concurrent包含许多线程安全、测试良好、高性能的并发构建块。创建concurrent的目的就是要实现Collection框架对数据结构所执行的并发操作。通过提供一组可靠的、高性能并发构建块，开发人员可以提高并发类的线程安全、可伸缩性、性能、可读性和可靠性。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 public class lab3 { public static void main(String[] args) throws ExecutionException, InterruptedException { //创建一个线程池,里面自带三个\u0026#34;空\u0026#34;线程 Executors 是调度器,对线程池进行管理 ExecutorService executorService = Executors.newFixedThreadPool(3); //实例化 Callable 对象 Runner03 person04 = new Runner03(); person04.setName(\u0026#34;PERSON04\u0026#34;); Runner03 person05 = new Runner03(); person05.setName(\u0026#34;PERSON05\u0026#34;); Runner03 person06 = new Runner03(); person06.setName(\u0026#34;PERSON06\u0026#34;); //将整个对象扔到线程池中, 线程池自动分配一个线程来运行person04对象的 call方法 //Future 用于接收线程池内部call方法的返回值 Future\u0026lt;Integer\u0026gt; result04 = executorService.submit(person04); Future\u0026lt;Integer\u0026gt; result05 = executorService.submit(person05); Future\u0026lt;Integer\u0026gt; result06 = executorService.submit(person06); try { Thread.sleep(5000); } catch (InterruptedException e) { e.printStackTrace(); } //关闭线程池,释放所有资源 executorService.shutdown(); System.out.println(\u0026#34;PERSON04累计跑了: \u0026#34; + result04.get() + \u0026#34;米\u0026#34;); System.out.println(\u0026#34;PERSON05累计跑了: \u0026#34; + result05.get() + \u0026#34;米\u0026#34;); System.out.println(\u0026#34;PERSON06累计跑了: \u0026#34; + result06.get() + \u0026#34;米\u0026#34;); } } //使用Callable 允许返回值 和 抛出异常 class Runner03 implements Callable\u0026lt;Integer\u0026gt;{ private String name; public void setName(String name){ this.name = name; } //实现 Callable接口可以允许我们的线程返回值或抛出异常 @Override public Integer call() throws Exception { Integer speed = new Random().nextInt(100); Integer distince = 0;//总共奔跑的距离 for (int i = 0; i \u0026lt;= 100; i++) { Thread.sleep(10); distince = i * speed; System.out.println(this.name + \u0026#34;已前进\u0026#34; + distince + \u0026#34;米(\u0026#34; + speed + \u0026#34;米/秒)\u0026#34;); } return distince; } } 优点 缺点 使用场景 继承Thread 编程简单 单继承 无法对线程组有效控制 不推荐使用 实现Runnable 面向接口编程 执行效率高 无法对线程组有效控制没有返回值、异常 简单的多线程程序 利用线程池 容器管理线程 允许返回值和异常 执行效率相对低 编程复杂 企业级应用 推荐使用 synchronized的使用场景 synchronized代码块 - 任意对象即可\n在堆中的对象对象头中的线程id指向当前线程,线程中的record mark记录当前对象头的信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class classSample{ //锁对象 Obeject obj = new Object(); public void methodSample01(){ synchronized(obj){ //待同步代码 . . . } } public void methodSample02(){ synchronized(obj){ //待同步代码 . . . } } } synchronized方法 - this当前对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class classSample{ public synchronized void methodSample01(){ //待同步代码 . . . } //给方法加锁等同于给this对象加锁 public void methodSample02(){ synchronized(this){ //待同步代码 . . . } } } synchronized静态方法 - 该类的字节码对象\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class classSample{ public synchronized static void methodSample01(){ //待同步代码 . . . } //给静态方法加锁等同于给类的字节码对象加锁 public void methodSample02(){ synchronized(classSample.class){ //待同步代码 . . . } } } 线程的五种状态 新建 (new) 就绪 (ready) 运行中 (running) 阻塞 (blocked) 死亡 (dead) 死锁 死锁是在多线程情况下最严重的问题，在多线程对公共资源 （文件、数据）等进行操作时，彼此不释放自己的资源，而 去试图操作其他线程的资源，而形成交叉引用，就会产生死锁\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class DeadLock { private static String fileA = \u0026#34;A文件\u0026#34;; private static String fileB = \u0026#34;B文件\u0026#34;; public static void main(String[] args) { new Thread(){//线程1 @Override public void run() { while (true) { //打开文件A,线程独占 synchronized (fileA) { System.out.println(this.getName() + \u0026#34;: 文件A写入\u0026#34;); synchronized (fileB) { System.out.println(this.getName() + \u0026#34;: 文件B写入\u0026#34;); } System.out.println(this.getName() + \u0026#34;: 所有文件保存\u0026#34;); } } } }.start(); new Thread(){//线程1 @Override public void run() { while (true) { //打开文件A,线程独占 synchronized (fileB) { System.out.println(this.getName() + \u0026#34;: 文件B写入\u0026#34;); synchronized (fileA) { System.out.println(this.getName() + \u0026#34;: 文件A写入\u0026#34;); } System.out.println(this.getName() + \u0026#34;: 所有文件保存\u0026#34;); } } } }.start(); } } 解决死锁最根本的建议是： 尽量减少公共资源的引用，用完马上释放 用完马上释放公共资源 减少synchronized使用，采用“副本”方式替代 线程安全 在拥有共享数据的多条线程并行执行的程序中，线程安全的代码会通过同步机制保证各个线程都可以正常且正确的执行，不会出现数据污染等意外情况\n线程安全 优点：可靠\n缺点：执行速度慢\n使用建议：需要线程共享时使用\n线程不安全 优点：速度快\n缺点：可能与预期不符\n使用建议：在线程内部使用，无 需线程间共享\n列举线程安全与不安全的类 StringBuffer是线程安全的，StringBuilder是线程不安全的\nHashTable是线程安全的，HashMap是线程不安全的\nProperties是线程安全的，HashSet、TreeSet是不安全的\nVector是线程安全的，ArrayList、LinkedList是线程不安全的\nThreadPool 线程池 new Thread() 的弊端 new Thread()新建对象性能差 线程缺乏统一管理，可能无限制的新建线程，相互竞争，严重时会占用过多系统资源导致死机或OOM ThreadPool 线程池 重用存在的线程，减少对象创建、消亡的开销 线程总数可控，提高资源的利用率 避免过多的资源竞争，避免阻塞 提供额外功能，定时执行、定期执行、监控等 线程池的种类 在JUC中，提供了工具类Executors（调度器）对象来创建线程池，可创建的线程池有四种：\nCachedThreadPool：可缓存线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 public class ThreadPoolSample01 { public static void main(String[] args) { //Executors调度器对象 //ExecutorService用于管理线程池 //创建一个可缓存线程池 //可缓存线程池的特点,无限大,如果线程池中没有可用的线程则创建,有空闲则利用 ExecutorService threadPool = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt;= 1000; i++) { final int index = i; threadPool.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; : \u0026#34; + index); } }); } try { //给线程足够的运行时间 Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } //threadPool.shutdown() 代表关闭线程池(等待所有线程完成) //threadPool.shutdownNow() 代表立即终止线程池的运行,不等待线程,不推荐使用(强制关闭) threadPool.shutdown(); } } FixedThreadPool：定长线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class ThreadPoolSample02 { public static void main(String[] args) { //创建一个定长线程池 //定长线程池的特点,固定线程总数,空闲线程用于执行任务,如果线程都在使用 //后续任务则处于等待状态(备选的等待算法为 FIFO(默认)和 LIFO) //在线程池中的线程执行任务后再执行后续的任务 ExecutorService threadPool = Executors.newFixedThreadPool(3); for (int i = 0; i \u0026lt;= 1000; i++) { final int index = i; threadPool.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; : \u0026#34; + index); } }); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } threadPool.shutdown(); } } SingleThreadExecutor：单线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 public class ThreadPoolSample03 { public static void main(String[] args) { //Executors调度器对象 //ExecutorService用于管理线程池 //创建一个单线程线程池 ExecutorService threadPool = Executors.newSingleThreadExecutor(); for (int i = 0; i \u0026lt;= 1000; i++) { final int index = i; threadPool.execute(new Runnable() { @Override public void run() { System.out.println(Thread.currentThread().getName() + \u0026#34; : \u0026#34; + index); } }); } try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } threadPool.shutdown(); } } ScheduledThreadPool：调度线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public class ThreadPoolSample04 { public static void main(String[] args) { //Executors调度器对象 //ExecutorService用于管理线程池 //创建一个可调度线程池 ScheduledExecutorService scheduledThreadPool = Executors.newScheduledThreadPool(5); //延迟三秒执行一次run // scheduledThreadPool.schedule(new Runnable() { // @Override // public void run() { // System.out.println(\u0026#34;延迟3s执行\u0026#34;); // } // }, 3, TimeUnit.SECONDS); //在使用可调度线程池后 Timer类就可以不再使用 //但是在项目实际开发中两者都不会被用到, //因为有着更为成熟的调度框架 Quartz 或 Spring自带调度 scheduledThreadPool.scheduleAtFixedRate(new Runnable() { @Override public void run() { System.out.println(new Date() + \u0026#34; 延迟1s执行,每3s执行一次\u0026#34;); } }, 1, 3, TimeUnit.SECONDS); } } CountDownLatch 倒计时锁 CountDownLatch倒计时锁适合\u0026quot;总-分任务\u0026quot;，例如多线程计算后的数据汇总，可以实现类似计数器的功能\nCDL执行原理 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 public class CountDownSample { private static int count = 0; public static void main(String[] args) { ExecutorService threadPool = Executors.newFixedThreadPool(100); //CDL总数和操作数保持一直 CountDownLatch cdl = new CountDownLatch(10000); for (int i = 0; i \u0026lt;= 10000; i++) { final int index = i; threadPool.execute(new Runnable() { @Override public void run() { synchronized (CountDownSample.class) { try { count += index; } catch (Exception e) { e.printStackTrace(); } finally { cdl.countDown(); } } } }); } try { //堵塞当前线程,直到cdl=0的适合再继续往下走 cdl.await(); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(count); threadPool.shutdown(); } } Semaphore 信号量 Semaphore信号量经常用于限制获取某种资源的线程数量\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class SemaphoreSample01 { public static void main(String[] args) { //用来装载等待的请求 ExecutorService threadPool = Executors.newCachedThreadPool(); //定义5个信号量,即服务器只允许5个请求同时进行 Semaphore semaphore = new Semaphore(5); for (int i = 1; i \u0026lt;= 20 ; i++) { final int index = i; threadPool.execute(new Runnable() { @Override public void run() { try { //获取一个信号量, 占用一个\u0026#34;使用权\u0026#34; semaphore.acquire(); use(); //执行完成后释放这个信号量, 结束服务使用 semaphore.release(); } catch (InterruptedException e) { e.printStackTrace(); } } }); } threadPool.shutdown(); } public static void use(){ try { System.out.println(new Date() + \u0026#34; \u0026#34; + Thread.currentThread().getName() + \u0026#34;获得服务器使用资格\u0026#34;); Thread.sleep(2000); System.out.println(new Date() + \u0026#34; \u0026#34; + Thread.currentThread().getName() + \u0026#34;退出服务器\u0026#34;); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } } } 服务已满终止等待提示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 public class SemaphoreSample02 { public static void main(String[] args) { ExecutorService threadPool = Executors.newCachedThreadPool(); Semaphore semaphore = new Semaphore(5); for (int i = 1; i \u0026lt;= 20 ; i++) { final int index = i; threadPool.execute(new Runnable() { @Override public void run() { try { //尝试获取一次信号量,获取到返回true否则返回false if (semaphore.tryAcquire(6, TimeUnit.SECONDS)){ use(); semaphore.release(); } else{ System.out.println(Thread.currentThread().getName() + \u0026#34; 对不起,服务器已满,请稍后再试\u0026#34;); } } catch (InterruptedException e) { e.printStackTrace(); } } }); } threadPool.shutdown(); } public static void use(){ try { System.out.println(new Date() + \u0026#34; \u0026#34; + Thread.currentThread().getName() + \u0026#34;获得服务器使用资格\u0026#34;); Thread.sleep(2000); System.out.println(new Date() + \u0026#34; \u0026#34; + Thread.currentThread().getName() + \u0026#34;退出服务器\u0026#34;); Thread.sleep(500); } catch (InterruptedException e) { e.printStackTrace(); } } } CyclicBarrier 循环屏障 CyclicBarrier 是一个同步工具类，它允许一组线程互相等待，直到到达某个公共屏障带你。与CDL不同的是该barrier再释放等待线程后可以宠用，所以称为循环(Cyclic)屏障(Barrier)。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class CyclicBarrierSample { private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) { ExecutorService threadPool = Executors.newCachedThreadPool(); for (int i = 1; i \u0026lt;= 20; i++) { final int index = i; try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } threadPool.execute(new Runnable() { @Override public void run() { go(); } }); } threadPool.shutdown(); } private static void go(){ System.out.println(Thread.currentThread().getName() + \u0026#34; 准备就绪\u0026#34;); try { //设置屏障点,当累计五个线程都准备好后,才运行后面的代码 cyclicBarrier.await(); System.out.println(Thread.currentThread().getName() + \u0026#34; 开始运行\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } catch (BrokenBarrierException e) { e.printStackTrace(); } } } CyclicBarrier 应用场景 适用于多线程必须同时开始的场景，抢票秒杀等等\nReentrantLock 重入锁 重入锁是指任意线程在获取到锁之后，再次获取该锁而不会被该锁所阻塞\nReentrantLock设计的目标是用来替代synchronized关键字1\n特征 synchronized（推荐） ReentrantLock 底层原理 JVM实现 JDK实现 性能区别 低 -\u0026gt; 高 (JDK5+) 高 锁的释放 自动释放 (编译器保证) 手动释放 (finally保证) 编码难度 简单 复杂 锁的粒度 读写不区分 读锁、写锁 高级功能 无 公平锁、非公平锁唤醒、Condition分组唤醒、中断等待锁 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 public class ReentrantLockSample { public static int users = 100;//同时模拟的并发访问用户数量 public static int downTotal = 50000; //用户下载的真实总数 public static int count = 0;//计数器 private static ReentrantLock lock = new ReentrantLock(); public static void main(String[] args) { //调度器，JDK1.5后提供的concurrent包对于并发的支持 ExecutorService executorService = Executors.newCachedThreadPool(); //信号量，用于模拟并发的人数 final Semaphore semaphore = new Semaphore(users); for (int i = 0; i \u0026lt; downTotal; i++) { executorService.execute(() -\u0026gt; { //通过多线程模拟N个用户并发访问并下载 try { semaphore.acquire(); add(); semaphore.release(); } catch (Exception e) { e.printStackTrace(); } }); } try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } executorService.shutdown();//关闭调度服务 System.out.println(\u0026#34;下载总数：\u0026#34; + count); } public static void add() { lock.lock();//上锁 try { count++; } finally { lock.unlock(); //解锁，一定要放在finally里面否则会出现死锁 } } } Condition 等待与唤醒 在并行程序中，避免不了某些线程要预先规定好顺序执行，如：先新增再修改，先买后卖，先进后出\u0026hellip;，对于这种场景，使用JUC中的Condition对象再适合不过了。\nJUC中提供了Condition对象，用于让指定线程等待和唤醒，按预期顺序执行。它必须和ReentrantLock重入锁配合使用。\nCondition用于替代wait()和/notify()方法\nnotify()只能随机唤醒等待的线程，而Condition可以唤醒指定的线程，这有利于更好的控制并发程序。 Condition核心方法 await()：阻塞当前线程，直到singal()唤醒 signal()：唤醒被await()的线程，从中断处继续执行 signalAll()：唤醒所有被await()阻塞的线程 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 public class ConditionSample { public static void main(String[] args) { //Condition对象必须配合Lock一起使用 ReentrantLock lock = new ReentrantLock(); Condition c1 = lock.newCondition();//创建Condition Condition c2 = lock.newCondition();//创建Condition Condition c3 = lock.newCondition();//创建Condition new Thread(new Runnable() { //T1 @Override public void run() { lock.lock();//加锁 try { c1.await();//阻塞当前线程,c1.signal的时候线程激活继续执行 Thread.sleep(1000); System.out.println(\u0026#34;粒粒皆辛苦\u0026#34;); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock();//解锁 } } }).start(); new Thread(new Runnable() { @Override public void run() { lock.lock();//加锁 try { c2.await(); Thread.sleep(1000); System.out.println(\u0026#34;谁知盘中餐\u0026#34;); c1.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock();//解锁 } } }).start(); new Thread(new Runnable() { @Override public void run() { lock.lock();//加锁 try { c3.await(); Thread.sleep(1000); System.out.println(\u0026#34;汗滴禾下土\u0026#34;); c2.signal(); } catch (InterruptedException e) { e.printStackTrace(); } finally { lock.unlock();//解锁 } } }).start(); new Thread(new Runnable() { @Override public void run() { lock.lock(); try { Thread.sleep(1000); System.out.println(\u0026#34;锄禾日当午\u0026#34;); c3.signal(); } catch (Exception e) { e.printStackTrace(); } finally { lock.unlock(); } } }).start(); } } Callable \u0026amp; Future Callable 和 Runnable一样代表着任务，区别在于Callable有返回值并且可以抛出异常。\nFuture 是一个接口。它用于表示异步计算的结果。提供了检查计算是否完成的方法，以等待计算的完成，并获取计算的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 //并发计算质数 public class FutureSample { public static void main(String[] args) { ExecutorService threadPool = Executors.newFixedThreadPool(10); for (int i = 2; i \u0026lt;= 10000; i++) { Computer c = new Computer(); c.setNum(i); //Future对用于计算的线程进行监听,因为计算是在其它线程中执行的,所以这个返回结果的过程是异步的 //将c对象提交给线程池,如有空闲线程立即执行里面的call方法 Future\u0026lt;Boolean\u0026gt; result = threadPool.submit(c); try { //用于获取返回值,如果线程内部的call没有执行完成,则进入等到状态,直到计算完成 Boolean r = result.get(); if (r){ System.out.println(c.getNum()); } } catch (InterruptedException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } } threadPool.shutdown(); } } class Computer implements Callable\u0026lt;Boolean\u0026gt; { private Integer num; public Integer getNum() { return num; } public void setNum(Integer num) { this.num = num; } @Override public Boolean call() throws Exception { boolean isPrime = true; for (int i = 2; i \u0026lt; num; i++) { if (num % i == 0){ isPrime = false; break; } } return isPrime; } } JUC 并发容器 ArrayList -\u0026gt; CopyOnWriteArrayList - 写复制列表\nHashSet -\u0026gt; CopyOnWriteArraySet - 写复制集合\nHashMap -\u0026gt; ConcurrentHashMap - 分段锁映射\nCopyOnWriteArrayList 并发原理 CopyOnWriteArrayList 通过\u0026quot;副本\u0026quot;解决并发问题\n1 2 3 4 5 6 7 8 9 10 11 12 public class CopyOnWriteArrayListSample { public static void main(String[] args) { List\u0026lt;Integer\u0026gt; list = new CopyOnWriteArrayList \u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; 1000; i++) { list.add(i); } for (Integer i : list) { list.remove(i); } System.out.println(list); } } CopyOnWriteArraySet 并发原理\n与CopyOnWriteArrayList类似\nConcurrentHashMap 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 public class ReentrantLockSample { public static int users = 100;//同时模拟的并发访问用户数量 public static int downTotal = 50000; //用户下载的真实总数 public static ConcurrentHashMap count = new ConcurrentHashMap();//计数器 public static void main(String[] args) { //调度器，JDK1.5后提供的concurrent包对于并发的支持 ExecutorService executorService = Executors.newCachedThreadPool(); //信号量，用于模拟并发的人数 final Semaphore semaphore = new Semaphore(users); for (int i = 0; i \u0026lt; downTotal; i++) { final Integer index = i; executorService.execute(() -\u0026gt; { //通过多线程模拟N个用户并发访问并下载 try { semaphore.acquire(); count.put(index, index); semaphore.release(); } catch (Exception e) { e.printStackTrace(); } }); } try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } executorService.shutdown();//关闭调度服务 System.out.println(\u0026#34;下载总数：\u0026#34; + count.size()); } } Atomic 包 \u0026amp; CAS 算法 原子性 是指一个操作或者多个操作要么全部执行，且执行的过程不会被任何因素打断，要么就不执行\nAtomic 包 专为线程安全而设计，包含多个原子操作类\nAtomic 常用类\nAtomicInteger AtomicIntegerArray AtomicBoolean AtomicLong AtomicLongArray 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 public class AtomicIntegerSample { public static int users = 100;//同时模拟的并发访问用户数量 public static int downTotal = 50000; //用户下载的真实总数 public static AtomicInteger count = new AtomicInteger();//计数器 public static void main(String[] args) { //调度器，JDK1.5后提供的concurrent包对于并发的支持 ExecutorService executorService = Executors.newCachedThreadPool(); //信号量，用于模拟并发的人数 final Semaphore semaphore = new Semaphore(users); for (int i = 0; i \u0026lt; downTotal; i++) { final Integer index = i; executorService.execute(() -\u0026gt; { //通过多线程模拟N个用户并发访问并下载 try { semaphore.acquire(); add(); semaphore.release(); } catch (Exception e) { e.printStackTrace(); } }); } try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } executorService.shutdown();//关闭调度服务 System.out.println(\u0026#34;下载总数：\u0026#34; + count); } //线程不安全 public static void add(){ //count++ count.getAndIncrement(); } } CAS 算法 锁是用来做并发最简单的方式，当然其代价也是最高的。独占锁是 一种悲观锁，synchronized就是一种独占锁，它假设最坏的情况， 并且只有在确保其它线程不会造成干扰的情况下执行，会导致其它 所有需要锁的线程挂起，等待持有锁的线程释放锁。\n所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。其中CAS（比较与交换，Compare And Swap） 是一种有名的无锁算法\nAtomic的应用场景 虽然基于CAS的线程安全机制很好很高效，但要说的是，并非所有线程安全都可以用这样的方法来实现， 这只适合一些粒度比较小型,如计数器这样的需求用起来才有效，否则也不会有锁的存在了求用起来才有效，否则也不会有锁的存在了\n","date":"2021-11-17T00:00:00Z","permalink":"https://Kirov7.github.io/p/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","title":"Java并发编程学习笔记"},{"content":"第七章 MySQL 锁机制 * 在MySQL中，就很容易出现多线程同时操作表中数据的情况，如果要避免潜在的并发问题，那么我们可以使用之前讲解的事务隔离级别来处理，而事务隔离中利用了锁机制。\n读未提交(Read Uncommitted)：能够读取到其他事务中未提交的内容，存在脏读问题。 读已提交(Read Committed RC)：只能读取其他事务已经提交的内容，存在不可重复读问题。 可重复读(Repeated Read RR)：在读取某行后不允许其他事务操作此行，直到事务结束，但是依然存在幻读问题。 串行读(Serializable)：一个事务的开始必须等待另一个事务的完成。 我们可以切换隔离级别分别演示一下：\n1 set session transaction isolation level read uncommitted; 在RR级别下，MySQL在一定程度上解决了幻读问题：\n在快照读（不加锁）读情况下，MySQL 通过 MVCC 来避免幻读。 在当前读（加锁）读情况下，MySQL 通过next-key来避免幻读。 MVCC，全称 Multi-Version Concurrency Control ，即多版本并发控制。MVCC 是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n第一节 读锁和写锁 从对数据的操作类型上来说，锁分为读锁和写锁：\n**读锁：**也叫共享锁，当一个事务添加了读锁后，其他的事务也可以添加读锁或是读取数据，但是不能进行写操作，只能等到所有的读锁全部释放。 **写锁：**也叫排他锁，当一个事务添加了写锁后，其他事务不能读不能写也不能添加任何锁，只能等待当前事务释放锁。 第二节 全局锁、表锁和行锁 从锁的作用范围上划分，分为全局锁、表锁和行锁：\n**全局锁：**锁作用于全局，整个数据库的所有操作全部受到锁限制。 **表锁：**锁作用于整个表，所有对表的操作都会收到锁限制。 **行锁：**锁作用于表中的某一行，只会通过锁限制对某一行的操作（仅InnoDB支持） 1. 全局锁 我们首先来看全局锁，它作用于整个数据库，我们可以使用以下命令来开启读全局锁：\n1 FLUSH TABLES WITH READ LOCK; 开启后，整个数据库被上读锁，我们只能去读取数据，但是不允许进行写操作（包括更新、插入、删除等）一旦执行写操作，会被阻塞，直到锁被释放，我们可以使用以下命令来解锁：\n1 UNLOCK TABLES; 除了手动释放锁之外，当我们的会话结束后，锁也会被自动释放。\n2. 表锁 表锁作用于某一张表，也是MyISAM和InnoDB存储引擎支持的方式，我们可以使用以下命令来为表添加锁：\n1 LOCK TABLE 表名称 READ/WRITE; 在我们为表添加写锁后，我们发现其他地方是无法访问此表的，一律都被阻塞。\n3. 行锁 表锁的作用范围太广了，如果我们仅仅只是对某一行进行操作，那么大可不必对整个表进行加锁，因此InnoDB支持了行锁，我们可以使用以下命令来对某一行进行加锁：\n1 2 3 4 -- 添加读锁（共享锁） SELECT * FROM ... LOCK IN SHARE MODE; -- 添加写锁（排他锁） SELECT * FROM ... FOR UPDATE; 使用InnoDB的情况下，在执行更新、删除、插入操作时，数据库也会自动为所涉及的行添加写锁（排他锁），直到事务提交时，才会释放锁，执行普通的查询操作时，不会添加任何锁。使用MyISAM的情况下，在执行更新、删除、插入操作时，数据库会对涉及的表添加写锁，在执行查询操作时，数据库会对涉及的表添加读锁。\n**提问：**当我们不使用索引列进行选择，行锁会发生什么变化？（行锁升级）\n如果没有走索引，引擎就无法得知SELECT语句到查询的是哪一行不，行锁就会升级为全表锁（本质为记录锁）。\n第三节 记录锁、间隙锁和临键锁 我们知道InnoDB支持使用行锁，但是行锁比较复杂，它可以继续分为多个类型。\n1. 记录锁 （Record Locks）记录锁, 仅仅锁住索引记录的一行，在单条索引记录上加锁。Record lock锁住的永远是索引，而非记录本身，即使该表上没有任何索引，那么 InnodDB 会在后台创建一个隐藏的聚集主键索引，那么锁住的就是这个隐藏的聚集主键索引。所以说当一条sql没有走任何索引时，那么将会在每一条聚合索引后面加写锁，这个类似于表锁，但原理上和表锁应该是完全不同的。\n2. 间隙锁 （Gap Locks）仅仅锁住一个索引区间（开区间，不包括双端端点）。在索引记录之间的间隙中加锁，或者是在某一条索引记录之前或者之后加锁，并不包括该索引记录本身。比如在 1、2中，间隙锁的可能值有 (-∞, 1)，(1, 2)，(2, +∞)，间隙锁可用于防止幻读，保证索引间的不会被插入数据。\n3. 临键锁 （Next-Key Locks）Record lock + Gap lock，左开右闭区间。默认情况下，InnoDB正是使用Next-key Locks来锁定记录（如select … for update语句）它还会根据场景进行灵活变换：\n场景 转换 使用唯一索引进行精确匹配，但表中不存在记录 自动转换为 Gap Locks 使用唯一索引进行精确匹配，且表中存在记录 自动转换为 Record Locks 使用非唯一索引进行精确匹配 不转换 使用唯一索引进行范围匹配 不转换，但是只锁上界，不锁下界 注：关于更多临键锁机制可以阅读此文章 MySQL的锁机制 - 记录锁、间隙锁、临键锁 - 知乎 ","date":"2021-10-14T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E4%B8%83/","title":"从零开始学MySQL(七)"},{"content":"第六章 数据库设计 第一节 设计数据库 1. 什么是实体 实体就是软件开发过程中所涉及到的事物，通常都是一类数据对象的个体。\n2. 什么是数据库设计 数据库设计就是将实体与实体之间的关系进行规划和结构化的过程\n3. 为什么要对数据库进行设计 当存储的数据比较少的时候，当然不需要对数据库进行设计。但是，当对数据的需求量越来越大时，对数据库的设计就很有必要性了！如果数据库的设计不当，会造成数据冗余、修改复杂、操作数据异常等问题。而好的数据库设计，则可以减少不必要的数据冗余，通过合理的数据规划提高系统的性能\n4. 如何设计数据库 收集信息 在确定客户要做什么之后，收集一切相关的信息，尽量不遗漏任何信息\n标识实体 实体一般是名词，每个实体只描述一件事情，不能重复出现含义相同的实体\n标识实体的详细属性\n标识每个实体需要存储的详细信息\n标识实体之间的关系 理清实体与实体之间的关系\n第二节 ER 图 1. 什么是 ER 图 ER = Entity Relational （实体关系）\nER图就是实体关系图\n2. 如何绘制 ER 图 示例：\n第三节 数据库模型图 1. 什么是关系模式 实体关系的描述称为关系模式，关系模式通常使用二维表的形式表示\n示例： 学生（学号，姓名，性别，年龄，所属班级） 班级（班级编号， 班级名称）\n2. 关系模式转为数据库模型图 将关系模式使用Navicat工具转换为数据库模型图，转换步骤如下：\n将各实体转换为对应的表，将各属性转换为各表对应的列 标识每个表的主键列 在表之间建立主外键，体现实体 第四节 数据库三大范式 1. 数据库第一范式 第一范式是最基本的范式，确保每列保持原子性，也就是每列不可再分\n示例：\n2. 数据库第二范式 第二范式是在第一范式的基础上，每张表的属性完全依赖于主键，也就是每张表只描述一件事情\n示例：\n3. 数据库第三范式 第三范式是在第二范式的基础上，确保每列都直接依赖于主键，而不是间接依赖于主键，也就是不能存在传递依赖。比如A依赖于B，B依赖于C，这样A间接依赖于C\n第五节 综合练习 假设某建筑公司要设计一个数据库。公司的业务规则概括说明如下：\n公司承担多个工程项目，每一项工程有：工程号、工程名称、施工人员等 公司有多名职工，每一名职工有：职工号、姓名、性别、职务（工程师、技术员）等 公司按照工时和小时工资率支付工资，小时工资率由职工的职务决定（例如，技术员的小时工资率与工程师不同） 分析：\n找出实体（工程、员工、职务、工时） 找出实体关系 绘制 ER 图，然后将 ER 图转换为数据库模型图 使用三大范式规范数据库设计 ER 图 数据库模型图 此时发现按照数据库模型图回推ER图时会发现关联有误，故需要更改ER图\n修改后的 ER 图 注意：在实际开发过程中，为了满足性能的需要，数据库的设计可能会打破数据库三大范式的约束。\n以空间换时间：当数据库中存储的数据越来越多时，查询效率下降，为了提升了查询效率，可能会在表中增加新的字段，此时，数据库的设计就不再满足三大范式。\n","date":"2021-10-10T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E5%85%AD/","title":"从零开始学MySQL(六)"},{"content":"第五章 存储过程、函数、触发器和视图 第一节 变量 在 MySQL中，变量分为四种类型，即局部变量、用户变量、会话变量和全局变量。其中局部变量和用户变量在实际应用中使用较多，会话变量和全局变量使用较少，因此作为了解即可。\n1. 全局变量 MySQL全局变量会影响服务器整体操作，当服务启动时，它将所有全局变量初始化为默认值。要想更改全局变量，必须具有管理员权限。其作用域为服务器的整个生命周期。\n1 2 3 4 5 6 7 8 9 10 -- 显示所有的全局变量 SHOW GLOBAL VARIABLES; -- 设置全局变量的值的两种方式 SET GLOBAL sql_warnings = ON; SET @@GLOBAL.sql_warnings = OFF; -- 查询全局变量的值的两种方式 SELECT @@GLOBAL.sql_warnings; SHOW GLOBAL VARIABLES LIKE \u0026#39;%sql_warnings%\u0026#39;; 2. 会话变量 MySQL会话变量是服务器为每个连接的客户端维护的一系列变量。其作用域仅限于当前连接，因此，会话变量是独立的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 -- 显示所有的会话变量 SHOW SESSION VARIABLES; -- 设置会话变量的值的三种方式 SET SESSION auto_increment_increment = 1; SET @@SESSION.auto_increment_increment = 2; -- 当省略SESSION关键字时，默认缺省为SESSION，即设置会话变量的值 SET auto_increment_increment = 3; -- 查询会话变量的值的三种方式 SELECT @@auto_increment_increment; SELECT @@SESSION.auto_increment_increment; -- SESSION关键字可以省略，也可以用关键字LOCAL替代 SHOW SESSION VARIABLES LIKE \u0026#39;%auto_increment_increment%\u0026#39;; SET @@LOCAL.auto_increment_increment = 1; SELECT @@LOCAL.auto_increment_increment; 3. 用户变量 MySQL用户变量， MySQL中用户变量不用提前申明，在用的时候直接用“@变量名”使用就可以了。其作用域为当前连接。\n1 2 3 4 5 6 7 8 9 10 -- 第一种用法，使用SET时可以用“=”或“:=”两种赋值符号赋值 SET @age = 18; -- 第二种用法，使用SELECT时必须用“:=”赋值符号赋值 SELECT @age := 19; SELECT @age := age FROM stu WHERE `name` = \u0026#39;枫阿雨\u0026#39;; -- 第三种用法，使用SELECT...INTO语句赋值 SELECT age INTO @age FROM stu WHERE `name` = \u0026#39;枫阿雨\u0026#39;; SELECT @age; 示例：筛选所有id大于100的成绩信息，并引入用户变量作为递增序号num\n1 2 3 4 5 6 7 SELECT (SELECT @index := @index + 1) num, a.* FROM score a, (SELECT @index := 0) b WHERE id \u0026gt; 100; 4. 局部变量 MySQL局部变量，只能用在BEGIN/END语句块中，比如存储过程中的BEGIN/END语句块。\n1 2 3 4 5 6 7 -- 定义局部变量 DECLARE age INT(3) DEFAULT 0; -- 为局部变量赋值 SET age = 10; SELECT age := 10; SELECT 10 INTO age; SELECT age; 第二节 存储过程 1. 存储过程的概念 在大型数据库系统中，存储过程是一组为了完成特定功能而存储在数据库中的 SQL语句集，一次编译后永久有效\n2. 为什么要使用存储过程 运行速度快： 在存储过程创建的时候，数据库已经对其进行了一次解析和优化。存储过程一旦执行，在内存中就会保留一份这个存储过程，下次再执行同样的存储过程时，可以从内存中直接调用，所以执行速度会比普通 SQL快。 减少网络传输： 存储过程直接就在数据库服务器上跑，所有的数据访问都在数据库服务器内部进行，不需要传输数据到其它服务器，所以会减少一定的网络传输。 增强安全性： 提高代码安全，防止 SQL被截获、篡改。 3. 如何使用存储过程 语法\n1 2 3 4 5 6 7 8 9 10 11 12 -- 声明分隔符 [DELIMITER $$] CREATE PROCEDURE 存储过程名称 ([IN | OUT | INOUT] 参数名1 数据类型, [[IN | OUT | INOUT] 参数名2 数据类型, ..., [IN | OUT | INOUT] 参数名n 数据类型]) -- 语句块开始 BEGIN -- SQL语句集 END[$$] -- 还原分隔符 [DELIMITER ; ] -- 调用存储过程 CALL 存储过程名(参数1, 参数2, ...); 语法：使用存储过程完成银行业务转账\n1 2 3 4 5 6 7 8 9 10 11 -- 创建存储过程 DELIMITER // CREATE PROCEDURE transferMoney(IN transferFROM BIGINT, IN transferTo BIGINT, IN money DOUBLE(20, 3)) BEGIN UPDATE account SET balance = balance - money WHERE account = transferFrom; UPDATE account SET balance = balance + money WHERE account = transferTo; END // DELIMITER ; -- 调用存储过程 CALL transferMoney(123456, 123456, 2000); 如果转账账户余额不足，上面的 SQL代码依然可以正常执行，只是执行完后，转账账户的余额变为了负数。这显然不符合常理。因此需要修正。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 -- 创建存储过程 DELIMITER // CREATE PROCEDURE transferMoney(IN transferFROM BIGINT, IN transferTo BIGINT, IN money DOUBLE(20, 3)) BEGIN -- 定义变量表示执行结果：0-失败，1-成功 DECLARE result TINYINT(1) DEFAULT 0; -- 转账账户必须保证余额大于等于转账金额 UPDATE account SET balance = balance - money WHERE account = transferFrom AND balance \u0026gt;= money; -- 检测受影响的行数是否为1，为1表示更新成功 IF ROW_COUNT() = 1 THEN UPDATE account SET balance = balance + money WHERE account = transferTo; -- 目标账号余额增加 IF ROW_COUNT() = 1 THEN -- 更新执行结果为1 SET result = 1; END IF; END IF; -- 查询结果 SELECT result; END // DELIMITER ; -- 调用存储过程 CALL transferMoney(123456, 123456, 2000); 如果转账账户已经将钱转出去，而在执行目标账户增加余额的时候出现了异常或者目标账户输入错误，此时应该怎么办呢？ MySQL对数据的操作提供了事务的支持，用来保证数据的一致性,可以有效的解决此类问题。\n4. 事务 4.1 什么是事务 事务( Transaction)是访问并可能操作各种数据项的一个数据库操作序列，这些操作要么全部执行,要么全部不执行，是一个不可分割的工作单位。事务由事务开始与事务结束之间执行的全部数据库操作组成。\n4.2 事务的特性(ACID) 原子性（Atomicity） 事务的各元素是不可分的（原子的）,它们是一个整体。要么都执行，要么都不执行。 一致性（Consistency） 当事务完成时，必须保证所有数据保持一致状态。当转账操作完成时，所有账户的总金额应该保持不变，此时数据处于一致性状态；如果总金额发生了改变，说明数据处于非一致性状态。 隔离性（Isolation） 对数据操作的多个并发事务彼此独立，互不影响。比如张三和李四同时都在进行转账操作，但彼此都不影响对方。 持久性（Durability） 对于已提交事务，系统必须保证该事务对数据库的改变不被丢失，即使数据库出现故障 4.3 事务解决银行转账问题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 -- 创建存储过程 DELIMITER // CREATE PROCEDURE transferMoney(IN transferFROM BIGINT, IN transferTo BIGINT, IN money DOUBLE(20, 3)) BEGIN -- 定义变量表示执行结果：0-失败，1-成功 DECLARE result TINYINT(1) DEFAULT 0; -- 声明SQLEXCEPTION处理器，当有SQLEXCEPTION发生时，错误标识符的值设为0 -- 发生SQLEXCEPTION时的处理方式：CONTINUE，EXIT -- CONTINUE表示即使有异常发生，也会执行后面的语句 -- EXIT表示，有异常发生时，直接退出当前存储过程 DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET result = 0; -- 开启事务 START TRANSACTION; UPDATE account SET balance = balance - money WHERE account = transferFrom AND balance \u0026gt;= money; IF ROW_COUNT() = 1 THEN UPDATE account SET balance = balance + money WHERE account = transferTo; IF ROW_COUNT() = 1 THEN SET result = 1; END IF; END IF; -- 如果result的值为0，表示操作存在失败的情况，事务回滚，数据恢复到更改之前的状态 IF result = 0 THEN ROLLBACK; -- 否则，表示所有操作都成功，提交事务 ELSE COMMIT; END IF; -- 查询结果 SELECT result; END // DELIMITER ; 5. 存储过程输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 -- 创建存储过程 DELIMITER // CREATE PROCEDURE transferMoney(IN transferFROM BIGINT, IN transferTo BIGINT, IN money DOUBLE(20, 3), OUT TINYINT(1)) BEGIN -- 为SQL异常声明一个持续处理的处理器，一旦出现异常，则将result的值更改为0 DECLARE CONTINUE HANDLER FOR SQLEXCEPTION SET result = 0; -- 开启事务 START TRANSACTION; UPDATE account SET balance = balance - money WHERE account = transferFrom AND balance \u0026gt;= money; -- 检测受影响的行数是否为1，为1表示更新成功 IF ROW_COUNT() = 1 THEN UPDATE account SET balance = balance + money WHERE account = transferTo; -- 执行成功则设置result值为1 IF ROW_COUNT() = 1 THEN -- 更新执行结果为1 SET result = 1; ELSE SET result = 0; END IF; ELSE SET result = 0; END IF; -- 如果result的值为0，表示操作存在失败的情况，事务回滚，数据恢复到更改之前的状态 IF result = 0 THEN ROLLBACK; -- 否则，表示所有操作都成功，提交事务 ELSE COMMIT; END IF; END // DELIMITER ; CALL transferMoney(123456, 123458, 2000 , @result) SELECT @result; 第三节 自定义函数 1.自定义函数的概念 函数就是在大型数据库系统中，一组为了完成特定功能而存储在数据库中的 SQL 语句集，一次编译后永久有效\n2. 自定义函数 MySQL本身提供了一些内置函数，这些函数给我们日常的开发和数据操作带来了很大的便利，比如聚合函数SUM()、AVG()以及日期时间函数等。但这并不能完全满足开发的需要，有时我们需要一个函数来完成一些复杂功能的实现，而 MySQL中又没有这样的函数，因此，我们需要自定义函数来实现。\n3. 如何使用自定义函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 CREATE FUNCTION 函数名称 (参数名1 数据类型, 参数名2 数据类型, ..., 参数名n 数据类型]) RETURNS 数据类型 -- 函数特征： -- DETERMINISTIC: 不确定的 -- NO SQL:没有SQL语句，当然也不会修改数据 -- READS SQL DATA: 只是读取数据，不会修改数据 -- MODIFIES SQL DATA:要修改数据 -- CONTAINS SQL：包含了SQL语句 DETERMINISTIC | NO SQL | READS SQL DATA | MODIFIES SQL DATA | CONTAINS SQL -- 语句块开始 BEGIN -- SQL语句 RETURN 结果; -- 语句块结束 END 示例：使用函数实现求score表中的成绩最大差值\n1 2 3 4 5 6 7 8 9 CREATE FUNCTION getMaxDiff() RETURNS DOUBLE(5, 2) DETERMINISTIC BEGIN RETURN (SELECT MAX(score) - MIN(score) FROM score); END -- 调用函数 SELECT getMaxDiff(); 4. 循环结构 1 2 3 4 5 6 7 8 9 10 11 12 13 WHILE 循环条件 DO -- SQL语句集 END WHILE: REPEAT -- SQL语句集 UNTIL 循环终止条件 END REPEAT; 标号: LOOP -- SQL语句集 IF 循环终止条件 THEN LEAVE 标号; END IF; END LOOP; 示例：使用函数实现求0~给定的任意整数的累加和\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 -- 使用WHILE 循环实现 CREATE FUNCTION getTotal(maxNum INT(11)) RETURNS INT(11) NO SQL BEGIN DECLARE total INT(11) DEFAULT 0; DECLARE i INT(11) DEFAULT 0; WHILE i \u0026lt;= maxNum DO SET total = total + i; SET i = i + 1; END WHILE; RETURN total; END -- 使用REPEAT UNTIL实现 CREATE FUNCTION getTotal1(maxNum INT(11)) RETURNS INT(11) NO SQL BEGIN DECLARE total INT(11) DEFAULT 0; DECLARE i INT(11) DEFAULT 0; REPEAT SET total = total + i; SET i = i + 1; UNTIL i \u0026gt; maxNum END REPEAT; RETURN total; END -- 使用LOOP实现 CREATE FUNCTION getTotal2(maxNum INT(11)) RETURNS INT(11) NO SQL BEGIN DECLARE total INT(11) DEFAULT 0; DECLARE i INT(11) DEFAULT 0; a: LOOP SET total = total + i; SET i = i + 1; IF i \u0026gt; maxNum THEN LEAVE a; END IF; END LOOP; RETURN total; END -- 调用函数 SELECT getTotal(100); SELECT getTotal1(100); SELECT getTotal2(100); 练习：使用函数实现生成一个指定长度的随机字符串\n思路：\n定义变量保存字符和数字组成字符串 定义变量保存生成的字符串 循环获取随机数，使用字符串截取的方式获得随机字符，并使用字符串拼接函数完成组装 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 CREATE FUNCTION rodomString(stringLength INT(11)) RETURNS VARCHAR(255); NO SQL BEGIN DECLARE str VARCHAR(64) DEFAULT \u0026#39;ABCDEFGHIJKLMOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789\u0026#39;; DECLARE result VARCHAR(255) DEFAULT NULL; DECLARE position INT(11); DECLARE i INT(11) DEFAULT 0; WHILE i \u0026lt; stringLength DO SELECT ROUND(RAND() * 62) INTO position; SET result = CONCAT(result, SUBSTRING(str, position, 1)); SET i = i + 1; END WHILE; RETURN result; END 5. 函数和存储过程的区别 注：此部分内容选自 函数和存储过程的区别 - 随情 - 博客园\n函数和存储过程的优点： 1、共同使用的代码可以只需要被编写一次，而被需要该代码的任何应用程序调用（.net, C++, Java，也可以使DLL库）。\n2、这种几种编写、几种维护更新、大家共享的方法，简化了应用程序的开发维护，提高了效率和性能。\n3、这种模块化的方法使得一个复杂的问题、大的程序逐步简化成几个简单的、小的程序部分，进行分别编写，因此程序的结构更加清晰，简单，也容易实现。\n4、可以在各个开发者之间提供处理数据、控制流程、提示信息等方面的一致性。\n5、节省内存空间。它们以一种压缩的形式被存储在外存中，当被调用时才被放入内存进行处理。而且多个用户在调用同一个存储过程或函数时，只需要加载一次即可。\n6、提高数据的安全性和完整性。通过把一些对数据的操作方到存储过程或函数中，就可以通过是否授予用户有执行该语句的权限，来限制某些用户对数据库进行这些操作。\n函数和存储过程的区别： 1、存储过程用户在数据库中完成特定操作或者任务（如插入，删除等），函数用于返回特定的数据。\n2、存储过程声明用PROCEDURE，函数用FUNCTION。\n3、存储过程不需要返回类型，函数必须要返回类型。\n4、存储过程可作为独立的pl-sql执行，函数不能作为独立的plsql执行，必须作为表达式的一部分。\n5、存储过程只能通过out和in/out来返回值，函数除了可以使用out，in/out以外，还可以使用return返回值。\n6、SQL语句（DML或SELECT)中不可用调用存储过程，而函数可以。\n适用场合： 1、如果需要返回多个值和不返回值，就使用存储过程；如果只需要返回一个值，就使用函数。\n2、存储过程一般用于执行一个指定的动作，函数一般用于计算和返回一个值。\n3、可以再SQL内部调用函数来完成复杂的计算问题，但不能调用存储过程。\n存储过程与存储函数的区别和联系 相同点：1.创建语法结构相似，都可以携带多个传入参数和传出参数。\n2.都是一次编译，多次执行。\n不同点：1.存储过程定义关键字用PROCEDURE，函数定义用FUNCTION。\n2.存储过程中不能用RETURN返回值，但函数中可以，而且函数中必须有RETURN子句。\n3.执行方式略有不同，存储过程的执行方式有两种（1.使用execute 2.使用begin和end），函数除了存储过程的两种方式\t外，还可以当做表达式使用，例如放在select中（ SELECT f1() FROM dual; ）。\n总结：如果只有一个返回值，用存储函数，否则，一般用存储过程。 第四节 触发器 1. 触发器概念 触发器（trigger）是用来保证数据完整性的一种方法，由事件来触发，比如当对一个表进行增删改操作时就会被激活执行。经常用于加强数据的完整性约束和业务规则\n2. 如何定义触发器 1 2 3 4 5 6 7 8 9 -- 删除触发器 DROP TRIGGER [IF EXISTS] 触发器名称; -- 创建触发器 -- 触发时机为BEFORE或者AFTER -- 触发事件，为INSERT 、 UPDATE或者DELETE CREATE TRIGGER 触发器名称 {BEFORE|AFTER} {INSERT|UPDATE|DELETE} ON 表名 FOR EACH ROW BEGIN -- 执行的SQL操作 END 3. 触发器类型 触发器类型 NEW 和 OLD 的使用 INSERT 触发器 NEW 表示将要或者已经新增的数据 UPDATE 触发器 OLD 表示将要或者已经修改的数据，NEW 表示将要修改的数据 DELETE 触发器 OLD 表示将要或者已经删除的数据 4. 触发器使用场景 场景一：现有商品表goods和订单表order，每一个订单的生成都意味着商品数量的减少，请使用触发器完成这一过程。\n1 2 3 4 5 6 7 8 9 10 11 12 -- 表数据关系 -- order 订单 id goods_id sales_id sale_count created_time state -- goods 商品 id name number price agent_id -- 创建触发器 CREATE TRIGGER addOrder AFTER INSERT ON `order` FOR EACH ROW BEGIN UPDATE goods SET number = number - NEW.sale_count WHERE id=NEW.goods_id; END -- 测试代码 INSERT INTO `order` (`goods_id`, `sales_id`, `sale_count`, `created_time`, `state`) VALUES(1, 1, 6, \u0026#39;2021-08-16\u0026#39;, 1); 场景二：现有商品表goods和订单order，每一个订单的取消都意味着商品数量的增加，请使用触发器完成这一过程。\n1 2 3 4 5 6 7 8 -- 创建触发器 CREATE TRIGGER deleteOrder AFTER DELETE ON `order` FOR EACH ROW BEGIN UPDATE goods SET number = number + OLD.sale_count WHERE id=OLD.goods_id; END -- 测试代码 DELETE FROM `order` WHERE id =350001; 场景三：现有商品表goods和订单表order，每一个订单购买数量的更新都意味着商品数量的变动，请使用触发器完成这一过程。\n1 2 3 4 5 6 7 8 9 10 11 -- 创建触发器 CREATE TRIGGER updateOrder AFTER UPDATE ON `order` FOR EACH ROW BEGIN DECLARE changeNum INT(11) DEFAULT 0; SET changeNum = NEW.sale_count - OLD.sale_count; UPDATE goods SET number = number - changeNum WHERE id = old.goods_id; END -- 测试代码 UPDATE `order` SET sale_count = sale_count + 2 WHERE id=20; UPDATE `order` SET sale_count = sale_count - 4 WHERE id=20; 第五节 视图 1. 视图的概念 视图是一张虚拟表，本身并不存储数据，当 SQL操作视图时所有数据都是从其他表中查出来，运用了封装的思想，实质类似于 子查询并重命名\n2. 如何使用视图 创建视图\n1 CREATE VIEW 视图名称 AS SELECT 列1[, 列2, ...] FROM 表名 WHERE 条件; 更新视图\n1 CREATE OR REPLACE VIEW 视图名称 AS SELECT 列1[, 列2, ...] FROM 表名 WHERE 条件; 删除视图\n1 DROP VIEW IF EXISTS 视图名称; 3. 为什么使用视图 定制用户数据，聚焦特定的数据 示例：如果频繁获取销售人员编号、姓名和代理商名称，可以创建视图\n1 2 3 4 5 6 7 8 9 10 11 12 13 CREATE OR REPLACE VIEW salesInfo AS SELECT a.id, a.`name` saleName, b.`name` agentName FROM sales a, agent b WHERE a.agent_id = b.id; -- 测试代码 SELECT id, saleName FROM salesInfo; 简化数据操作 示例：进行关联查询时，涉及到的表可能会很多，这时写的 SQL语句可能会很长，如果这个动作频繁发生的话，可以创建视图\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 CREATE OR REPLACE VIEW searchOrderDetail AS SELECT a.id regionId, a.`name` regionName, b.id agentId, b.`name` agentName, c.id saleId, c.`name` saleName, d.sale_count saleCount, d.created_time createdTime, e.`name` goodsName FROM region a, agent b, sales c, `order` d, goods e WHERE a.id = b.region_id AND b.id = c.agent_id AND c.id = d.sales_id AND d.goods_id = e.id; -- 测试代码 SELECT * FROM searchOrderDetail; 提高安全性能 示例：例如：用户密码属于隐私数据，用户不能直接查看密码。可以使用视图过滤掉这一字段\n1 2 3 4 5 6 7 8 9 10 CREATE OR REPLACE VIEW userInfo AS SELECT username, salt, failure_times, last_log_time FROM `user`; SELECT username, salt FROM userInfo; 注：视图并不能提升查询速度，只是方便了业务开发，但同时也加大了数据库服务器的压力，因此，需要合理的使用视图\n第六节 综合练习 1. 创建存储过程的语法\n1 2 3 4 CREATE PROCEDURE 存储过程的名称(IN|OUT 参数名1 参数类型1, ..., IN|OUT 参数名n 参数类型n) BEGIN -- 存储过程语句 END 2. 创建函数的语法\n1 2 3 4 5 6 CREATE FUNCTION 函数名称(参数名1 参数类型1, ..., 参数名n 参数类型n) RETURNS 数据类型 DETERMINISTIC | NO SQL | READ SQL DATA | CONTAINS SQL BEGIN RETURN 结果; END 3. 创建触发器的语法\n1 2 3 4 CREATE TRIGGER 触发器名称 BEFORE|AFTER INSERT|UPDATE|DELETE ON 表名 FOR EACH ROW BEGIN END 4. 创建视图的语法\n1 CREATE OR REPLACE VIEW 视图名称 AS SELECT 语句; ","date":"2021-10-02T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E4%BA%94/","title":"从零开始学MySQL(五)"},{"content":"第四章 联表查询与索引 第一节 表与表之间的关系 1. 表与表之间的关系 数据表是用来描述实体信息的，比如可以使用数据表来描述学生信息，也可以用数据表来描述班级信息，这样就会存在学生表和班级表。而学生和班级显然存在着一种关系：\n这种关系在数据库中体现就称之为表与表之间的关系。数据库通过主外键关联关系来体现表与表之间的关联关系\n2. 主外键关联关系 如图所示，此时学生表和班级表并没有任何关系，然而实际上学生和班级是存在归属关系。可以在学生表中添加一个字段，表明该学生所属班级，该字段值使用的是班级表中的主键，在学生表中称之为外键。这样学生表中的所属班级（外键）与班级表中的编号（主键）就产生关联关系，这种关联关系称为主外键关联关系。\n3. 主外键关联关系的对应 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 CREATE TABLE IF NOT EXISTS clss( id INT(20) AUTO_INCREMENT NOT NULL PRIMARY KEY COMMENT \u0026#39;学号\u0026#39;, name VARCHAR(30) NOT NULL COMMENT \u0026#39;班级名称\u0026#39;, grade VARCHAR(30) NOT NULL COMMENT \u0026#39;年级\u0026#39;, )ENGINE=InnoDB CHARSET=UTF8 COMMENT \u0026#39;班级表\u0026#39;; CREATE TABLE IF NOT EXISTS stu( number BIGINT(20) AUTO_INCREMENT NOT NULL COMMENT \u0026#39;学号\u0026#39;, name VARCHAR(30) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, sex VARCHAR(2) NOT NULL DEFAULT \u0026#39;男\u0026#39; COMMENT \u0026#39;性别\u0026#39;, age TINYINT(3) UNSIGNED DEFAULT 0 COMMENT \u0026#39;年龄\u0026#39;, class_id INT(11) NOT NULL COMMENT \u0026#39;所属班级\u0026#39;, -- 指定number为主键 PRIMARY KEY(number), -- 字段class_id与cls表中的number字段相关联 FOREIGN KEY(class_id) REFERENCES class(id) )ENGINE=InnoDB CHARSET=UTF8 COMMENT \u0026#39;学生表\u0026#39;; 4. 约束 4.1 主键约束 添加主键约束，保证数据的唯一性\n1 ALTER TABLE 表名 ADD PRIMARY KEY(字段名1,字段名2, ..., 字段名n); 示例：\n1 ALTER TABLE stu ADD PRIMARY KEY(number); 删除主键约束\n1 ALTER TABLE 表名 DROP PRIMARY KEY; 注：若主键自增则无法直接删除主键约束\n示例：\n1 ALTER TABLE stu DROP PRIMARY KEY; 4.2 外键约束 添加外键约束\n1 ALTER TABLE1 表名 ADD CONSTRAINT 外键名称 FOREIGN KEY (表名1的字段名) REFERENCES 表名2(表名2的字段名); 注： MyISAM不支持外键索引\n示例：\n1 ALTER TABLE stu ADD CONSTRAINT fk_class_id FOREIGN KEY (class_id) REFERENCES class(id); 删除外键约束\n1 ALTER TABLE 表名 DROP FOREIGN KEY 外键名称; 注：因外键可以多个，故需要声明外键名称\n示例：\n1 ALTER TABLE stu DROP FOREIGN KEY fk_class_id; 4.3 唯一约束 为字段添加唯一约束\n1 ALTER TABLE 表名 ADD CONSTRAINT 约束名称 UNIQUE(字段名1, 字段名2, ..., 字段名n); 示例：\n1 ALTER TABLE stu ADD CONSTRAINT un_name UNIQUE(name); 删除字段的唯一约束\n1 ALTER TABLE 表名 DROP KEY 约束名称; 示例：\n1 ALTER TABLE stu ADD CONSTRAINT un_name UNIQUE(name); 4.4 非空约束 为字段添加非空约束\n1 ALTER TABLE 表名 MODIFY 字段名 列类型 NOT NULL; 删除字段的非空约束\n1 ALTER TABLE 表名 MODIFY 字段名 列类型 NULL; 4.5 默认值约束 为字段添加默认值\n1 ALTER TABLE 表名 ALTER 字段名 SET DEFAULT 默认值; 删除字段的非空约束\n1 ALTER TABLE 表名 ALTER 字段名 DROP DEFAULT; 4.6 自增约束 为字段添加自增约束\n1 ALTER TABLE 表名 MODIFY 字段名 列类型 AUTO_INCREMENT; 删除字段的自增约束\n1 ALTER TABLE 表名 MODIFY 字段名 列类型; 第二节 索引 1. 什么是索引 在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是表中一列或多列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。\n对比书籍目录理解\n2. 索引的作用 保证数据的准确性 提高检索速度 提高系统性能 3. 索引的类型 唯一索引（UNIQUE）：不可以出现相同的值，可以有NULL值 普通索引（INDEX）：允许出现相同的索引内容 主键索引（PRIMARY KEY）：不允许出现相同的值 全文索引（FULLTEXT INDEX）：可以针对值中的某个单词，但效率确实不敢恭维 组合索引：实质上是将多个字段建到一个索引里，列值的组合必须唯一。注意组合索引在进行匹配时，遵循最左原则。 4. 索引的创建、查看、删除 创建索引\n1 ALTER TABLE 表名 ADD INDEX 索引名称 (字段名1, 字段名2, ..., 字段名n); 创建全文索引\n1 ALTER TABLE 表名 ADD FULLTEXT 索引名称 (字段名1, 字段名2, ..., 字段名n); 注：5.56版本之前的 InnoDB 不支持全文索引\n查看索引\n1 SHOW INDEX FROM 表名; 删除索引\n1 ALTER TABLE 表名 DROP INNDEX 索引名称; 使用全文索引示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 -- 创建表单 CREATE TABLE articles ( id INT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY, title VARCHAR(200), body TEXT, FULLTEXT (body)); -- 插入数据 INSERT INTO articles VALUES (NULL,\u0026#39;MySQL Tutorial\u0026#39;, \u0026#39;DBMS stands for DataBase ...\u0026#39;), (NULL,\u0026#39;How To Use MySQL Efficiently\u0026#39;, \u0026#39;After you went through a ...\u0026#39;), (NULL,\u0026#39;Optimising MySQL\u0026#39;,\u0026#39;In this tutorial we will show ...\u0026#39;), (NULL,\u0026#39;1001 MySQL Tricks\u0026#39;,\u0026#39;1. Never run mysqld as root. 2. ...\u0026#39;), (NULL,\u0026#39;MySQL vs. YourSQL\u0026#39;, \u0026#39;In the following database comparison ...\u0026#39;), (NULL,\u0026#39;MySQL Security\u0026#39;, \u0026#39;When configured properly, MySQL ...\u0026#39;); 查询语句\n1 SELECT * FROM articles WHERE MATCH (body) AGAINST (\u0026#39;database\u0026#39;); 其查询结果等同于\n1 SELECT * FROM articles WHERE body like \u0026#39;%database%\u0026#39;; 注：注意全文索引如何定义字段的，match中就必须是哪些字段，against中定义需要模糊匹配的字符串，用作查找的字符串实际上是被分词之后的结果，如果进行模糊匹配的不是一个词语，那么会查找失败，但是它的效率远高于下面的这种写法\n查看索引的执行情况\n可以使用EXPLAIN语句（它可以用于分析select语句的执行计划，也就是MySQL到底是如何在执行某条select语句的）来分析查询语句到底有没有通过索引进行匹配。\n1 EXPLAIN SELECT * FROM student WHERE name = \u0026#39;枫阿雨\u0026#39;; 得到的结果如下：\nselect_type：查询类型，上面的就是简单查询（SIMPLE） table：查询的表 type：MySQL决定如何查找对应的记录，效率从高到低：system \u0026gt; const \u0026gt; eq_ref \u0026gt; ref \u0026gt; range \u0026gt; index \u0026gt; all possible_keys：执行查询时可能会用到的索引 key：实际使用的索引 key_len：Mysql在索引里使用的字节数，字段的最大可能长度 rows：扫描的行数 extra：附加说明 5. 使用索引的注意事项 虽然索引大大提高了查询速度，但也会降低更新表的速度，比如对表进行INSERT、UPDATE和DELETE操作，此时，数据库不仅要保存数据，还要保存一下索引文件 建立索引会占用磁盘空间的索引文件。如果索引创建过多（尤其是在字段多、数据量大的表上创建索引），就会导致索引文件过大，这样反而会降低数据库性能。因此，索引要建立在经常进行查询操作的字段上 不要在列上进行运算（包括函数运算），这会忽略索引的使用 不建议使用LIKE操作，如果非使用不可，注意正确的使用方式。LIKE '%查询内容%' 不会使用索引，而LIKE '查询内容%'可以使用索引 避免使用IS NULL、NOT IN、\u0026lt;\u0026gt;、!=、OR操作，这些操作都会忽略索引而进行全表扫描 6. 索引底层原理 * 既然我们要通过索引来快速查找内容，那么如何设计索引就是我们的重点内容，因为索引是存储在硬盘上的，跟我们之前使用的HashMap之类的不同，它们都是在内存中的，但是硬盘的读取速度远小于内存的速度，每一次IO操作都会耗费大量的时间，我们也不可能把整个磁盘上的索引全部导入内存，因此我们需要考虑尽可能多的减少IO次数，索引的实现可以依靠两种数据结构，一种是我们在JavaSE阶段已经学习过的Hash表，还有一种就是B-Tree。\n我们首先来看看哈希表，实际上就是计算Hash值来快速定位：\n通过对Key进行散列值计算，我们可以直接得到对应数据的存放位置，它的查询效率能够达到O(1)，但是它也存在一定的缺陷：\nHash索引仅仅能满足“=”，“in”查询条件，不能使用范围查询。 Hash碰撞问题。 不能用部分索引键来搜索，因为组合索引在计算哈希值的时候是一起计算的。 那么，既然要解决这些问题，我们还有一种方案就是使用类似于二叉树那样的数据结构来存储索引，但是这样相比使用Hash索引，会牺牲一定的读取速度。\n但是这里并没有使用二叉树，而是使用了B-Tree，它是专门为磁盘数据读取设计的一种度为n的查找树：\n树中每个结点最多含有m个孩子（m \u0026gt;= 2）\n除根结点和叶子结点外，其它每个结点至少有[ceil(m / 2)]个孩子。\n若根结点不是叶子结点，则至少有2个孩子。\n所有叶子结点都出现在同一层。\n每个非终端结点中包含有n个键值信息： (P1，K1，P2，K2，P3，\u0026hellip;\u0026hellip;，Kn，Pn+1)。其中：\nKi (i=1\u0026hellip;n)为键值，且键值按顺序升序排序K(i-1)\u0026lt; Ki。 Pi为指向子树根的结点，且指针P(i)指向的子树中所有结点的键值均小于Ki，但都大于K(i-1)。 键值的个数n必须满足： [ceil(m / 2)-1] \u0026lt;= n \u0026lt;= m-1。 比如现在我们要对键值为10的记录进行查找，过程如下：\n读取根节点数据（目前进行了一次IO操作） 根据根节点数据进行判断得到10\u0026lt;17，因为P1指向的子树中所有值都是小于17的，所以这时我们将P1指向的节点读取（目前进行了两次IO操作） 再次进行判断，得到8\u0026lt;10\u0026lt;12，因为P2指向的子树中所有的值都是小于12大于8的，所以这时读取P2指向的节点（目前进行了三次IO操作） 成功找到。 我们接着来看，虽然B-Tree能够很好地利用二叉查找树的思想大幅度减少查找次数，但是它的查找效率还是很低\n因此它的优化版本 B+Tree 诞生了，它拥有更稳定的查询效率和更低的IO读取次数：\n我们可以发现，它和BTree有一定的区别：\n有n棵子树的结点中含有n个键值，B-Tree只有n-1个。 所有的键值信息只在叶子节点中包含，非叶子节点仅仅保存子节点的最小（或最大）值，和指向叶子节点的指针，这样相比B-Tree每一个节点在硬盘中存放了更少的内容（没有键值信息了） 所有叶子节点都有一个根据大小顺序指向下一个叶子节点的指针Q，本质上数据就是一个链表。 这样，读取IO的时间相比BTree就减少了很多，并且查询任何键值信息都需要完整地走到叶子节点，保证了查询的IO读取次数一致。因此MySQL默认选择B+Tree作为索引的存储数据结构。\n这是MyISAM存储引擎下的B+Tree实现：\n这是InnoDB存储引擎下的B+Tree实现：\nInnoDB与MyISAM实现的不同之处：\n数据本身就是索引的一部分（所以这里建议主键使用自增） 非主键索引的数据实际上存储的是对应记录的主键值（因此InnoDB必须有主键，若没有也会自动查找替代） 注：可阅读一下文章 MySQL InnoDB数据表缺少主键会怎样 - 知乎 第三节 多表查询 1. 笛卡尔积 笛卡尔积又称为笛卡尔乘积，由笛卡尔提出，表示两个集合相乘的结果。\n笛卡尔积与多表查询有什么关系呢？每一张表可以看做是一个数据的集合，多表关联串时，这些表中的数据就会形成笛卡尔积。\n2. 内连接 内连接相当于在笛卡尔积的基础上加上了连接条件。当没有连接条件时，内连接上升为笛卡尔积。\n1 2 3 SELECT 字段名1, 字段名2, ..., 字段名n FROM 表1 [INNER] JOIN 表2 [ON 链接条件]; -- 等价于 SELECT 字段名1, 字段名2, ..., 字段名n FROM 表1, 表2 [WHERE 关联条件 AND 查询条件]; 示例：\n1 2 3 SELECT COUNT(*) FROM stu INNER JOIN score ON stu.id=score.stu_id; -- 等价于 SELECT COUNT(*) FROM stu, score WHERE stu.id=score.stu.id; 注：上方写法效率更高，下方写法为ORACLE的写法，MySQL仍支持\n3. 外连接 外连接涉及到两张表：主表和从表，要查询的信息主要来自于哪张表，哪张表就是主表。 外连接查询的结果为主表中所有的记录。如果从表中有和它匹配的，则显示匹配的值，这部分相当于内连接查询出来的结果；如果从表中没有和它匹配的，则显示null。 外连接查询的结果 = 内连接的结果 + 主表中有的而内连接结果中没有的记录 外连接分为左外连接和右外连接两种。左外连接使用LEFT JOIN关键字，LEFT JOIN左边的是主表；右外连接使用RIGHT JOIN关键字，RIGHT JOIN右边的是主表。\n3.1 左外连接 1 SELECT 字段名1, 字段名2, ..., 字段名n FROM 主表 LEFT JOIN 从表 [ON 链接条件] 示例：\n1 SELECT * FROM stu a LEFT JOIN score b ON a.id=b.stu_id; 3.2 右外连接 1 SELECT 字段名1, 字段名2, ..., 字段名n FROM 从表 RIGHT JOIN 主表 [ON 连接条件]; 示例：\n1 SELECT * FROM stu a RIGHT JOIN score b ON a.id=b.stu_id; 第四节 子查询 1. 什么是子查询 子查询就是嵌套在其他查询中的查询。因此，子查询出现的位置只有3种情况：在SELECT ... FROM 之间、在FROM ... WHERE之间、在WHERE之后\n注：下面示例中stu表中有学生信息，score表中有成绩对应信息\n2. SELECT \u0026hellip; FROM 之间 示例：查询stu表所有学生信息，并将性别按男、女、其他展示\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -- 先创建字典表 CREATE TABLE IF NOT EXISTS dict( id INT AUTO_INCREMENT NOT NULL PRIMARY KEY COMMENT \u0026#39;学生id\u0026#39;, type VARCHAR(50) NOT NULL COMMENT \u0026#39;类型\u0026#39;, `value` VARCHAR(50) NOT NULL COMMENT \u0026#39;原始值\u0026#39;, `text` VARCHAR(50) NOT NULL COMMENT \u0026#39;转换值\u0026#39;, )ENGINE=InnoDB CHARSET=UTF8 COMMENT \u0026#39;字典表\u0026#39;; -- 向字典表插入字典转换内容 INSERT INTO dict (1, sex, 0, \u0026#39;男\u0026#39;), (2, sex, 1, \u0026#39;女\u0026#39;), (3, sex, 2, \u0026#39;其他\u0026#39;); -- 执行查询 SELECT id, `name`, (SELECT text FROM dict WHERE tYPE=\u0026#39;sex\u0026#39; ANDE value=sex) sex, birthday, class FROM stu; 注：执行时机是在查询结果出来之后\n3. FROM \u0026hellip; WHERE 之间 示例：查询年龄与Java成绩都与枫阿雨的年龄与Java成绩都相同的学生信息\n1 2 3 4 5 6 7 8 9 10 11 12 SELECT c.*, d.* FROM stu c INNER JOIN score d ON c.id=d.stu_id INNER JOIN (SELECT TIMESTAMPDIFF(YEAR, a.birthday, NOW()) age, b.score FROM stu a INNER JOIN score b ON a.id=b.stu_id WHERE a.name=\u0026#39;枫阿雨\u0026#39; AND b.score=\u0026#39;Java\u0026#39;) e ON TIMESTAMPDIFF(YEAR, a.birthday, NOW())=e.age AND d.score=e.score WHERE d.course=\u0026#39;Java\u0026#39;; 注：执行时机是一开始就执行\n4. WHERE 之后 示例：查询Java成绩最高的所有学生信息\n1 2 3 SELECT a.*, b.* FROM stu a INNER JOIN score b ON a.id=b.stu_id WHERE b.score=(SELECT MAX(score) FROM score WHERE course=\u0026#39;Java\u0026#39;) AND b.course=\u0026#39;Java\u0026#39;; 第五节 综合练习 1. 查询有哪些分类\n1 2 3 内连接：衔接的多表必须保证数据一一对应才可能展示结果 左外连接：衔接的主表(LEFT JOIN 左边的表为主表) 为准，从表中没忽悠的数据以NULL形式展示 右外连接：衔接的主表(RIGHT JOIN 右边的表为主表) 为准，从表中没忽悠的数据以NULL形式展示 2. 子查询有哪些分类\n1 2 3 在 SELECT ... FROM 之间：执行时机就是查询出结果后执行 在 FROM ... WHERE 之间：执行时机是一开始就先执行 在 WHERE 之后：执行时机是筛选数据时执行 ","date":"2021-09-21T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E5%9B%9B/","title":"从零开始学MySQL(四)"},{"content":"第三章 MySQL常用函数 第一节 常用数学函数 函数 说明 示例 ABS(X) 返回X的绝对值 SELECT ABS(-8); FLOOR(X) 返回不大于X的最大整数 SELECT FLOOR(1.3); CEIL(X) 返回不小于X的最小整数 SELECT CEIL(1.3); TRUNCATE(X, D) 返回值X保留到小数点后D位的值，截断时不进行四舍五入 SELECT TRUNCATE(1.2328, 3); ROUND(X) 返回离X最近的整数，截断时要进行四舍五入 SELECT ROUND(1.8); ROUND(X, D) 返回X小数点后D位的值，截断时要进行四舍五入 SELECT ROUND(1.2323, 3); RAND() 返回0-1的随机数 SELECT RAND(); MOD(N, M) 返回N除以M以后的余数 SELECT MOD(2, 9); 第二节 常用字符串函数 函数 说明 示例 CHAR_LENGTH(str) 计算字符串字符个数 SELECT CHAR_LENGTH(\u0026lsquo;枫阿雨\u0026rsquo;); \u0026ndash;3 LENGTH(str) 返回值位字符串str的长度，单位为字节 SELECT LENGTH(\u0026lsquo;枫阿雨\u0026rsquo;); \u0026ndash;9 CONCAT(s1, s2, \u0026hellip;) 将多个字符串拼接在一起，其中任意一个为NULL则返回值为NULL SELECT CONCAT(\u0026lsquo;枫\u0026rsquo;, \u0026lsquo;阿\u0026rsquo;, \u0026lsquo;雨\u0026rsquo;); \u0026ndash;枫阿雨 LOWER(str)LCASE(str) 将字符串中的字母全部转换成小写 SELECT LOWER(\u0026lsquo;JAVA\u0026rsquo;);SELECT LCASE(\u0026lsquo;JAVA\u0026rsquo;); \u0026ndash;java UPPER(str)UCASE(str) 将字符串中的字母全部转换成大写 SELECT UPPER(\u0026lsquo;java\u0026rsquo;);SELECT LCASE(\u0026lsquo;java\u0026rsquo;); \u0026ndash;JAVA LEFT(s, n) 返回字符串s从最左边开始的n个字符 SELECT LEFT(\u0026lsquo;枫阿雨带帅比\u0026rsquo;, 3); \u0026ndash;枫阿雨 RIGHT(s, N) 返回字符串s从最右边开始的n个字符 SELECT RIGHT(\u0026lsquo;枫阿雨带帅比\u0026rsquo;, 3); \u0026ndash;带帅比 LTRIM(str) 返回字符串s，其左边的所有空格被删除 SELECT LTRIM(\u0026lsquo;Java\u0026rsquo;); \u0026ndash;Java RTRIM(str) 返回字符串s，其右边的所有空格被删除 SELECT RTRIM(\u0026lsquo;Java \u0026lsquo;); \u0026ndash;Java TRIM(str) 返回字符串str删除了两边空格之后的字符串 SELECT TRIM(\u0026rsquo; Java \u0026lsquo;); \u0026ndash;Java REPLACE(s, s1, s2) 返回一个字符串，用字符串s2替代字符串s中的所有字符串s1 SELECT REPLACE(\u0026lsquo;疯阿雨\u0026rsquo;, \u0026lsquo;疯\u0026rsquo;, \u0026lsquo;枫\u0026rsquo;); \u0026ndash;枫阿雨 SUBSTRING(s, n, len) 从字符串s中返回一个第n个字符开始 长度为len的字符串 SELECT SUBSTRING(\u0026lsquo;枫阿雨带帅比\u0026rsquo;, 2, 2); \u0026ndash;阿雨 示例：假设表中有信管和大数据四个班(class)，查询信管和大数据各有多少人\n1 SELECT LEFT(class, 2), COUNT(*) FROM student GROUP BY LEFT(class, 2); 示例：查询名字有4个字的学生信息\n1 SELECT * FROM student WHERE CHAR_LENGTH(name)=4; 示例：查询成绩能够被10整除的考试信息\n1 SELECT * FROM student WHERE MOD(score, 10)=0; 第三节 日期和时间函数 函数 说明 示例 CURDATE()CURRENT_DATE() 返回当前日期：YY-MM-dd SELECT CURDATE(); CURTIME()CURRENT_TIME() 返回当前时间：HH:mm:ss SELECT CURTIME; NOW()CURRENT_TIMESTAMP()SYSDATE(); 返回当前日期和时间：YY-MM-dd HH:mm:ss SELECT NOW(); YEAR(d) 返回日期 d 中的年份值 SELECT YEAR(NOW()); MONTH(d) 返回日期 d 中的月份值，范围是1~12 SELECT MONTH(NOW()); WEEKDAY(d) 返回日期 d 是星期几 SELECT WEEKDAY(NOW()); DAYOFMONTH(d) 返回给定日期 d 是当月的第几天 SELECT DAYOFMONTH(NOW()); HOUR(d) 返回日期 d 的小时数 SELECT HOUR(NOW()); MINUTE(d) 返回日期 d 的分钟数 SELECT MINUTE(NOW()); SECOND(d) 返回日期 d 的秒数 SELECT SECOND(NOW()); ADDDATE(d, n) 返回起始日期 d 加上 n 天的日期 SELECT ADDDATE(NOW(), 3); TIMESTAMPDIFF(INTERVAL expr type, d1, d2) 返回给定日期 d1 和 d2 的时间差 SELECT TIMESTAMPDIFF(YEAR, \u0026lsquo;2003-1-4\u0026rsquo;, \u0026lsquo;2022-1-22\u0026rsquo;); DATE_FORMAT(d, f) 返回给定日期格式的字符串 SELECT DATE_FORMAT(NOW(), \u0026lsquo;%Y-%m-%d %H:%i:%s\u0026rsquo;); 示例：查询年龄在20岁以上的学生信息\n1 SELECT * FROM student WHERE TIMESTAMPDIFF(YEAR, birthday, NOW()) \u0026gt; 20; 示例：查询今天过生日的学生信息\n1 SELECT * FROM student WHERE MONTH(birthday)=MONTH(NOW()) AND DATEOFMONTH(birthday)=DATEOFMONTH(NOW()); 示例：查询本周过生日的学生信息\n1 2 SELECT * FROM student WHERE RIGHT(birthday, 5) \u0026gt; RIGHT(DATE_FORMAT(ADDDATE(NOW(), -DAYOFWEEK(NOW())), \u0026#39;%Y-%m-%d\u0026#39;), 5) AND RIGHT(birthday, 5) \u0026lt;= RIGHT(DATE_FORMAT(ADDDATE(NOW(),7-DAYOFMONTH(NOW())), \u0026#39;%Y-%m-%d\u0026#39;), 5); 第四节 条件判断函数 1. IF 函数 1.1 IF 1 IF(条件, 表达式1, 表达式2) 如果条件满足，则使用表达式1，否则使用表达式2\n示例：将学生成绩展示为及格和不及格\n1 SELECT id, name, IF(score \u0026gt;= 60, \u0026#39;及格\u0026#39;, \u0026#39;不及格\u0026#39;) finalScore FROM scoreTable; 1.2 IFNULL 1 IFNULL(字段, 表达式) 如果字段值为空，则使用表达式，否则，使用字段值\n示例：将未参加考试的学生成绩展示为缺考\n1 SELECT id, name, IFNULL(score, \u0026#39;缺考\u0026#39;) finalScore FROM scoreTable; 2. CASE \u0026hellip; WHEN 语句 2.1 CASE WEHN 1 CASE WHEN 条件1 THEN 表达式1 [WHEN 条件2 THEN 表达式2 ...] ELSE 表达式n END 如果条件1满足，则使用表达式1；【如果条件2满足，则使用表达式2， \u0026hellip; 】否则，使用表达式n。相当于Java中的多重if..else语句\n示例：行转列，查看每人每科的分数\n1 2 3 4 5 6 7 8 9 SELECT name, course, MAX(CASE WHEN (course = \u0026#39;Java\u0026#39;) THEN score ELSE 0 END) JavaScore, MAX(CASE WHEN (course = \u0026#39;Python\u0026#39;) THEN score ELSE 0 END) PythonScore, MAX(CASE WHEN (course = \u0026#39;C/Cpp\u0026#39;) THEN score ELSE 0 END) C/CppScore, MAX(CASE WHEN (course = \u0026#39;Golang\u0026#39;) THEN score ELSE 0 END) GolangScore FROM scoreTable GROUP BY name; 2.2 CASE \u0026hellip; WHEN 1 CASE 表达式 WHEN 值1 THEN 表达式1 [WHEN 值2 THEN 表达式2 ...] ELSE 表达式n END 如果表达式的执行结果为值1，则使用表达式1；【执行结果为值2，则使用表达式2， \u0026hellip; 】否则，使用表达式n。相当于Java中的switch语句\n示例：行转列，查看每人每科的分数\n1 2 3 4 5 6 7 8 9 SELECT name, course, MAX(CASE course WHEN \u0026#39;Java\u0026#39; THEN score ELSE 0 END) JavaScore, MAX(CASE course WHEN \u0026#39;Python\u0026#39; THEN score ELSE 0 END) PythonScore, MAX(CASE course WHEN \u0026#39;C/Cpp\u0026#39; THEN score ELSE 0 END) C/CppScore, MAX(CASE course WHEN \u0026#39;Golang\u0026#39; THEN score ELSE 0 END) GolangScore FROM scoreTable GROUP BY name; 练习：查询各班级人数，查询结果格式为 班级 男 女 其他\n1 2 3 4 5 6 7 SELECT class, SUM(CASE sex WHEN \u0026#39;男\u0026#39; THEN sex ELSE 0 END) \u0026#39;男\u0026#39;, SUM(CASE sex WHEN \u0026#39;女\u0026#39; THEN sex ELSE 0 END) \u0026#39;女\u0026#39;, SUM(CASE sex WHEN \u0026#39;其他\u0026#39; THEN sex ELSE 0 END) \u0026#39;其他\u0026#39; FROM scoreTable GROUP BY class; 第五节 其他函数 1. 数字格式化函数 1 FORMAT(X, D) 将数字X格式化，将X保留到小数点后D位，截断时要进行四舍五入\n示例：\n1 SELECT FORMAT(1.2353, 2); 2. 系统信息函数 函数 说明 示例 VERSION() 获取服务器的版本号 SELECT VERSION(); CONNECTION_ID() 获取服务器的连接数 SELECT CONNECTION_ID(); DATEBASE()SCHEMA() 获取当前数据库名 SELECT DATEBASE();SELECT SCHEMA(); USER()SYSTEM_USER()SESSION_USER() 获取当前用户名 SELECT USER();SELECT SYSTEM_USER();SELECT SESSION_USER(); CURRENT_USER()CURRENT_USER 获取当前用户名 SELECT CURRENT_USER; 第六节 综合练习 1. 求字符串'ABCdEfGHIJkLMn'的字符数\n1 SELECT CHAR_LENGTH(\u0026#39;ABCdEfGHIJkLMn\u0026#39;); 2. 将'枫阿雨'和'带帅比'拼接成新的字符串\n1 SELECT CONCAT(\u0026#39;枫阿雨\u0026#39;, \u0026#39;带帅比\u0026#39;); 3. 求'2003-01-04'到现在总过有多少天\n1 SELECT TIMESTAMPDIFF(DAY, \u0026#39;2003-01-04\u0026#39;, NOW()); 4. 如果字段score的值大于90，则展示为优秀，否则展示为良好\n1 SELECT IF(score \u0026gt; 90, \u0026#39;优秀\u0026#39;, \u0026#39;良好\u0026#39;) score; ","date":"2021-09-14T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E4%B8%89/","title":"从零开始学MySQL(三)"},{"content":"让我们开始吃树~ ​\t提起树状数据结构的家族，我们不得不从二叉树开始说起。\n​\t在学二叉树的时候，我们知道，二叉树是指每个结点最多只有两个子结点的树。\n​\t二叉树，是指树中每个结点最多只有两个结点的树。当然，二叉树本身好像没有什么太大的作用。我们平时所说的二叉树，基本上就是指二叉排序树(二叉查找树)。\n二叉查找树（BST） ​\t二叉查找树就是在二叉树的基础上增加有序性，这个有序性一般是指自然顺序，有了有序性，我们就可以使用二叉树来快速的查找、删除、插入元素了。\n​\t但是，二叉查找树有个非常严重的问题，试想，还是这三个元素，如果按照A、B、C的顺序插入元素会怎样？\n​\t那么如果按照顺序插入，就会变成一个单链表。没错，当按照元素的自然顺序插入元素的时候，二叉查找树就退化成单链表了，单链表的插入、删除、查找元素的时间复杂度是多少？？\n​\t所以，在极限状态下，二叉查找树的时间复杂度是非常差的。\n​\t既然，插入元素后有可能导致二叉查找树的性能变差，我们是不是增加了一些手段，让插入后的二叉查找树依然性能良好？\n​\t这种手段，就叫做平衡。可以做到自平衡的树就叫做平衡树。\n平衡树 ​\t平衡树，是指插入、删除元素后可以自平衡的二叉查找树。我们平衡的手段，就是旋转。\n​\t平衡这个概念一直都有，直到62年，发明了第一种平衡树\u0026mdash;-AVL树。\n​\t严格来说，平衡树是指可以自平衡的二叉查找树，关键词就是：自平衡、二叉、查找（有序）。\nAVL树 ​\tAVL树是指任意节点的两个子树的高度差不超过1的平衡树。\n​\t当数据量非常多的时候，你会非常难以判断这是否是一颗AVL树，比如\n​\t如果把上面看成一颗二叉排序树，他是一颗AVL树，其实你很难一眼就看出来他是一颗AVL树，这就是AVL树的第一个缺点，不够直观，特别是当结点特别多的时候。\n​\t第二个缺点就是，在插入和删除的时候自平衡的过程非常的复杂。\n​\t基于这些缺点，所以，后来又发展出来了各种各样的神奇的平衡树。\n多路平衡二叉树 索引 ​\t一般来说，我们操作的数据都是存储在内存（CPU）中的，但如若我们要操作的数据集非常大，大到内存已经没办法处理了怎么办呢？如数据库中的上千万条记录的数据表、硬盘中的上万个文件等，他们必然不能都存储在内存中，而是存储在外存中的。\n​\t对于外存中的数据，常见如数据库，我们通常通过索引表来进行数据查找和交互，一般来说，索引表本身也很大，因为数据库的数据非常多，因此索引也不可能全部存储在内存中，因此索引表往往也是以索引文件的形式存储的磁盘上。Mysql的MyISAM引擎的索引文件和数据文件是分离的，一张数据库表就有它对应的索引表，索引表中一个索引对应一条数据库记录的磁盘地址，内存中发起请求通过指定索引的查找索引表即可定位唯一的一条数据；当然Mysql的InnoDB引擎的索引表也是数据表，即索引表保存了索引和完整的数据记录。但是不管怎么说数据的查找都会依赖索引，并且建议通过索引查找，因为如果没有走索引，那就会走全表扫描，使得查找效率大大降低。\t因为索引文件同样存储在磁盘上，这样的话，索引查找过程中每查找一次就要产生一次磁盘I/O消耗，相对于CPU存取，I/O存取的消耗要高几个数量级，访问磁盘的成本大概是访问内存的十万倍左右。\n​\t实际上，考虑到磁盘IO是非常高昂的操作，计算机操作已经系统做了一些优化，当一次IO时，不光把当前磁盘地址的数据，而是把相邻的数据也都读取到内存缓冲区内，局部预读性原理告诉我们，当计算机访问一个地址的数据的时候，与其相邻的数据也会很快被访问到。\n​\t每一次IO读取的数据我们称之为一页(page)。具体一页有多大数据跟操作系统有关，一般为4k或8k大小的连续磁盘块，也就是我们读取一页内的数据时候，实际上才发生了一次IO，这个理论对于索引的数据结构设计非常有帮助，通常，索引节点的大小被设计为一页的大小。\n多路平衡查找树 ​\t对于一旦涉及到这样的外部存储设备（外存），关于时间复杂度的计算就会发生变化，访问某个表/集合元素的时间已经不仅仅是寻找该元素所需比较次数的函数，我们必须考虑对硬盘IO进行操作的时间。由于IO耗时远大于CPU耗时，所以此处评价一个数据结构作为索引的优劣最重要的指标就是要尽量减少查找过程中磁盘IO的存取次数。\n​\t我们之前谈的树，都是一个节点可以有多个孩子，但是它自身只存储一个元素。二叉树限制更多，节点最多只能有两个孩子。一个节点只能存储一个元素，在元素非常多的时候，就使得要么树的度非常大（节点拥有子树的个数的最大值），要么树的高度非常大，甚至两者都必须足够大才行，这就使得IO次数非常多，这显然成了时间效率上的瓶颈，并且由于一次IO读取一个节点的数据，普通二叉树并不能容纳更多的数据，这样又造成了磁盘块空间的浪费。\n​\t以上种种限制迫使我们设计出每一个节点可以存储多个元素，并且数据结构的高度可控的数据结构，为此引入了多路查找树的概念。一颗平衡多路查找树同样可以使得数据的查找效率保证在O(logN)这样的对数级别上，此时底数为叉数或者阶。\n​\t多路查找树（muitl-way search tree），其每一个节点的孩子数可以多于两个，且每一个节点处可以存储多个元素。由于它是一颗平衡查找树，所有元素之间存在某种特定的排序关系。在这里，每一个节点可以存储多少个元素，以及它的孩子数的多少是非常关键的。\n2-3树 ​\t因为AVL树所带来的搜索性能的提升，不足以弥补平衡树所带来的性能损耗。所以，就开始思考，有没有一种绝对平衡的树。没有高度差，没有高度差就没有平衡因子，没有平衡因子就没有旋转操作。\n​\t随着这种思考，衍生出了2-3树。也就是二叉-三叉树。\n​\t2-3树就是一种绝对平衡的树，任意节点到它所有的叶子结点的深度都是相等的。\n定义 ​\t一颗2-3树或为一颗空树，或有以下结点组成：\n​\t2-节点：含有一个元素和两个子树，左子树的所有元素的值均小于它的父结点，右子树所有元素的值均大于它的父结点。\n​\t3-节点：还有两个元素和三个子树（左中右 子树），左子树所有元素的值均小于它的父结点，中子树所有元素的值都位于父结点两个元素之间，右子树所有元素的值均大于它的父结点。\n2-3树查找元素 ​\t2-3树的查找类似于二分，根据元素的大小来决定来决定查找的方向。要判断一个元素是否存在，我们就要先将待查找元素和根元素比较，如果他和任意一个相等，那查找命中，否则根据比较结果来选择查找方向。\n2-3树插入元素 ​\t插入元素首先进行查找命中。若查找命中则不插此元素。如果需要支持重复的元素则将这个元素对象添加一个属性count。若查找未命中，则在叶子结点中插入这个元素。\n​\t空树的插入很简单，创建一个结点就可以了。如果不是空树，插入又分成了四种情况：\n1、向2-结点中插入元素 2、向一颗只含有一个3-节点的树中插入元素 ​\t如果命中查找结束于3-节点，先临时将其成为4-节点，把待插入元素添加到其中，然后将4-节点转化为3个2-节点，中间的节点成为左右节点的父节点。如果之前临时4-节点有父节点，就会变成向一个父节点为2-节点的3-节点中插入元素，中间节点与父节点为2-节点的合并。\n​\t3、向一个父结点为2-节点的3-节点中插入元素 同前者\n4、向一个父结点为3-节点的3-节点中插入元素 ​\t插入元素后一直向上分解临时的4-节点，直到遇到2-节点的父节点变成3-节点不再分解。如果达到树根节点还是4-节点，则进行分解根节点，此时树高+1（只有分解根节点才会增加树高），下面动画2-3树插入会出这个例子。\n2-3树的删除操作 ​\t2-3树的删除也分为三种情况，与插入相反。\n1、当删除元素为于3-节点的叶子结点上 ​\t只需要删除该元素即可，不会影响到整棵树的其他结点结构。\n2、当删除元素位于非叶子结点 ​\t使用中序遍历找到待删除节点的后继节点，然后将后继节点与待删除节点位置互换，此时就将问题转化为删除节点为叶子节点（平衡树的非叶子节点中序遍历后继节点肯定是叶子节点），如果该叶子是3-节点，则跟情况（1）一样，如果该节点是2-节点，则跟后面的情况（3）一样；\n3、当删除元素位于2-结点的叶子结点上 ​\t删除元素2-结点的叶子结点的步骤相对很复杂，删除后需要做出相应的判断。并根据判断结果调整树的结构。\n1、删除结点为2结点，父结点为2结点，兄弟结点为3结点。 ​\t操作步骤：当前待删除节点的父节点是2-节点、兄弟节点是3-节点，将父节点移动到当前待删除节点位置，再将兄弟节点中最接近当前位置的key移动到父节点中。\n2、删除结点为2-结点，父结点为2-结点，兄弟结点为2-结点 ​\t操作步骤：当前待删除节点的父节点是2-节点、兄弟节点也是2-节点，先通过移动兄弟节点的中序遍历直接后驱到兄弟节点，以使兄弟节点变为3-节点；\n​\t删除结点4位2-结点，兄弟结点7也为2结点，需要中序遍历得到兄弟结点7的直接后继8，然后结点7和8构成3-结点。\n重复1情况\n3、删除结点为2-结点，父结点为3-结点 ​\t操作步骤：当前待删除节点的父节点是3-节点，拆分父节点使其成为2-节点，再将再将父节点中最接近的一个拆分key与中孩子合并，将合并后的节点作为当前节点。\n2-3树为满二叉树，删除叶子结点 ​\t2-3 树作为一种平衡查找树，查询效率比普通的二叉排序树要稳定许多。但是2-3树需要维护两种不同类型的结点，查找和插入操作的实现需要大量的代码，而且它们所产生的额外开销可能会使算法比标准的二叉查找树更慢。\n​\t可以看到，上面自平衡的过程中，出现了一种节点，它具有四个子节点和三个数据元素，这个节点可以称作4节点，如果把4节点当作是可以允许存在的，那么，就出现了另一种树：2-3-4树。\n2-3-4树 ​\t2-3-4树，它的每个非叶子节点，要么是2节点，要么是3节点，要么是4节点，且可以自平衡，所以称作2-3-4树。\n​\t2节点、3节点、4节点的定义在上面已经提及，我们再重申一下：\n​\t2节点：包含两个子节点和一个数据元素；\n​\t3节点：包含三个子节点和两个数据元素；\n​\t4节点：包含四个子节点和三个数据元素；\n​\t插入M，依旧符合2-3-4树的规则。在插入N呢？\n​\t插入N，L上移。\n​\tF上移\t​\t是不是挺简单的，至少比AVL树那种左旋右旋简单得多。同样地，在2-3-4树自平衡的过程中出现了临时的5节点，所以，如果允许5节点的存在呢？嗯，2-3-4-5树由此诞生！同样地，还有2-3-4-5-6树、2-3-4-5-6-7树……子子孙孙，无穷尽也~所以，有人就把这一类树归纳为一个新的名字：B树。\nB树 ​\tB树，表示的是一类树，它允许一个节点可以有多于两个子节点，同时，也是自平衡的，叶子节点的高度都是相同的。所以，为了更好地区分一颗B树到底属于哪一类树，我们给它一个新的属性：度（Degree）。具有度为3的B树，表示一个节点最多有三个子节点，也就是2-3树的定义。具有度为4的B树，表示一个节点最多有四个子节点，也就是2-3-4树的定义。\n​\tB树，一个节点可以存储多个元素，有利于缓存磁盘数据，整体的时间复杂度趋向于O(log n)，原理也比较简单，所以，经常用于数据库的索引，包括早期的mysql也是使用B树来作为索引的。但是，B树有个大缺陷，比如，我要按范围查找元素，以上面的2-3-4树为例，查找大于B且小于K的所有元素，该怎么实现呢？很难，几乎无解，所以，后面又出现替代B树的方案：B+树。当然了，B+树不是本节的重点，本节的重点是红黑树。 来了来了，有意思的红黑树来了~~\n红黑树 我们先用图来体会\n​\t我可以跟大家说，这棵树，就是一颗红黑树。红黑树就是2-3-4树。\n​\t我们知道2-3-4的插入、删除、查找元素的原理是相当简单的，那么，我们是不是可以利用2-3-4树来记忆红黑树呢？答案是肯定的，我们就来看看如何利用2-3-4树来快速掌握红黑树，再也不用死记硬背了~~\n​\t现在，我们来看一看红黑树的精髓所在，我们来看一看，什么是红黑树的黑高，为什么要有红黑树，红黑树的旋转跟AVL有什么区别，如何去选择？红黑树是如何保持平衡的？直接进入正题\n什么是红黑树 ​\t红黑树是一颗自平衡的二叉排序树，树上的每一个结点都遵循下面的规则（特别注意，这里的自平衡和平衡二叉树AVL的高度有区别）。我们再来看一看红黑树的定义：\n1、每一个结点都有一个颜色，要么是红色，要么是黑色。\n2、树的根结点为黑色\n3、树中不存在两个相邻的红色节点（红色节点的父结点和孩子结点均不为黑色）\n4、从任意一个结点出发，包括根结点，到其任何后代NULL结点（默认都是黑色啊）的每条路径都具有相同数量的黑色结点。\n​\t这就是一颗典型的红黑树，树中的每个结点的颜色要么是黑色，要么是红色；根结点 6 为黑色结点；树中不存在两个相邻的红色结点，比如结点 15 为红色结点，其父亲节点 6 与两个孩子结点就一定是黑色，而不能是红色； 从结点到其后代的 NUll结点 的每条路径上具有相同数目的黑色结点，比如根结点 6 到其左子树的 NULL结点 包含三个黑色结点，到其右子树所有的 NULL 结点也包含三个黑色结点。 可能还不够清晰，为此我对上图做了修改为所有默认为黑色的 NULL 结点给了一个标记。\n​\t现在解释规则的第四条简直不能再清晰了！比如根结点 6 到 NULL结点 a 的路径 6→2→a 上的黑色结点为 3 个，从根结点 6 到结点 c 的路径 6→15→10→9→c 中包含的黑色结点个数也是 3 个，同理从根结点 6 到其他所有 NULL结点 的黑色结点数都是 3 。再举个栗子，从红色结点 15 到NULL结点 d 的路径 15→18→g 包含 2 个黑色结点，到NULL结点 c 的路径 15→10→9→c 也包含黑色结点 2 个，从结点 15 到其所有后代的 NULL结点的 黑色结点数目都是 2 。\n为什么要有红黑树 ​\t大多数二叉排序树BST的操作（查找、最大值、最小值、插入、删除等等）都是O（h）的时间复杂度，h 为树的高度。但是对于斜树而言（BST极端情况下出现），BST的这些操作的时间复杂度将达到O（n），n就是结点数。为了保证BST的所有操作的时间复杂度的上限为O（logn） ，就要想办法把一颗BST树的高度一直维持在logn，而红黑树就做到了这一点，红黑树的高度始终都维持在logn，n 为树中的顶点数目。\n​\t这个时候就有一个疑问，不对啊。AVL树不也始终是一个均值么？\n红黑树RBT与平衡二叉树AVL的比较 ​\tAVL 树比红黑树更加平衡，但AVL树在插入和删除的时候也会存在大量的旋转操作。所以当你的应用涉及到频繁的插入和删除操作，切记放弃AVL树，选择性能更好的红黑树；当然，如果你的应用中涉及的插入和删除操作并不频繁，而是查找操作相对更频繁，那么就优先选择 AVL 树进行实现。\n一颗红黑树到底是如何保持平衡的呢？ 举一个很简单但是很经典的例子，包含三个结点的单链是不可能出现在红黑树当中的。关于这一点，我们可以自己绘制一条单链，然后尝试为其着色，来判断。\n从上图中可以发现，将根结点 9 涂黑色，其他结点分四种情况着色，结果都不满足红黑树的性质要求。唯一的办法就是调整树的高度\n这就算我们对于红黑树的初探，然后我们来看两个重要的概念。\n什么是一颗红黑树的黑高？ ​\t在一颗红黑树中，从某个结点 x 出发（不包含该结点）到达一个叶结点的任意一条简单路径上包含的黑色结点的数目称为 黑高 ，记为 bh(x) 。所以我们发现，其实6和15的黑高是一样的，都是2。\n​\t计算结点 6 的黑高，从结点 6 到结点 c 的路径是 6→15→10→9→c ，其中黑色结点为 6、10、c ，但是在计算黑高时，并不包含结点本身，所以从结点 6 到结点 c 的路径上的黑色结点个数为 2 ，那么 bh(6)=2 ；从结点 15 到结点 c 的路径为 15→10→9→c ，其中黑色结点为 10、c ，所以从结点 15 到结点 c 的路径上黑色结点数目为 2 ，bh(15)=2 。\n​\t因为红黑树的黑高为其根结点的黑高。所以根据红黑树的性质3和性质4，一颗红黑树的黑高bh一定\u0026gt;= h/2。\n1 2 3 Number of nodes from a node to its farthest descendant leaf is no more than twice as the number of nodes to the nearest descendant leaf. 从一个结点到其最远的后代叶结点的顶点数目不会超过从该结点到其最近的叶结点的结点数目的两倍。 ​\t其中黑高 bh 就表示从根结点 6 到离它最近的叶结点 2 包含的结点数 2 ，而 h 则表示从根结点 6 到其最远的叶结点 9 所包含的结点数目 4 ，显然这一公式是合理的。\n​\t引出来一个道理：一颗有n个结点的红黑树的高度h\u0026lt;=2lg(n+1)。\n​\t这就合并成了一颗2-3-4树，这棵树中的每一个结点有2、3、4个孩子结点，而一颗2-3-4树的叶结点有着相同的深度h‘。\n​\t也正是基于这个，所以对于有n个结点的红黑树而言，不论查找、删除、最大值、最小值等等的时间复杂都平均下来了，也就是O（logn）。\n红黑树的插入 ​\t其实红黑树的操作也很简单，就是比AVL多了一个着色的操作。\n​\t在AVL中，我们通过左旋和右旋来调整由于插入和删除所造成的不平衡的问题。在红黑树中，我们使用两种方式：\n​\t1、重新着色\n​\t2、旋转\n​\t当红黑树中出现不平衡的状态，我们首先会考虑重新着色，如果重新着色依旧不能使红黑树平衡，那么就考虑旋转。插入操作主要有两种情况，具体取决于叔叔结点的颜色。如果叔叔结点是红色的，我们会重新着色。如果叔叔结点是黑色的，我们会旋转或者重新着色，或者两者都考虑。\n​\t假设x是新插入的一个结点。\n​\t1、进行标准的BST插入并将新插入的结点设置为红色\n​\t2、如果x是根结点，将x的颜色转化为黑色（整棵树的黑高增加1）\n​\t3、如果x的父结点p不是黑色并且x不是根结点，则：\n​\t1）、如果x的叔叔结点u是红色；\n​\t2）、如果x的叔叔结点u是黑色，则对于x、x的父结点p和x的爷爷结点g有四种情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 LL（p是g的左孩子且x是p的左孩子） LR（P是g的右孩子且x是p的右孩子） RR（p是g的右孩子且x是p的右孩子） RL（p是g的右孩子且x是p的左孩子） 将插入结点x的父结点p和叔叔结点u的颜色变成黑色 将x的爷爷结点g设置为红色 将g看作是x，对于新的x重复2、3两步 插入结点x的叔叔结点u是红色 ​\t对于新插入结点 x，我们执行标准的 BST 插入之后，将插入结点 x 着色为红色；如果插入结点不是根结点，且x的父结点 p 为红色结点，分为 1) 和 2) 两种情况处理，我们先看的是 1) 的情况：x 的叔叔结点 u 为红色，如下图所示：\n​\t第一步：将父亲结点p和叔叔结点u都设置为黑色\n​\t​\t第二步：将g的颜色设置为红色\n​\t第三步：针对于g结点，在执行第二，第三步。\n插入结点x的叔叔结点u为黑色 ​\t当插入结点x的叔叔结点为黑色的时候，根据插入接待你x、x的父结点p和x的爷爷结点g可能出现的位置关系，分为四种情况。\nLL LR 首先通过左旋p转化为LL的情况：\n然后按照LL的情况处理：\nRR RL 先右旋转化成RR的情况\n然后按照RR的情况处理\n到这里，插入排序就全部讲完了。但我也知道很多人可能会有疑惑，那就让我们来构造一颗红黑树，看看运用上述规则到底是否适用。\n红黑树插入操作示例 下面就带大家构造一颗稍微复杂一点儿的红黑树：\n初始时，我们已知的插入依次插入：\n第一步：插入结点2，结点2就是根结点，设置为黑色：\n第二步：插入结点6，首先执行标准的BST插入操作并将结点6设置为红色，但6号结点的父结点为2的颜色为黑色，所以什么都不用做。\n第三步：插入结点9，执行BST插入，设置为红色。其父结点6颜色为红色，且叔叔结点null为黑色，属于RR的情况。故对其爷爷结点2进行左旋操作，并交换g和p的颜色。\n第四步：插入结点 10，执行标准的 BST 插入操作并设置为红色，其父结点 9为红色，其叔叔结点 2为红色结点，将其父结点 9 和叔叔结点涂黑色，并将其爷爷结点涂红色并设置为新的x，判断其爷爷结点 6 ，发现为根结点，重新更新为黑色。\n第五步：插入结点 12，执行标准的BST插入操作并设置为红色，其父结点 10为红色，其叔叔结点为黑色，其爷爷结点 9为红色，RR 的情况，则左旋 g ，交换 g 和 p 的颜色。\n第六步：插入结点15\n第七步：插入20\n第八步：插入18\n第九步：插入结点1\n第十步：插入结点5\n第十一步：插入结点13\n红黑树的删除 ​\t说起红黑树的删除操作，就不得不提我们讲的红黑树的插入。与红黑树的插入操作类似，红黑树的删除也是重新着色和旋转来保证每一次删除操作后依旧满足红黑树的属性。\n​\t在插入操作中，通过判断插入结点 x 的叔叔结点 u 的颜色来确定恰当的平衡操作。而删除操作中，是通过检查兄弟结点的颜色来决定恰当的平衡操作。 ​\t红黑树中插入一个结点最容易出现两个连续的红色结点，违背红黑树的性质3（红黑树中不存在两个相邻的红色结点）。而删除操作，最容易造成子树黑高（Black Height）的变化（删除黑色结点可能导致根结点到叶结点黑色结点的数目减少，即黑高降低）。 ​\t与插入操作相比，红黑树的删除操作相对复杂一点，但多点儿耐心，还是没有问题的。为了理解删除操作，我们先来看一个 双黑（Double Black） 的概念。\n​\t当删除结点 v 是黑色结点，且其被其黑色子节点替换时，其子结点就被标记为 双黑。\n​\t所以说，删除操作最主要的任务就是将转化为双黑结点转换为我们普通的黑色结点。\n删除操作总纲 ​\t删除操作总体上分为三步，我们先提高挈领地看一下，有个宏观概念，然后步步为营，攻陷删除。\n​\t首先我们假定要删除的结点为 v ，u 是用来替换 v 的孩子结点（注意，当 v 是叶结点时， u 是 NULL结点，且NULL结点我们还是当做黑色结点处理）。\n​\t删除操作总纲：\n​\t1、执行标准的BST的删除操作\n​\t2、简单情况：u或者v时红色\n​\t3、复杂情况：u和v都是黑色\n​\t1）u是双黑结点\n​\t2）当前结点u是双黑结点且不是根结点\n​\ta）u的兄弟结点s是黑色且s的孩子结点至少有一个是红色（LL、LR、RR、RL）\n​\tb）u的兄弟结点s是黑色且它的两个孩子都是黑色\n​\tc）u的兄弟结点s是红色（s是其父结点p的左孩子、s是其父结点的右孩子）\n​\t3）当前结点u是双黑结点且是根结点\n1、执行标准的BST删除操作 ​\t在标准的 BST 删除操作中，我们最终都会以删除一个叶子结点或者只有一个孩子的结点而结束（对于内部节点，就是要删除结点左右孩子都存在的情况，最终都会退化到删除结点是叶子结点或者是只有一个孩子的情况）。所以我们仅需要处理被删除结点是叶结点或者仅有一个孩子的情况。\n2、简单情况：u或者v是红色 ​\t如果 u 或者 v 是红色，我们将替换结点 v 的结点 u 标记为黑色结点（这样黑高就不会变化）。注意这里是 u 或者 v 是红色结点，因为在一棵红黑树中，是不允许有两个相邻的红色结点的，而结点 v 是结点 u 的父结点，因此只能是 u 或者 v 是红色结点。\n​\t删除结点 v 为黑色结点 10 ，替换结点 v 的结点 u 为红色结点 9 的情况：\n删除结点v为红色结点20，替换结点v的结点u为黑色NULL结点的情况：\n3、复杂情况 u和v都是黑色结点 3.1 结点u是双黑结点 ​\t当要删除结点 v 和孩子结点 u 都是黑色结点，删除结点 v ，导致结点 u 变为双黑结点。当 u 变成双黑结点时，我们的主要任务将变成将该双黑结点 u 变成普通的单黑结点。一定要特别注意，我们在上篇就提到的，NULL结点为黑色结点 ， 所以删除黑色的叶子结点就会产生一个双黑结点。\n3.2 当前结点u是双黑结点且不是根结点 ​\t当前结点 u 是双黑结点且不是根结点，又包含三种情况进行处理。我们约定结点 u 的兄弟结点为 s .\nu的兄弟结点s是黑色且s的孩子结点至少有一个是红色 ​\t对于这种情况，需要对 u 的兄弟结点 s 进行旋转操作，我们将 s 的一个红色子结点用 r 表示，u 和 s 的父结点用 p 表示，那么结点 p 、s 和 r 的位置将出现以下四种情况（LL、LR、RR、RL）。\n​\tLL（s 是 p 的左孩子，r 是 s 的左孩子，或者 s 的两个孩子都是红色结点）：\n​\t我们删除下图中的结点 25 为例进行说明：\n​\t删除结点 25 ，用结点 25 的NULL结点 替换结点 25 ，产生一个双黑结点 u ，双黑结点 u 的兄弟结点 s 为 15 ，结点 s 是其父结点 20（p） 的左孩子，其左孩子 10（r） 正好是红色结点。即为 LL 情况。\n​\ts 的左孩子 r 颜色设置为 s 的颜色，s 的颜色设置为父结点 p 的颜色，然后右旋p结点。\nLR（s是p的左孩子，r是s的右孩子，或者s的两个孩子都是红色）\n删除结点25，不过结点25的兄弟结点15只有一个右孩子18\n将结点r的颜色设置为p的颜色。\n左旋结点15（s）\n右旋结点20（p），p的颜色设置为黑色，双黑变单黑\nRR（s 是 p 的右孩子，r 是 s 的右孩子，或者 s 的两个孩子都是红色结点）： 删除结点 2 ，用结点 2 的NULL结点 a 替换结点 2 ，产生一个双黑结点 u ，双黑结点 u 的兄弟结点 s 为 15 ，结点 s 是其父结点 6（p） 的右孩子，其右孩子 18（r） 正好是红色结点。即为 RR 情况（仔细观察其实和 LL 情况是对称的）。\nr的颜色变为s的颜色，s的颜色变为p的颜色。\n左旋p，p的颜色设置为黑色，双黑变单黑\nRL情况（s 是 p 的右孩子，r 是 s 的左孩子，或者 s 的两个孩子都是红色结点）： 该情况与 LR情况是对称的\n结点r的颜色变为p的颜色\n右旋结点15\n左旋结点6（p），p的颜色设置为黑色，双黑变单黑\nu 的兄弟结点 s 是黑色且 s 的两个孩子结点都是黑色 ​\t对于这种情况需要递归地进行处理，如果删除结点后得到的双黑结点的父结点此时为黑色，则结点 u 变单黑，且结点 u 的父结点 p 变双黑，然后对结点 u 的父结点 p 继续进行处理，直到当前处理的双黑结点的父结点为红色结点，此时将双黑结点的父结点设置为黑色，双黑结点变为单黑结点（红色 + 双黑 = 单黑）。\n​\t假设以 10 为根结点的子树为整棵树的左子树，删除结点 9 ，产生双黑结点 c 且其兄弟结点 12（s） 为黑色，兄弟结点的左右孩子均为黑色。\n此时双黑结点的兄弟结点 12 变为红色结点，然后将 u 的父结点 10 变为双黑结点，一直向上判断。\n那么这个过程什么时候结束呢？\n如下图，删除结点12，得到一个双黑结点u，双黑结点的兄弟结点31及兄弟结点的孩子结点均为黑色，且双黑结点的父结点19为红色结点，刚好是不再继续向上判断的情况：\n此时只需要将结点 u 的兄弟结点 31 的颜色变为红色，双黑结点 u 的父结点 19 由红色变为黑色结点，双黑结点 u 变为单黑结点。\nu的兄弟结点s是红色结点 ​\t当前 u 的兄弟结点 s 是红色结点时，通过旋转操作将 u 当前的兄弟结点向上移动，并对 u 的父结点和其旋转前的兄弟结点重新着色，接着继续对结点 u 旋转后的兄弟结点 s 进行判断，确定相应的平衡操作。旋转操作将 u 的兄弟结点情况又会转换为前面刚提到的3.2（a）和（b）的情况。根据兄弟结点 s 是父结点 p 的左右孩子又分为两种情况。\n情况一：u 的兄弟结点 s 是父结点 p 的左孩子 ,对结点 p 进行右旋操作。\n​\t删除结点 18 ，产生一个双黑结点 u ，且 u 的兄弟结点 s 是红色，兄弟结点 s 是其父结点的左孩子，接着就是对其父结点 15 进行右旋操作。\n​\t对结点 15 进行右旋操作，并且对旋转前的 p 和 s 进行重新着色后，继续对双黑结点旋转后的兄弟结点进行判断，发现此时正好和 3.2（b）的情况是一样，进行相应处理，如下图所示。\n情况二：u 的兄弟结点 s 是父结点 p 的左孩子 ,对结点 p 进行左旋操作（这种情况与上面的是对称的）。\n删除结点 6 ，产生一个双黑结点 u ，且 u 的兄弟结点 10（s） 为红色，s 是父结点 p 的右孩子，左旋P\n对双黑结点 u 旋转后的兄弟结点继续判断：\n3.3 当前结点u是双黑结点且是根结点\n​\t当前结点 u 是双黑结点且是根结点时，直接将双黑结点变为单黑结点，整颗红黑树的黑高减 1.\n红黑树与AVL树的比较 ​\t红黑树中的每个结点需要一个存储位表示结点的颜色，可以是红或黑。通过对任何一条从根到叶子的路径上各个结点着色方式的限制，红黑树确保对于每一个结点其到叶子结点的最长路径不会超过最短路径的两倍，因此，红黑树是一种弱平衡二叉树（由于是弱平衡，可以看到，在相同结点的情况下，AVL树的高度\u0026lt;=红黑树），相对于要求严格的AVL树来说，它的旋转次数少，所以对于插入，删除操作较多的情况下，使用红黑树。\n来自一年后的补充: 红黑树的逻辑操作，第一次啃需要很长时间，啃下来之后长时间不复习，也很容易忘记，真正熟练的理解红黑树的详细逻辑是有一定困难的，而有时候不需要在这些地方上浪费太多的时间。（几乎忘得一干二净的我如此补充到\n","date":"2021-09-10T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/cfclogo03.png","permalink":"https://Kirov7.github.io/p/%E4%BB%8Ebstavl%E6%A0%912-3%E6%A0%91%E6%9D%80%E5%88%B0blt%E7%BA%A2%E9%BB%91%E6%A0%91%E5%B8%B8%E8%A7%81%E6%A0%91%E7%8A%B6%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E8%A7%A3%E8%AF%BB/","title":"从BST、AVL树、2-3树杀到BLT(红黑树)，常见树状数据结构解读"},{"content":"第二章 MySQL数据库的增删改查 第一节 DML语句 1. 什么是DML DML为Data Manipulation Language，表示数据操作语言。主要体现于对表数据的增删改操作。因此DML仅包括INSERT、UPDATE和DELEETE语句。\n2. INSERT语句 1 2 3 4 5 6 7 -- 需要注意，VALUES后的字段值必须与表名后的字段名一一对应 INSERT INTO 表名(字段名1, 字段名2, ..., 字段名n) VALUES(字段值1, 字段值2, ..., 字段值n); -- 需要注意，VALUES后的字段值必须与创建表时的字段顺序保持一一对应 INSERT INTO 表名 VALUES(字段值1, 字段值2, ..., 字段值n); -- 一次性插入多条数据 INSERT INTO 表名(字段名1, 字段名2, ..., 字段名n) VALUES(字段值1, 字段值2, ..., 字段值n),(字段值1, 字段值2, ..., 字段值n), ... , (字段值1, 字段值2, ..., 字段值n); INSERT INTO 表名 VALUES(字段值1, 字段值2, ..., 字段值n), (字段值1, 字段值2, ..., 字段值n), ..., (字段值1, 字段值2, ..., 字段值n); 示例：向课程表中插入数据\n1 2 3 4 5 INSERT INTO course (`number`, name, score, `time`) VALUES (1, \u0026#39;Java\u0026#39;, 8, 80); INSERT INTO course VALUE (2, \u0026#39;Golang\u0026#39;, 6, 60); INSERT INTO course (`number`, score, name, `time`) VALUES (3, 5, \u0026#39;Python\u0026#39;, 50); INSERT INTO course (`number`, name, score, `time`) VALUES (4, \u0026#39;C/Cpp\u0026#39;, 3, 30),(5, \u0026#39;Spring\u0026#39;, 4, 40); INSERT INTO course VALUE (6, \u0026#39;SpringMVC\u0026#39;, 4 ,40),(7, \u0026#39;SpringBoot\u0026#39;, 5, 50); 3. UPDATE语句 1 UPDATE 表名 SET 字段名1=字段值1[,字段名2=字段值2, ..., 字段名n=字段值n] [WHERE 修改条件]; 3.1 WHERE条件子句 3.1 WHERE条件子句 在Java中，条件的表示通常都是使用关系运算符来表示，在SQL语句中也是一样，使用 \u0026gt;, \u0026lt;, \u0026gt;=, \u0026lt;=, != 来表示。不同的是，除此之外，SQL中还可以使用SQL专用的关键字来表示条件。这些将在后面的DQL语句中详细讲解。 在Java中，条件之间的衔接通常都是使用逻辑运算符来表示，在SQL语句中也是一样，但通常使用AND来表示逻辑与(\u0026amp;\u0026amp;)，使用OR来表示逻辑或(||) 示例：\n1 2 3 WHERE time \u0026gt; 20 AND time \u0026lt; 60; -- 等价于 WHERE time \u0026gt; 20 \u0026amp;\u0026amp; time \u0026lt; 60; 3.2 UPDATE语句使用 将C/Cpp的学分更改为2，学时更改为20\n1 UPDATE course SET score=2, `time`=20 WHERE name=\u0026#39;C/Cpp\u0026#39;; 4. DELETE语句 1 DELETE FROM 表名 [WHERE 删除条件]; 示例：删除课程表中课程编号为1的数据\n1 DELETE FROM course WHERE \u0026#39;number\u0026#39;=1; 5. TRUNCATE语句 1 2 -- 清空表中的数据 TRUNCATE [TABLE] 表名; 示例：清空表course中的数据\n1 TRUNCATE course; 6. DELETE与TRUNCATE区别 DELETE语句根据条件删除表中数据，而TRUNCATE语句则是将表中数据全部清空；如果DELETE语句要删除表中所有数据，那么在效率上要低于TRUNCATE语句。 如果表中有自增长列，TRUNCATE语句会重置自增长的计数器，但DELETE语句不会。 TRUNCATE语句执行后，数据无法恢复，而DELETE语句执行后，可以使用事务回滚进行恢复。 第二节 DQL语句 1. 什么是DQL DQL全称是Data Query Language，表示数据查询语言。体现在数据的查询操作上，因此，DQL仅包括SELECT语句。\n2. SELECT语句 1 SELECT ALL/DISTINCT * | 字段名1 AS 别名1[,字段名1 AS 别名1, ..., 字段名n AS 别名n] FROM 表名 WHERE 查询条件 注：ALL表示查询所有满足条件的记录，可以省略；DISTINCT表示去掉查询结果中重复的记录AS可以给数据列、数据表取一个别名\n示例：从课程表中查询课程编号小于5的课程名称，从课程表中查询Java课程的学分(score)和学时(time)，从课程表中查询Java课程的学分和学时并重命名\n1 2 3 4 5 6 7 8 9 SELECT name FROM course WHERE `number` \u0026lt; 5; SELECT score, `time` FROM course name=\u0026#39;Java\u0026#39;; SELECT score AS \u0026#39;学分\u0026#39;, `time` AS \u0026#39;学时\u0026#39; FROM course name=\u0026#39;Java\u0026#39;; -- AS可以省略 SELECT score \u0026#39;学分\u0026#39;, `time` \u0026#39;学时\u0026#39; FROM course name=\u0026#39;Python\u0026#39;; -- 给表起别名 SELECT c.name, c.score, c.time FROM course c WHERE c.name=\u0026#39;Java\u0026#39;; -- 给表起别名的同时给字段重命名 SELECT c.name \u0026#39;课程名称\u0026#39;, c.score \u0026#39;学分\u0026#39;, c.time \u0026#39;学时\u0026#39; FROM course c WHERE c.name=\u0026#39;Python\u0026#39;; 3. 比较操作符 操作符 语法 说明 IS NULL 字段名 IS NULL 如果字段的值为NULL，则条件满足 IS NOT NULL 字段名 IS NOT NULL 如果字段的值不为NULL，则条件满足 BETWEEN \u0026hellip; AND \u0026hellip; 字段名 BETWEEN 最小值 AND 最大值 如果字段的值在最小值与最大值之间（能够取到最小值和最大值），则条件满足 LIKE 字段名 LIKE \u0026lsquo;%匹配内容%\u0026rsquo; 如果字段值包含有匹配内容，则条件满足 IN 字段名 IN(值1，值2，\u0026hellip;， 值n) 如果字段值在值1,值2, \u0026hellip;，值n中，则条件满足 示例：从课程表查询课程名为NULL的课程信息\n1 SELECT * FROM course WHERE name IS NULL; 示例：从课程表查询课程名不为NULL的课程信息\n1 SELECT * FROM coures WHERE name IS NOT NULL; 示例：从课程表查询学分在2~4之间的课程信息\n1 2 3 SELECT * FROM course WHERE score BETWEEN 2 AND 4; -- 等价于 SELECT * FROM course WHERE score \u0026gt;= 2 ANDE score \u0026lt;= 4; 示例：从课程表查询课程名包含\u0026quot;V\u0026quot;的课程信息\n1 SELECT * FROM course WHERE name LIKE \u0026#39;%V%\u0026#39;; 示例：从课程表查询课程名以\u0026quot;J\u0026quot;开头的课程信息\n1 SELECT * FROM course WHERE name LIKE \u0026#39;J%\u0026#39;; 示例：从课程表查询课程名以\u0026quot;p\u0026quot;结尾的课程信息\n1 SELECT * FROM course WHERE name LIKE \u0026#39;%p\u0026#39;; 示例：从课程表查询课程名只有三个字符的课程信息\n1 SELECT * FROM course WHERE name LIKE \u0026#39;___\u0026#39;; 示例：从课程表查询课程编号为1,3,5的课程信息\n1 SELECT * FROM course WHERE `number` IN (1, 3, 5); 4. 分组 数据表准备：新建学生表student，包含字段学号（no），类型为长整数，长度为20，是主键，自增长，非空；姓名（name），类型为字符串，长度为20，非空；性别（sex），类型为字符串，长度为2，默认值为\u0026quot;男\u0026quot;；年龄（age），类型为整数，长度为3，默认值为0；成绩（score），类型为浮点数，长度为5，小数点后面保留2位有效数字\n1 2 3 4 5 6 7 CREATE TABLE IF NOT EXISTS student( `no` BIGINT(20) AUTO_INCREMENT NOT NULL PRIMARY KEY COMMENT \u0026#39;学号\u0026#39;, name VARCHAR(20) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, sex VARCHAR(2) DEFAULT \u0026#39;男\u0026#39; COMMENT \u0026#39;性别\u0026#39;, age VARCHAR(3) INT(3) DEFAULT 0 COMMENT \u0026#39;年龄\u0026#39;, score DOUBLE(5, 2) COMMENT \u0026#39;成绩\u0026#39; )ENGINE=InnoDB CHARSET=UTF8 COMMENT \u0026#39;学生表\u0026#39; 插入测试数据：\n1 2 3 4 5 6 7 8 9 INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;枫阿雨\u0026#39;, \u0026#39;男\u0026#39;, 19, 89); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;雨阿枫\u0026#39;, \u0026#39;男\u0026#39; 19, 90); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;阿枫雨\u0026#39;, \u0026#39;男\u0026#39;, 19, 62); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;枫雨阿\u0026#39;, \u0026#39;男\u0026#39;, 22, 75); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;雨枫阿\u0026#39;, \u0026#39;女\u0026#39;, 18, 59); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;阿雨枫\u0026#39;, \u0026#39;其他\u0026#39;, 27, 88); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;亚烟雨\u0026#39;, \u0026#39;男\u0026#39;, 19, 88); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;烟亚雨\u0026#39;, \u0026#39;女\u0026#39;, 28, 81); INSERT INTO student(no, name, sex, age, score) VALUES (DEFAULT, \u0026#39;雨亚烟\u0026#39;, \u0026#39;其他\u0026#39;, 32, 62); 4.1 分组查询 1 SELECT ALL/DISTINCT * | 字段名1 AS\t别名1[,字段名1 AS 别名1, ..., 字段名n AS 别名n] FROM 表名 WHERE 查询条件 GROUP BY 字段名1, 字段名2, ...,字段名n; 注：分组查询所得结果只会展示组内的第一条数据\n示例：从学生表查询成绩在80分以上的学生信息并按性别分组\n1 SELECT * FROM student WHERE score \u0026gt; 80 GROUP BY sex; 示例：从学生表查询成绩在60~80之间的学生信息并按性别和年龄分组\n1 SELECT * FROM student WHERE score \u0026gt;= 60 AND score \u0026lt;= 80 GROUP BY sex, age; 4.2 聚合函数 COUNT()：统计满足条件的数据总条数\n示例：从学生表查询成绩在80分以上的学生人数\n1 SELECT COUNT(*) total FROM student WHERE score \u0026gt; 80; SUM()：只能用于数值类型的字段或表达式，九三该满足条件的字段值的总和\n示例：从学生表查询不及格的学生人数和总成绩\n1 SELECT COUNT(*) totalCount, SUM(score) totalScore FROM student WHERE score \u0026lt; 60; AVG()：只能用于数值类型的字段或者表达式，计算该满足条件的字段值的平均值\n示例：从学生表查询男生、女生、其他类型的学生的平均成绩\n1 SELECT sex, AVG(score) avgScore FROM student GROUP BY sex; MAX()：只能用于数值类型的字段或者表达式，计算该满足条件的字段值的最大值\n示例：从学生表查询学生的最大年龄\n1 SELECT MAX(age) FROM student; MIN()：只能用于数值类型的字段或者表达式，计算该满足条件的字段值的最小值\n示例：从学生表查询学生的最低分\n1 SELECT MIN(score) FROM student; 4.3 分组查询结果筛选 分组后如果还需要满足其他条件，则需要使用HAVING子句来完成。\n1 SELECT ALL/DISTINCT * | 字段名1 AS\t别名1[,字段名1 AS 别名1, ..., 字段名n AS 别名n] FROM 表名 WHERE 查询条件 GROUP BY 字段名1, 字段名2, ...,字段名n HAVING 筛选条件; 示例：从学生表查询年龄在18~22之间的学生信息并按性别分组，找出组内平均分在75分以上的组\n1 SELECT * FROM student WHERE age BETWEEN 18 AND 22 GROUP BY sex HAVING AVG(score) \u0026gt; 75; 5. 排序 1 2 3 SELECT ALL/DISTINCT * | 字段名1 AS 别名1[,字段名1 AS 别名1, ..., 字段名n AS 别名n] FROM 表名 WHERE 查询条件 ORDER BY 字段名1 ASC|DESC，字段名2 ASC|DESC,..., 字段名n ASC|DESC; -- DESC : 降序排序 -- ASC : 升序排序 注：ORDER BY必须位于WHERE 条件之后。\n示例：从学生表查询年龄在18~30岁之间的学生信息并按成绩从高到低排列，如果成绩相同，则按年龄从小到大排列\n1 SELECT * FROM student WHERE age BETWEEN 18 AND 30 ORDER BY score DESC, age ASC; 6. 分页 1 SELECT ALL/DISTINCT * | 字段名1 AS 别名1[,字段名1 AS 别名1, ..., 字段名n AS 别名n] FROM 表名 WHERE 查询条件 LIMIT 偏移量, 查询条数 LIMIT的第一个参数表示偏移量，也就是跳过的行数。 LIMIT的第二个参数表示查询返回的最大行数，可能没有给定的数量那么多行。\n示例：从学生表分页查询成绩及格的学生信息，每页显示3条，查询第2页学生信息\n1 SELECT * FROM student WHERE score \u0026gt;= 60 LIMIT 3, 3; 注：如果一个查询中包含分组、排序和分页，那么它们之间必须按照分组-\u0026gt;排序-\u0026gt;分页的先后顺序排列。\n第三节 综合练习 1. 创建员工表 emp，包含字段员工编号（no），类型为整数，长度为20，是主键，自增长，非空；姓名（name），类型为字符串，长度为20，非空；性别（sex），类型为字符串，长度为2，默认值为\u0026quot;男\u0026quot;；年龄（age），类型为整数，长度为3，非空；所属部门（dept），类型为字符串，长度为20，非空；薪资（salary），类型为浮点数，长度为10，小数点后面保留2位有效数字，非空。\n1 2 3 4 5 6 7 8 CREATE TABLES IF NOT EXISTS emp( `no` BIGINT(20) AUTO_INCREMENT NOT NULL PRIMARY KEY COMMENT \u0026#39;员工编号\u0026#39;, name VARCHAR(20) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, sex VARCHAR(2) DEFAULT \u0026#39;男\u0026#39; COMMENT \u0026#39;性别\u0026#39;, age TINYINT(3) UNSIGNED NOT NULL COMMENT \u0026#39;年龄\u0026#39;, dept VARCHAR(20) NOT NULL COMMENT \u0026#39;所属部门\u0026#39;, salary DOUBLE(10, 2) NOT NULL COMMENT \u0026#39;薪资\u0026#39; )ENGINE=InnoDB CHARSET=UTF8 COMMENT \u0026#39;员工表\u0026#39;; 2. 向员工表插入如下数据：\n姓名 性别 年龄 部门 薪资 枫阿雨 男 19 研发部 27000 雨阿枫 男 24 研发部 22000 阿枫雨 女 23 财务部 16000 枫雨阿 女 26 财务部 17000 阿雨枫 男 28 研发部 25000 亚烟雨 女 24 研发部 23000 烟亚雨 女 24 测试部 12000 雨亚烟 女 26 测试部 14000 1 INSERT INTO emp (name, sex, age, dept, salary) VALUES (\u0026#39;枫阿雨\u0026#39;, \u0026#39;\u0026#39;男\u0026#39;\u0026#39;, 19, \u0026#39;研发部\u0026#39;, 27000),(\u0026#39;雨阿枫\u0026#39;, 男, 24, \u0026#39;研发部\u0026#39;, 22000),(\u0026#39;阿枫雨\u0026#39;, \u0026#39;女\u0026#39;, 23, \u0026#39;财务部\u0026#39;, 16000),(\u0026#39;枫雨阿\u0026#39;, \u0026#39;女\u0026#39;, 26, \u0026#39;财务部\u0026#39;, 17000),(\u0026#39;阿雨枫\u0026#39;, \u0026#39;男\u0026#39;, 28, \u0026#39;研发部\u0026#39;, 25000),(\u0026#39;亚烟雨\u0026#39;, \u0026#39;女\u0026#39;, 24, \u0026#39;研发部\u0026#39;, 23000),(\u0026#39;烟亚雨\u0026#39;, \u0026#39;女\u0026#39;, 24, \u0026#39;测试部\u0026#39;, 12000),(\u0026#39;雨亚烟\u0026#39;, \u0026#39;男\u0026#39;, 26, \u0026#39;研发部\u0026#39;, 14000); 3. 烟亚雨 因工作出色而被提升为测试主管，薪资调整为16000\n1 UPDATE emp SET salary=16000 WHERE name=\u0026#39;烟亚雨\u0026#39;; 4. 研发部 阿雨枫 离职\n1 DELETE FROM emp WHERE name=\u0026#39;阿雨枫\u0026#39;; 5. 从员工表中查询出平均年龄小于25的部门\n1 SELECT dept FROM emp GROUP BY dept HAVING AVG(age) \u0026lt; 25; 6. 从员工表中统计研发部的最高薪资、最低薪资、平均薪资和总薪资\n1 SELECT MAX(salary), MIN(salary), AVG(salary) FROM emp WHERE dept=\u0026#39;研发部\u0026#39;; 7. 从员工表中统计各个部门的员工数量\n1 SELECT dept, COUNT(*) FROM emp GROUP BY dept; 8. 从员工表中查询薪资在14000以上的员工信息并按薪资从高到低排列\n1 SELECT * FROM emp WHERE salary \u0026gt; 14000 ORDER BY salary DESC; 9. 从员工表中分页查询员工信息，每页显示5条员工信息，按薪资从高到低排列，查询第2页员工信息\n1 SELECT * FROM emp ORDER BY salary DESC LIMIT 5, 5; ","date":"2021-09-10T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E4%BA%8C/","title":"从零开始学MySQL(二)"},{"content":"第一章 初识MySQL数据库 第一节 数据库操作 1. 创建数据库的语法 1 CREATE DATABASE [IF NOT EXISTS] 数据库名称 DEFAULT CHARACTER SET 字符集 COLLATE 排序规则; 实例：创建数据库lesson，并指定字符集为GBK，排序规则为GBK_CHINESE_CI\n1 CREATE DATABASE IF NOT EXISTS lesson DEFAULT CHARACTER SET GBK COLLATE GBK_CHINESE_CI; 2.修改数据库的语法 1 ALTER DATABASE 数据库名称 CHARACTER SET 字符集 COLLATE 排序规则; 实例：修改数据库lesson，并指定字符集为UTF8，排序规则为UTF8_GENERAL_CI\n1 ALTER DATABASE lesson CHARACTER SET UTF8 COLLATE UTF8 GENERAL_CI; 3.删除数据库的语法 1 DROP DATABASE [IF EXISTS] 数据库名称; 实例：删除数据库lesson\n1 DROP DATABASE IF EXISTS lesson; 4.查看数据库语法 1 SHOW DATABASE; 5.使用数据库语法 1 USE 数据库名称; 实例：使用数据库lesson\n1 USE lesson; 第二节 列类型 在MySQL中，常用列类型主要为数值类型、日期时间类型、字符串类型\n1. 数值类型 tinyint smallint mediumint int bigint float double decimal 1字节 2字节 3字节 4字节 8字节 4字节(浮点) 8字节(浮点) m字节(浮点) 注：decimal(m, d) 为字符串存储的浮点数，其中m表示总位数，d表示保留小数位数\n2. 日期时间类型 DATE(日期) TIME(时间) DATETIME TIMESTAMP(时间戳) YEAR YYYY-MM-dd HH:mm:ss YY-MM-dd HH:mm:ss YY-MM-dd HH:mm:ss YYYY 3. 字符串类型 类型 说明 最大长度 char[(M)] 固定长字符串，索引快但费空间，0\u0026lt;=M\u0026lt;=255 M字符 varchar[(M)] 可变字符串，0\u0026lt;=M\u0026lt;=65535 变长度 text 文本串 2^16^-1字节 注： char(50) ：不论插入值占用多少位空间，在数据库中都会占50个长度。比如\u0026quot;男\u0026quot;\n​\tvarchar(50)：最大占用50个长度。比如\u0026quot;男\u0026quot;占用1个\n​\ttext：用于存储长文本\n4. 列类型修饰属性 类型 说明 示例 UNSIGNED 无符号，只能修饰数值类型，表明该列数据不能出现负数 UNSIGNED INT(4)，表示只能为4位大于等于0整数 ZEROFILL 不足的位数使用0 INT(4) ZEROFILL，如果给定的值位10，此时只有2位，而该列需要4位，不足的2位由0来填充，最终值为0010 NOT NULL 表示该列类型的值不能为空 VARCHAR(20) NOT NULL，表示该列不能为空值 DEFAULT 表示设置默认值 INT(4) DEFAULT 0，表示该列不赋值时默认为0 AUTO_INCREMENT 表示自增长，只能应用于数值列类型，该列类型必须为键，且不能为空 INT(11) AUTO_INCREMENT NOT NULL PRIMARY KEY。第一次为该列中插入值时为1，第二次为2，以此类推 第三节 数据表操作 1. 数据表类型 MySQL中的数据表类型由许多，如MyISAM、InnoDB、HEAP、BOB、CSV等。其中最常用的就是MyISAM和InnoDB\nMyISAM和InnoDB的区别 名称 MyISAM InnoDB 事务处理 不支持 支持 数据行锁定 不支持 支持 外键约束 不支持 支持 全文索引 支持 不支持 表空间大小 较小 较大，约2倍 事务：涉及的所有操作是一个整体，要么都执行，要么都不执行。\n数据行锁定：一行数据，当一个用户在修改该数据时，可以将该条数据锁定。\n注：如何选择数据表的类型?\n1 当涉及的业务操作以查询居多，修改和删除较少时，可以使用 MyISAM 。当涉及的业务操作经常会有修改和删除操作时使用 InnoDB 2. 创建数据表 1 2 3 4 5 6 7 CREATE TABLE [IF NOT EXISTS] 数据表名称( 字段名1 列类型(长度) [修饰属性] [键/索引] [注释], 字段名2 列类型(长度) [修饰属性] [键/索引] [注释], 字段名3 列类型(长度) [修饰属性] [键/索引] [注释], ...... 字段名n 列类型(长度) [修饰属性] [键/索引] [注释] ) [ENGINE = 数据表类型][CHARSET = 字符集编码] [COMMENT = 注释]; 示例：创建学生表，表中有字段学号、姓名、性别、年龄和成绩\n1 2 3 4 5 6 7 CREATE TABLE IF NOT EXISTS student( `number` VARCHAR(30) NOT NULL PRIMARY KEY COMMENT \u0026#39;学号，主键\u0026#39;, name VARCHAR(30) NOT NULL COMMENT \u0026#39;姓名\u0026#39;, sex TINYINT(1) UNSIGNED DEFAULT 0 COMMENT \u0026#39;性别：0-男 1-女 2-其他\u0026#39;, age TINYINT(3) UNSIGNED DEFAULT 0 COMMENT \u0026#39;年龄\u0026#39;, score DOUBLE(5, 2) UNSIGNED DEFAULT NULL COMMENT \u0026#39;成绩\u0026#39; )ENGINE=InnoDB CHARSET=UTF8 COMMENT=\u0026#39;学生表\u0026#39;; 3. 修改数据表 修改表名\n1 ALTER TABLE 表名 RENAME AS 新表名; 示例：将student表名修改为stu\n1 ALTER TABLE student RENAME AS stu; 增加字段\n1 ALTER TABLE 表名 ADD 字段名 列类型(长度) [修饰属性] [键/索引] [注释]; 示例：在stu中添加字段联系电话(phone)，类型为字符串，长度为11，非空\n1 ALTER TABLE stu ADD phone VARCHAR(11) NOT NULL COMMENT \u0026#39;联系电话\u0026#39;; 查看表结构\n1 DESC 表名; --查看表结构 修改字段\n1 2 3 4 -- MODIFY 只能修改字段的修饰属性 ALTER TABLE 表名 MODIFY 字段名 列类型(长度) [修饰属性] [键/索引] [注释]; -- CHANGE 可以修改字段的名字以及修饰属性 ALTER TABLE 表名 CHANGE 字段名 新字段名 列类型(长度) [修饰属性] [键/索引] [注释]; 示例：将stu表中的sex字般的类型设置为VARCHAR，长度为2，默认值为男，注释为\u0026quot;性别，男，女，其他\u0026quot;\n1 ALTER TABLE stu MODIFY sex VARCHAR(2) DEFAULT \u0026#39;男\u0026#39; COMMENT \u0026#39;性别：男，女，其他\u0026#39;; 示例：将stu表中的phone字段修改为moblie，属性保持不变\n1 ALTER TABLE stu CHANGE phone mobile VARCHAR(11) NOT NULL COMMENT \u0026#39;联系电话\u0026#39;; 删除字段\n1 ALTER TABLE 表名 DROP 字段名; 示例：将stu表中的mobile字段删除\n1 ALTER TABLE stu DROP mobile; 删除数据表\n1 DROP TABLE [IF EXISTS] 表名; 示例：删除数据表stu\n1 DROP TABLE IF EXISTS stu; 第四节 综合练习 1. 在数据库exercise中创建课程表stu_course，包含字段课程编号(number)，类型为整数，长度为11，是主键，自增长，非空；课程名称(name)，类型为字符串，长度为20，非空；学分(score)， 类型为浮点数，小数点后面保留2位有效数字，长度为5， 非空\n1 2 3 4 5 6 7 8 9 10 -- 如果数据库不存在则创建数据库 CREATE DATABASE IF NOT EXISTS exercise DEFAULT CHARACTER SET UTF8 COLLATE UTF8_GENERAL_CI; -- 使用数据库 USE exercise; -- 在数据库中创建数据表stu_course CREATE TABLE IF NOT EXISTS stu_course( `number` INT(11) AUTO_INCREMENT NOT NULL PRIMARY KEY COMMENT \u0026#39;课程编号\u0026#39;, name VARCHAR(20) NOT NULL COMMENT \u0026#39;课程名称\u0026#39;, score DOUBLE(5, 2) NOT NULL COMMENT \u0026#39;学分\u0026#39; )ENGINE=InnoDB CHARSET=UTF8 COMMENT \u0026#39;课程表\u0026#39;; 2. 将课程表重命名为course\n1 ALTER TABLE stu_course RENAME AS course; 3. 在课程表中添加字段学时(time)，类型为整数，长度为3，非空\n1 ALTER TABLE course ADD `time` INT(3) NOT NULL COMMENT \u0026#39;学时\u0026#39;; 4. 修改课程表学分类型为浮点数，小数点后面保留1位有效数字，长度为3，非空\n1 ALTER TABLE course MODIFY score DOUBLE(3, 1) NOT NULL COMMENT \u0026#39;学时\u0026#39;; 5. 删除课程表\n1 DROP TABLE IF EXISTS course; 6. 删除数据库exercise\n1 DROP DATABASE IF EXISTS exercise; ","date":"2021-09-06T00:00:00Z","image":"https://img-1307890592.cos.ap-chengdu.myqcloud.com/typroa/mysql.jpg","permalink":"https://Kirov7.github.io/p/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E5%AD%A6mysql%E4%B8%80/","title":"从零开始学MySQL(一)"},{"content":"فقرة 1 هذا النص هو مثال لنص يمكن أن يستبدل في نفس المساحة، لقد تم توليد هذا النص من مولد النص العربى، حيث يمكنك أن تولد مثل هذا النص أو العديد من النصوص الأخرى إضافة إلى زيادة عدد الحروف التى يولدها التطبيق. إذا كنت تحتاج إلى عدد أكبر من الفقرات يتيح لك مولد النص العربى زيادة عدد الفقرات كما تريد، النص لن يبدو مقسما ولا يحوي أخطاء لغوية، مولد النص العربى مفيد لمصممي المواقع على وجه الخصوص، حيث يحتاج العميل فى كثير من الأحيان أن يطلع على صورة حقيقية لتصميم الموقع. ومن هنا وجب على المصمم أن يضع نصوصا مؤقتة على التصميم ليظهر للعميل الشكل كاملاً،دور مولد النص العربى أن يوفر على المصمم عناء البحث عن نص بديل لا علاقة له بالموضوع الذى يتحدث عنه التصميم فيظهر بشكل لا يليق. هذا النص يمكن أن يتم تركيبه على أي تصميم دون مشكلة فلن يبدو وكأنه نص منسوخ، غير منظم، غير منسق، أو حتى غير مفهوم. لأنه مازال نصاً بديلاً ومؤقتاً.\nفقرة 2 هذا النص هو مثال لنص يمكن أن يستبدل في نفس المساحة، لقد تم توليد هذا النص من مولد النص العربى، حيث يمكنك أن تولد مثل هذا النص أو العديد من النصوص الأخرى إضافة إلى زيادة عدد الحروف التى يولدها التطبيق. إذا كنت تحتاج إلى عدد أكبر من الفقرات يتيح لك مولد النص العربى زيادة عدد الفقرات كما تريد، النص لن يبدو مقسما ولا يحوي أخطاء لغوية، مولد النص العربى مفيد لمصممي المواقع على وجه الخصوص، حيث يحتاج العميل فى كثير من الأحيان أن يطلع على صورة حقيقية لتصميم الموقع. ومن هنا وجب على المصمم أن يضع نصوصا مؤقتة على التصميم ليظهر للعميل الشكل كاملاً،دور مولد النص العربى أن يوفر على المصمم عناء البحث عن نص بديل لا علاقة له بالموضوع الذى يتحدث عنه التصميم فيظهر بشكل لا يليق. هذا النص يمكن أن يتم تركيبه على أي تصميم دون مشكلة فلن يبدو وكأنه نص منسوخ، غير منظم، غير منسق، أو حتى غير مفهوم. لأنه مازال نصاً بديلاً ومؤقتاً.\nتجربة RTL كلمة 1 Text كلمة 2\n","date":"2020-03-09T00:00:00Z","image":"https://Kirov7.github.io/p/%D9%85%D8%AB%D8%A7%D9%84-%D9%86%D8%B5/matt-le-SJSpo9hQf7s-unsplash_hu958d513eeefe5556a31d065479ecc5ac_14205_120x120_fill_q75_box_smart1.jpg","permalink":"https://Kirov7.github.io/p/%D9%85%D8%AB%D8%A7%D9%84-%D9%86%D8%B5/","title":"مثال نص"}]